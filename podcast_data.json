[
    {
        "title": "President of Argentina - Freedom, Economics, and Corruption",
        "guest": "Javier Milei",
        "thumbnail": "https://lexfridman.com/files/thumbs_ai_podcast/javier_milei.png",
        "video_link": "https://www.youtube.com/watch?v=8NLzc9kobDk",
        "episode_link": "https://lexfridman.com/javier-milei",
        "transcript_link": "https://lexfridman.com/javier-milei-transcript",
        "timestamps": [
            {
                "time": "0:00",
                "chapter": "Introduction"
            },
            {
                "time": "3:27",
                "chapter": "Economic freedom"
            },
            {
                "time": "8:52",
                "chapter": "Anarcho-capitalism"
            },
            {
                "time": "18:45",
                "chapter": "Presidency and reforms"
            },
            {
                "time": "38:05",
                "chapter": "Poverty"
            },
            {
                "time": "44:37",
                "chapter": "Corruption"
            },
            {
                "time": "53:14",
                "chapter": "Freedom"
            },
            {
                "time": "1:07:26",
                "chapter": "Elon Musk"
            },
            {
                "time": "1:12:54",
                "chapter": "DOGE"
            },
            {
                "time": "1:14:56",
                "chapter": "Donald Trump"
            },
            {
                "time": "1:20:56",
                "chapter": "US and Argentina relations"
            },
            {
                "time": "1:28:05",
                "chapter": "Messi vs Maradona"
            },
            {
                "time": "1:36:58",
                "chapter": "God"
            },
            {
                "time": "1:39:05",
                "chapter": "Elvis and Rolling Stones"
            },
            {
                "time": "1:42:45",
                "chapter": "Free market"
            },
            {
                "time": "1:49:46",
                "chapter": "Loyalty"
            },
            {
                "time": "1:52:23",
                "chapter": "Advice for young people"
            },
            {
                "time": "1:53:49",
                "chapter": "Hope for Argentina"
            }
        ],
        "transcript": [
            {
                "speaker": "Javier Milei",
                "time": "(00:00:00)",
                "text": "So what is the difference between a madman and a genius? Success."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:00:10)",
                "text": "The following is a conversation with Javier Milei, the president of Argentina. He is a libertarian, anarcho-capitalist, and economist, who campaigned with a chainsaw that symbolized his promise to slash the corrupt bureaucracy of the state. He stepped into the presidency one year ago, with a country on the brink of hyperinflation, deepened debt and suffering from mass unemployment and poverty. He took this crisis head on, transforming one of Latin America’s largest economies through pure free market principles. In just a few months in office, he already achieved Argentina’s first fiscal surplus in 16 years, and not just avoided the hyperinflation but brought inflation down to its lowest in three years."
            },
            {
                "speaker": "",
                "time": "(00:01:02)",
                "text": "We discuss all of this in detail, both the successes and the challenges. His depth of knowledge of economic principles, metrics and data was truly impressive and refreshing to hear from a world leader. But even bigger than the economic transformation of Argentina, Javier represents the universal fight against government corruption and the fight for freedom, economic freedom, political freedom, and freedom of speech. He has many critics, many of whom a part of the corrupt establishment he’s seeking to dismantle, but many are simply Argentinian citizens, scared of the pain his radical policies may bring, at least in the short term. But whether one disagrees with his methods or not, no one can deny that his presidency marks one of the most ambitious attempts at economic transformation in modern history, and that Javier Milei is truly a force of nature, combining the rigor of an economist with the passion of a revolutionary in the fight for freedom of a nation he loves. Argentina is one of my favorite countries, so I sincerely hope he succeeds."
            },
            {
                "speaker": "",
                "time": "(00:02:13)",
                "text": "This interview was conducted with the President speaking Spanish and me speaking English with an interpreter simultaneously translating. We make the episode available overdubbed and subtitled in both English and Spanish, thanks to our great friends at ElevenLabs. If you’re watching on YouTube, you can switch between English and Spanish by clicking the gear icon, selecting audio track, and then choosing the language. Same with the captions. If you’re watching on X, I’ll post both Spanish and English versions separately. If you’re watching on Spotify or listening elsewhere, I’ll probably only post the English version. This is a first time for me doing something like this in a foreign language. It was challenging, but illuminating. I hope to talking to many world leaders for two to three hours in this way, including Volodymyr Zelenskyy, Vladimir Putin, Narendra Modi, and Xi Jinping. I want to explore who they are, how they think, and how they hope to help their country and humanity flourish. This is the Lex Friedman Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Javier Milei."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:03:27)",
                "text": "When did you first understand the value of freedom, especially economic freedom?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(00:03:33)",
                "text": "Well, actually, I came to understand the ideas of freedom as an economic growth specialist back in the years of 2013 to 2014. I could see that per capita GDP statistics over the last 2,000 years of the Christian era essentially looked like a hockey stick, indicating that per capita GDP remained almost constant until around 1800, after which it accelerated sharply. In the same context of that phenomenal increase in productivity and per capita GDP, the population had multiplied sevenfold over the preceding 200 years."
            },
            {
                "speaker": "",
                "time": "(00:04:20)",
                "text": "So basically, in economics, that means you get increasing returns, and the presence of increasing returns implies the existence of monopolies, concentrated structures, and according to traditional neoclassical economic theory, the presence of monopolies and concentrated structures is not a good thing. But at the same time, one could see that living standards had increased tremendously and that middle-income people ended up living far better than emperors did in the Roman era, and the population had gone from having 95% of people in extreme poverty to less than 10%. And in that context, the question was, how it could be that something that had lifted so many people out of poverty, that had improved human conditions so much, could be something bad for economic theory, meaning something was not right."
            },
            {
                "speaker": "",
                "time": "(00:05:20)",
                "text": "So in that context, I remember that one of the people who worked on my team suggested I read an article by Murray Newton Rothbard called Monopoly and Competition. I remember reading it like it was today, and after reading it carefully, I said, “Everything I’ve taught about market structure in the last 20 years in courses on microeconomics is wrong.” This caused a very strong internal commotion in me. So I called this person who used work with me, and they recommended a place to buy Austrian School of Economics books, and I remember I bought at least 20 or 30 books, which I went to pick up one Saturday afternoon. And when I visited the bookstore, I was fascinated by all the stuff they had there."
            },
            {
                "speaker": "",
                "time": "(00:06:18)",
                "text": "So I went back the next day and I started calculating how much money I needed to pay for my dog’s food. That’s my four-legged child, and how much I needed to spend on the taxi fare and food. And then with what I have left, I spent all of it on more books. And then I started to read very intensively, and I remember for example, the experience of reading Human Action by Mises, and this was a book that I didn’t know about. And I remember that on the following weekend, I started to read this book right from the first page, and I didn’t stop until I finished it, and that was a true revolution in my head. And having the chance to read Austrian authors like Rothbard, Mises, Hayek, Hoppe and Jesus Huerta de Soto, or others like Juan Ramon Rallo, Philipp Bagus and Walter Block, for example."
            },
            {
                "speaker": "",
                "time": "(00:07:27)",
                "text": "That was very inspirational, and at one point I got the opportunity to read related to the works of Alberto Benegas Lynch [foreign language 00:07:38], and I also had the pleasure and honor to meet him. And today we are actually friends. So that paved the way for me to approach the ideas of freedom. And another book that was a very significant influence and impact on me was the Principles of Political Economics by Menger. It was truly eye-opening, or let’s say, for reading Eugen von Böhm-Bawerk, these were things that really challenged all of my former thinking. I had a vague idea and poor about the Austrian School. The only thing I had read about the Austrian School until then had been Money and Time, a very good book by Garrison. But now that I understand a little bit more about Austrian economics, I know that it was rather poor. This doesn’t mean that the book isn’t good, but there were a whole lot of things to read that ended up being truly fascinating."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:08:52)",
                "text": "So from that, what is now, today, and maybe you can talk about the evolution, is your philosophy, economics philosophy. You’ve described yourself as an anarcho-capitalist, market anarchists, libertarian. That’s the ideal, and then maybe in practice and reality, you’ve said that you’re more of a minarchist. So lay it all out. What’s your economics philosophy today?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(00:09:19)",
                "text": "Strictly speaking, I am an anarcho-capitalist. I despise the state government. I despise violence. Let us suppose we take the definition of liberalism. I usually use the definition of liberalism given by Alberto Benegas Lynch [foreign language 00:09:37], which is very much in line with the definition of John Locke, which essentially matches the definition by Alberto Benegas Lynch, Jr., who said that liberalism is the unrestricted respect for the life project of others based on the principle of non-aggression and in defense of the right to life, liberty, and property. So I frame all of the discussions within those terms. And the fact is that when you get to that notion, I would dare say that you become an anarcho-capitalist de facto. And what that describes, it is an idea which represents my ideal world. I mean, that is the ideal world."
            },
            {
                "speaker": "",
                "time": "(00:10:23)",
                "text": "Now, real life poses a whole lot of restraints, and some of those you can lift, and those restrictions and others you can’t. So in real life, I am a minarchist. I advocate for minimizing state size. I try to remove as many regulations as possible. In fact, that is what I used to say during my campaign, and let’s say, that is what I’m now carrying out. We have just carried out the largest structural reform in Argentine history. It is a structural reform that is eight times larger than Menem’s, which had been the largest structural reform in history. And we did that with 15% of the representatives and 10% of the senators. Furthermore, we have a deregulation ministry where basically every day we eliminate between one and five regulations. On the other hand, we have 3,200 additional structural reforms pending, to the point that the day we finish all these reforms, we will be the freest country on the planet, with the consequences they have in terms of well-being. Think about this, when Ireland started market reforms just over 40 years ago, it was the poorest country in Europe. Today, its GDP per capita is 50% higher than that of the United States. So I have a current situation, and what I am constantly looking for, whether from my academic works and my outreach notes and books, is the world we have today, that every day we are closer, that every day we gain more freedom because there are some very interesting things here. First, I would like to quote Milton Friedman. There is a moment when they do an interview with Milton Friedman and they ask him about liberals, and then he says that there are three types of liberals. There are the classical liberals where, for example, Adam Smith or Milton Friedman himself could fit. Some say that Hayek could fit into that category. For me, Hayek is a minarchist."
            },
            {
                "speaker": "",
                "time": "(00:12:38)",
                "text": "Then you have the minarchists where you could clearly find in that place Mises, Hayek. One could find in philosophical terms Nozick and basically Ayn Rand. And at one point, Milton Friedman, based on his own son, he says, “But if you look closely, there are some who are anarchists.” Let’s say, probably from my point of view, the person who has been the greatest inspiration in my life is essentially Murray Newton Rothbard. So therefore, there are two dimensions. One is where I want to go, and the topic is where I stand. So the most important thing is to try each day to advance further toward that ideal of anarcho-capitalism. In that sense, sometimes we face strong and harsh criticism regarding that ideal vision. I think that’s the nirvana fallacy. If you compare yourself against paradise, everything is horrible and miserable, but you don’t live in paradise. You live on earth. Basically, what you need to understand is something called the state conditions. Let’s suppose that you don’t like rectangular tables. You prefer circular tables. Now the reality is, I have only a few hours until I go and catch my flight and the table is rectangular. You like a circular table, a round one, but there isn’t one. What you have is a rectangular table. So either we do the interview here or we just can’t do it. So what do you do? You adapt to the current conditions. This is what there is now. So then you have some restrictions that you can change and others that you cannot. The idea is to modify all the ones that can be changed in the short term, and start working on those that can be modified in the medium or long-term. For example, if you really like round tables, perhaps the next interview we may do at a round table. We’re going to try and solve it, but today it’s something that we couldn’t possibly solve. So that’s basically the idea, right?"
            },
            {
                "speaker": "",
                "time": "(00:15:09)",
                "text": "Let’s say it’s about understanding that some restrictions you can change, others you can, and there are institutional restrictions too. There are many anarcho-capitalists who are dedicated to criticizing, and incredibly, they do so with more violence towards liberals, and many of them actually criticize me, which truly make no sense because it is precisely the nirvana fallacy but the reality is that… Look, in Argentina, for example, the most popular sport is soccer. When you go to watch an Argentina match, it is beautiful. The stands are full, and they’re all painted with sky blue and white colors. There is a lot of joy. People sing songs that are very fun, that are very distinctive. It’s very much part of Argentine folklore, so to speak. But you see that beautiful show is external. That is to say it does not determine the outcome. You place the ball in the middle of the field, and no matter how much people shout, the ball doesn’t move. The one who moves the ball and scores the goals is Messi."
            },
            {
                "speaker": "",
                "time": "(00:16:31)",
                "text": "So what do I mean? If you don’t get involved and don’t get into it, no, you don’t do anything. So what do I know is that there are many liberals, libertarians and anarcho-capitalists who are really useless because all they do is criticize, let’s say, those of us who want to lead the world toward the ideas of freedom. And what they don’t realize is that power is a zero-sum game, and if we don’t have it, then the left will have it. Therefore, if you level your harshest criticism at those in your own ranks, you end up being subservient to socialism probably. And also, for instance, you have cases of strong hypocrisy, let’s say. I have seen cases of agorists. It’s the anarcho- capitalists who criticize Rothbard because he said that you have to get into politics, otherwise the socialists will advance. And it’s interesting because some of them, I have seen them criticizing, proposing agorism, and I remember one of them, one day the police showed up and honestly, he was peeing himself."
            },
            {
                "speaker": "",
                "time": "(00:17:57)",
                "text": "So it’s very easy to criticize, propose, and suggest, but if he was truly such an agonist, he should have been willing to endure going to jail. However, when it was time to face the consequences of the idea he was promoting, he froze, wet his pants and ended up, let’s say, accepting all the restrictions because clearly it was better to be out of jail than in jail. But in doing so, he sold out his ideas. So it seems to me that no, not taking into account the restrictions of the situation, only serves to be functional to socialism because all it does is strike against one’s own."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:18:45)",
                "text": "So you became president 11 months ago. Can you, again, describe some of the actions you took? For example, you cut half the number of government ministries, layoffs, removed price controls. It’ll be interesting to lay out the first steps and what’s next."
            },
            {
                "speaker": "Javier Milei",
                "time": "(00:19:04)",
                "text": "If you allow me, I will first give you a description of the situation we received, and based on that, I will tell you each of the things we did. When we first took office, basically what we found was that in the first week of December, inflation was rising at the rate of 1% per day, which means 3,700% annually. In the first half of December, it had accelerated to 7,500% annually. When you look at wholesale inflation in December of last year, it was 54%, which if annualized would equate to an inflation rate of 17,000% per year. And in addition, Argentina for the previous 10 years had not been growing, with a drop in GDP per capita of approximately 15%. And the reality was that nearly 50% were living in poverty."
            },
            {
                "speaker": "",
                "time": "(00:20:16)",
                "text": "Now, later I will get deeper into that discussion, and the reality is that we had a fiscal deficit, which amounted to 15% of GDP. Five points were in the Treasury, 10 points were in the Central Bank, which was endogenous monetary issuance. And the reality is that we also had interest-bearing liabilities at the Central Bank, equivalent to four monetary bases maturing in one day, meaning we could have quintupled the amount of money in one day. We had peso-denominated maturities, amounting to the equivalent of $90 billion. The Central Bank had negative net currency foreign reserves, minus $12 billion. We had commercial debts in the Central Bank equivalent to $50 billion. There were company dividends held back amounting to $10 billion. Therefore, if we had instantly opened up… You see, I say we are liberal libertarians. We are not liberal fools. That’s what some anarchist liberals suggested, meaning that we basically open everything on the first day."
            },
            {
                "speaker": "",
                "time": "(00:21:40)",
                "text": "So in that context, of course, if we had done that, we would’ve encountered hyperinflation. Therefore, that would have led to the number of poor people being around 95% and probably, and by December, the Peronist party would have organized supermarket’s lootings, and would’ve done all sorts of things, and would’ve probably been ousted. And by the first part of the year, the Peronists would’ve gone back to office. So to us, it was crucial to end fiscal deficit."
            },
            {
                "speaker": "",
                "time": "(00:22:19)",
                "text": "One of the things we promised during the campaign had been to reduce the number of ministries, and indeed we reduced to less than half the number of ministries because we went to nine ministries, today we have eight. We have also laid off a large number of civil employees. Today, I can say that we’ve already dismissed about 50,000 of them, and we practically don’t renew any contracts unless the positions are absolutely necessary. At the same time, we have stopped public works and we have eliminated discretionary transfers to the provinces. We have also diluted public sector wages. Also, we have eliminated economic subsidies by restoring utility rates to the right levels. And in that, let’s say, in this context, we achieved fiscal balance as far as the Treasury is concerned. This is very important because in the last 123 years, Argentina had a deficit for 113 of them, and in the 10 years it did not have a deficit because it was not paying the debt. So that was absolutely false, and they told us it would be impossible to do that."
            },
            {
                "speaker": "",
                "time": "(00:23:47)",
                "text": "We had planned to do so within a year, and they said it wasn’t possible to adjust by more than one percentage point, and we achieved fiscal balance in the month of January. That is the first month of administration. At the same time, we also cut social plans linked to intermediation. This is very important because we knew we were going to make a very tough adjustment, and we knew that this was going to have a court in social terms, and we knew that we had to offer support during the first month, I mean, the first quarter and second quarter in office. One of the things we did was to eliminate what are known as poverty managers. That is intermediaries. Basically, people have a guard through which they receive assistance, but it happens that they had to provide a counter service, and that counter service was verified by a group called the piqueteros."
            },
            {
                "speaker": "",
                "time": "(00:24:54)",
                "text": "So in that context, when they were going to sign, the counter service took away half of the money. So by removing that payoff, they stopped extorting them, stopped stealing their money, and with the same amount of money, they received double the resources. And of course, we also provided an additional boost. So let’s say that this is related to the five adjustment points in the Treasury. Now, what happens, as we began to achieve fiscal balance and no longer needed to issue money to finance ourselves, and as we also met interest payments and some capital repayments, one of the things that happened is that the debt market began to be recreated. So we were able to take debt out of the Central Bank and transfer it to the Treasury where it should have always been, and that meant an adjustment of approximately 10% of GDP. Everyone said this would be impossible and couldn’t be fixed."
            },
            {
                "speaker": "",
                "time": "(00:25:58)",
                "text": "Essentially, what we did was implement a fiscal adjustment at the Central Bank, amounting to 10% of GDP. So if you ask me, it’s clear that we have not only made the biggest fiscal adjustment in the history of humanity, because we made a fiscal adjustment of 15 points of the GDP, but also most of that went back to the people as less seigniorage, as a lower inflation rate. It’s true that we temporarily raised the country tax, but we lowered it in September, and now in December, we’re going to eliminate it. Today, for example, we also announced that in December we are eliminating import taxes. In fact, in that regard, what you have is that we return to the people 13 and a half points of GDP because the real tax burden is the size of the state. So while back in December we were discussing hyperinflation, today we are discussing 30-year loans."
            },
            {
                "speaker": "",
                "time": "(00:27:03)",
                "text": "In other words, all those resources that the national government used to take are now back in the private sector. And that’s what has allowed it to be very dynamic. And this has two very strong impacts. The first one is that if you look at wholesale inflation, it went down from 54% to 2%. So it went down by 27 times. It was divided into 27. So we had inflation at the rate of 17,000% annually, and it’s now close to about 28% a year, but it’s not only that. You could consider consumer inflation, the latest consumer inflation rate was 2.7%. Now, it happens that we essentially, due to a matter that is related to the Central Bank’s balance sheets and also due to the debt stocks, we still have controls in place and we are eliminating restrictions, day by day. Now, the interesting thing is that we have a 2% monthly devaluation standard, and there’s international inflation of course, which means that you then have to subtract two and a half points from the inflation observed by the consumer."
            },
            {
                "speaker": "",
                "time": "(00:28:20)",
                "text": "This indicates that inflation in Argentina, the true inflation, not the induced one, but the actual monetary inflation is 0.2% per month. At 0.2% per month, this equates to 2.4% annually. What I’m saying is, the original discussion was about whether inflation could reach 17,000%. Now we are bringing inflation down to levels of 2.5% annually, and that is amazing. And we achieved this by considering a number of factors. The first one is that we did not experience a previous hyperinflation, which would’ve simplified the process of implementing a stabilization program. Typically, when hyperinflation occurs, monetary assets are diluted, leading to a natural restoration of demand. And besides, we did not resort to any expropriation. For example, before the Convertibility plan, which was the most successful program in Argentina’s history, Argentina experienced two instances of hyperinflation. During Alfonsin’s administration, inflation reached 5,000%, and under Menem was 1,200%."
            },
            {
                "speaker": "",
                "time": "(00:29:34)",
                "text": "Additionally, there was the BONEX plan, under which debt was exchanged on a compulsory basis. In other words, what we did instead was clean up the Central Bank balance sheet. So with that, we cleaned up the Central Bank’s balance sheet. We cleared a loss of $45 billion, all voluntarily. And the most amazing thing is that we did it in just six months, and at the same time, we have not controlled prices."
            },
            {
                "speaker": "Javier Milei",
                "time": "(00:30:00)",
                "text": "And at the same time, we have not controlled prices nor have we fixed the exchange rate. And this is very important. All previous stabilization programs in an effort to show quick results used to do this. What they would do is, before announcing the plan, they would adjust the rates. And once the rates were adjusted, they would launch the plan. But in our case, we couldn’t afford that luxury, so we had to implement it on the go. And also over the past few months, that is to say companies brought in rates that covered only about 10%, whereas today they cover 80% so you get the picture. Just imagine the adjustment we are making. And in that sense, it is also incredible what we have achieved because if we were to work with the inflation we have in our country today, considering the exchange rate situation, the figures are even better than during the convertibility program, which was the most successful economic program in Argentina’s history."
            },
            {
                "speaker": "",
                "time": "(00:31:09)",
                "text": "And in fact, there is an article called Passing the Buck, which is by Gerardo della Paolera, Bózzoli, and Irigoin that demonstrates that Menem’s first government was the best government in history. And basically, it argues two things in the success of the stabilization of the convertibility program. So if you take a closer look, when you examine it carefully, when you account for all these factors, our disinflation process is actually much more genuine. And not only that, it’s also much deeper. We are restored freedoms to Argentinians while simultaneously implementing a structural reform eight times larger. And we accomplished this with only with 15% of the representatives, 10% of the senators, and within the first six months of government. In other words, our deregulation agenda continues daily and we still have 3,200 structural reforms pending. This will ultimately make Argentina the freest country in the world."
            },
            {
                "speaker": "",
                "time": "(00:32:18)",
                "text": "Moreover, to have a sense of magnitude, the reforms that we already have made with the executive order 7023, and with the basis law, we have actually jumped 90 places in terms of economic freedom. What this means is that today, Argentina has institutions similar to those of Germany, France, Italy, and we obviously want this to continue. And let’s say we are going to surpass no doubt the levels of economic freedom that Ireland reached in its best moment. And not only that, we’re going to exceed the levels of economic freedom of Australia, New Zealand, and Switzerland. We are undoubtedly going to be the freest country in the world."
            },
            {
                "speaker": "",
                "time": "(00:32:59)",
                "text": "And this means that thanks to what we’ve done today, we are on a path that allows us to multiply our per capita GDP by 2.5 times when you apply the relevant correction. And this of course is something very interesting because it implies a huge increase in well-being. And furthermore, today the Argentinian economy is already strongly and amazingly recovering. And we can say analysts’ hypotheses were suggesting that next year we will be growing between five and 6%. Today, JP Morgan has now corrected or let’s say revised the projections upwards. And besides, when we normalized the price situation, the true poverty rate came up and it was 57% in January. Today it is at 46%, meaning we lowered poverty by 11 percentage points. Let’s say, I mean, it seems truly like a miracle. And not only that, but actually not a single job was lost in the process."
            },
            {
                "speaker": "",
                "time": "(00:34:04)",
                "text": "When it comes to all of this inflation reduction process, people said that our economy and economic activity would collapse. And actually when you look at the de-seasonalized data, you see that in August there was a recovery that took us back to December levels, to December levels. That means that in the year, we made the largest fiscal adjustment in the history of humanity. We will end up with less inflation, fewer poor people, better real wages, and additionally, a GDP higher than what we started with."
            },
            {
                "speaker": "",
                "time": "(00:34:39)",
                "text": "And if you look at it in dollars, I can assure you that the numbers are phenomenal because basically today the dollar is below the levels we had when we took office. So the reality is that in all of this, when you take my popularity levels and the government’s acceptance levels, today they are above the moment. We assumed office if you know that the moment of maximum popularity is when you take office. Therefore this means that far from resting on our laurels with this, we’re going for more reforms. We’re going to deepen the reforms. And I tell you, we won’t stop until Argentina is the freest country in the world."
            },
            {
                "speaker": "",
                "time": "(00:35:26)",
                "text": "Furthermore, a recent work by an Argentinian economist named Juan Pablo Nicolini was presented at the central bank’s monetary meetings and he works at the Federal Reserve. And it’s interesting because he shows that only on the basis of what we have done in fiscal matters it ensures that in the span of 10 years we can double the GDP per capita, meaning that Argentina could grow at rates of 7% annually, which is very much, very much, and that has strong consequences in terms of improving quality of life, reducing poverty, reducing indigence. Therefore, if during the worst moment our image didn’t suffer and we stayed strong in our ideas, now that everything is working much better, why should we change?"
            },
            {
                "speaker": "",
                "time": "(00:36:22)",
                "text": "On the contrary, we are ready to redouble the bet, to redouble our efforts because we’ve done things that no one else has done. I will give you an example. There’s something that seems trivial, but there’s what’s called the single paper ballot. Argentina used to vote with huge ballots, which were above all very costly. And that reform, it never… Let’s say it wasn’t done because it always harmed the ruling party. So everyone talked about going to the single paper ballot, but no one did it when they were in power. They didn’t want to implement it because they preferred to commit fraud or use some kind of trickery to avoid applying that rule that makes the election more competitive. Well, what’s interesting, we sent that law and it was approved."
            },
            {
                "speaker": "",
                "time": "(00:37:18)",
                "text": "What’s more? Now we are finishing with the open, simultaneous and mandatory primaries because it was a mechanism by which politics was also stealing. We are eliminating the financing of political parties. If you look, we have reduced the fiscal pressure by 15 points to the Argentinians. We are restoring freedoms with a deep set of structural and regulatory reforms that is I think that any sensible liberal could perceive. We are already delivering a wonderful government. In fact, it’s the best government in the history of Argentina. If the best had been that of Menem, we’ve already outpaced him."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:38:05)",
                "text": "Maybe you can explain to me the metrics of poverty and unemployment. As you said, unemployment went down, real unemployment went down, real poverty went down. But even that aside, what have been the most painful impacts of these radical reforms and how many of them are required in the short term to have a big positive impact in the long term?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(00:38:31)",
                "text": "Let’s take it step by step, all right? That is in fact, we started to do things right, therefore we did not create poverty. The poverty was an inherited poverty. The point is that what we did was to reveal it."
            },
            {
                "speaker": "",
                "time": "(00:38:50)",
                "text": "I’ll try to explain it with an example that I think clarifies what’s happening in Argentina. Argentina was an economy that had a total price controls. It had a fiscal deficit which was financed through money printing. Just for you to give you an idea, in the last year, Argentina financed 13 points of the gross domestic product with money printing. In other words, a real disaster. So that situation provoked this artificially demand and puts pressure on prices. The issue is that price controls are applied additionally over the prices that they enter the price index with which inflation was… I’m not saying they were lying about it. It was distorted."
            },
            {
                "speaker": "",
                "time": "(00:39:43)",
                "text": "And since Argentina measures poverty and indigence by income line, then what happens? That distorted the true levels of poverty, of course. But that’s not the only effect. I mean, let’s say the real poverty levels were higher, quite a bit higher than those shown by the previous government, which showed them at 41% and also did so on a six-monthly basis. So if you, let’s say, have a growing trend, they are actually leaving you a bomb and you don’t see it because let’s say basically the indicator was measured with a delayed form. But not only that, imagine that you are also given… You are in the middle of an island alone and they give you $1 million. What can you do with that? You cannot do anything because you cannot buy anything. It is the same as if someone tells you that the price of glasses is $10, but when you want to buy it, it’s not available."
            },
            {
                "speaker": "",
                "time": "(00:40:53)",
                "text": "Actually, there’s a joke told by an Argentinian professor named Juan Carlos de Pablo, who says that a man goes to a bazaar and asks for a vase. Then he says to him, “Well, I want that vase. How much would you charge me?” Then he says, “$5,000.”"
            },
            {
                "speaker": "",
                "time": "(00:41:10)",
                "text": "“Oh, okay, $5,000. But why $5,000 if across the street it’s 1,000?” He says, “Well, go buy it across the street for 1,000.”"
            },
            {
                "speaker": "",
                "time": "(00:41:19)",
                "text": "“Ah, there’s none for 1,000.”"
            },
            {
                "speaker": "",
                "time": "(00:41:21)",
                "text": "“Well then, here when there’s more, it’ll also cost 1,000.” In other words, prices at which they are available. So what happens? When you are faced with that situation, the supermarket shelves were empty. So what was the point of having a price at which you couldn’t buy anything? You left those prices. The shelves were empty. So the statistics showed that you were much better, but the reality is you couldn’t buy anything. You couldn’t make it happen."
            },
            {
                "speaker": "",
                "time": "(00:41:48)",
                "text": "So if you left the situation as it was, people were going to starve because they couldn’t buy anything. Yes, they had a certain amount of money that could supposedly buy certain goods, but those goods were not available. What is the only thing you can do to save people? Make the prices transparent and allow products to reappear. Well, when you make the prices transparent, you also make transparent the cost of the basic food basket and the total basic basket, meaning the poverty line… Sorry, the indigence line and the poverty line respectively. And when you do that, clearly you will see a jump in poverty. That brought poverty up to 57%."
            },
            {
                "speaker": "",
                "time": "(00:42:28)",
                "text": "Now, Argentina found its activity floor in the month of April. From that moment, Argentina began to invent a cyclical recovery. Real wages have been growing every month above inflation. Therefore, nominal wages are beating inflation. In fact, we are already at level similar to those we had in November. The same goes for pensions."
            },
            {
                "speaker": "",
                "time": "(00:42:53)",
                "text": "Moreover, also, let’s say there is a rebound in activity due to the recovery of the stock cycle. Therefore, this is also contributing to more and better-paid jobs. In fact, this is so strong and evident that the wages growing the most are in the informal sector. This means that poverty and extreme poverty are decreasing much faster than we imagined. But not only that, by eliminating inflation, you remove the inflationary tax, but the real burden is the fiscal deficit, which was 15 points of the GDP."
            },
            {
                "speaker": "",
                "time": "(00:43:27)",
                "text": "Okay, we temporarily raised the country tax, now we lower it, but we return that to the Argentinians. We gave back 15 points of the GDP. Not only that, but also when you eliminate inflation, you remove the distortion of relative prices. Therefore, the allocation of resources is much better. Not only that, but also with the strong fiscal adjustment we made, we have reduced the country risk from 3000 basis points to 770. Today, Fitch raised Argentina’s rating to CCC. So what do I mean? That translates into a lower country risk and interest rates. And that generates an increase in investment, also generates an increase in consumption."
            },
            {
                "speaker": "",
                "time": "(00:44:13)",
                "text": "In other words, the Argentinian economy is currently in an absolutely flourishing moment. And how is that sustained in the long term? With structural reforms which we implement daily, deregulating the economy and introducing new laws that free Argentinians from the many oppressive measures that have burdened it over the past 100 years."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:44:37)",
                "text": "You’ve spoken about the caste, the corrupt political establishment. So there’s a lot of powerful people and groups that are against your ideas. What does it take to fight when so much power is against you?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(00:44:54)",
                "text": "Look, we have fought against corruption like never before in Argentina. In fact, when we took office for example, there were about 900 roadblocks per year. That is people who made a habit of blocking the streets. They prevented free movement. And besides, they were given social plans and they were given a lot of money. If you remember when I started by explaining the cuts, one of the things I said was that we removed the middlemen of poverty. In other words, the managers of poverty, those who lived by stealing from the poor. Well, that is a huge source of corruption."
            },
            {
                "speaker": "",
                "time": "(00:45:35)",
                "text": "In fact, when we did that, two days later, one of the most renowned and influential Piqueteros called for a demonstration. He claimed that 50,000 people would attend because he was actually expecting 100,000. So he wanted to showcase it as a success. And so then let’s say with the decision made in human capital to cut their funding, the anti-blockade protocol was also enacted, where those who blocked the streets wouldn’t receive welfare benefits."
            },
            {
                "speaker": "",
                "time": "(00:46:13)",
                "text": "And those who broke the law would go to jail. All of that. And also we were informing this through transportation channels. Well, in that march, they expected to have 100,000 people there. And actually it turned out to be 3,000 people. And from that point on, they didn’t block the streets anymore."
            },
            {
                "speaker": "",
                "time": "(00:46:38)",
                "text": "We also evidently put an end to that corruption. One of the things that also generated a lot of corruption was public works. Another thing that led to significant acts of corruption were the discretionary transfers to provinces. In general, these transfers were made to the provinces with accounting as obscure as possible. So the national government, in collusion with the governors let’s say, the money ended up being used for other things. Not only that, with which we have already done many things."
            },
            {
                "speaker": "",
                "time": "(00:47:16)",
                "text": "Furthermore, the ministry of human capital is always filing complaints in court. Not in the media, in court. Acts of corruption like never before in Argentine history. Not only that, but also in terms of condemning corruption. That is, we have done, for example, two days ago, it was condemned, Cristina Fernández de Kirchner got a sentence for corruption, I mean, due to corruption. And the next day, that is yesterday, we took away their privileged pensions."
            },
            {
                "speaker": "",
                "time": "(00:47:52)",
                "text": "At the same time, we are, for example, we have discovered that Kirchnerism used disability pensions for acts of corruption. For example, there is a city that has more disability pensions than people. In other words, to give you an idea of the things being done in Argentina."
            },
            {
                "speaker": "",
                "time": "(00:48:12)",
                "text": "And also in Argentina, we have restored freedom to the judiciary. We do not pressure the judiciary. And this is so true that during my government, not only was Cristina Fernández de Kirchner convicted, but also the two terrorist attacks carried out by Iran were condemned. So if there is a government that is truly fighting against corruption, it is us. Not only that, but also with each deregulation, it is a privilege that we take away either from a politician, a prebendary company, or a power group. That is also very powerful. No one in Argentina has ever fought against corruption the way we have. In fact, I will move on to something that is deeply corrupt and one of my great battles, the corruption of the media and social media. That is to say, I removed the official advertising. That’s why you will see that even though we generate wonderful news, every week in large quantity, the media speak terribly. In other words, they demand to have a monopoly on the microphone. That is they are entitled to insult, hurt, offend, and they don’t want anyone to bother them, and they expect me not to even respond. That’s why a large part of journalism in Argentina hates the X Network. And that’s why the liberal libertarians love the X network, because we can all say what we want."
            },
            {
                "speaker": "",
                "time": "(00:49:49)",
                "text": "However, let’s say these supposed journalists who defend freedom of expression, actually what they want is to censor the ideas they don’t like. And of course, because they are leftists, because they are wokes, because they can’t stand the competition, because if they had to fight face-to-face, hand to hand, on a level playing field, when it comes to ideas, they would lose because they were a failure in the economic, social, and cultural aspects. And also, we must not forget that those murderers called socialists killed 150 million people. So they clearly cannot fight on equal terms. Therefore, they demand that social networks have censorship and that the truth cannot be told to them. Because when you tell a socialist the truth, they cry, claiming it’s hate speech. No, it’s not hate speech. It’s that you are useless people who have ruined the planet. They have made the planet much worse."
            },
            {
                "speaker": "",
                "time": "(00:50:50)",
                "text": "And fortunately today, thanks to social media, especially due to the enormous and brave work of Elon Musk and the role of Twitter, today X, allows information to flow, which makes it possible, let’s say, to expose politicians and also expose the media. And that’s why journalists in Argentina are so violent. Why? Because before they could, for instance, a journalist went and for example, he would go to a person and he would throw a folder at them and say, “If you don’t give me X amount of money, I am going to publish all of this and tarnish your reputation.” And I know for a fact a case of a journalist who carried out this extortion twice to a businessman, that businessman told him that he wasn’t going to pay. And evidently the journalist did it. Obviously they went to court, there was a trial, and that journalist lost both times. But that process is very slow. And in the meantime, they smeared."
            },
            {
                "speaker": "",
                "time": "(00:51:57)",
                "text": "So since the justice system takes a long time, so what is the problem? The problem is that in the meantime, your life got dirtied. So why can’t journalists do all this? Well, that’s why they dislike X. They dislike social media. They dislike the new form of communication because it took away their monopoly over the microphone. And by taking away the monopoly over the microphone, it removed the economic benefits of extortion."
            },
            {
                "speaker": "",
                "time": "(00:52:24)",
                "text": "So clearly, that’s another battle I’m fighting. You read a newspaper in Argentina, and 85% of what you read is a lie. That is to say the fundamental characteristic of most journalists, not all, but the vast majority of journalists in Argentina with some honorable exceptions, is that they are liars, slanderers, and defamers. And if the monopoly they demand were still in place that they want to reign again, I have no doubt that they will demand money in exchange for silence, because that’s what they are. They are extortionists, they are thieves, they are corrupt. And then of course, obviously when you take away a privilege from a sector, they get upset. Well, welcome to freedom."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:53:14)",
                "text": "So you’re not only fighting for economic freedom, you’re fighting for freedom of speech?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(00:53:19)",
                "text": "Exactly. I fight for freedom in all aspects of life. That is to say, one of the things that seems most interesting to me is that when the Berlin Wall fell, it’s true that officially it fell in the year 1989. But the reality is that the wall or socialism fell in the year 1961 when they had to build the wall. I mean, they built it because people were leaving Communist Germany for capitalist Germany. They realized that those on the western side were much better off. And of course, to prevent people from leaving. They put what a wonderful system, right? So I mean, they had to trap people. They couldn’t let them go. I mean, these are such wonderful ideas that they had to apply them at gunpoint."
            },
            {
                "speaker": "",
                "time": "(00:54:13)",
                "text": "Well, it’s no coincidence that they killed 150 million human beings. So what happened then? The official fall of the wall in the year 1989 made it clear that socialism had failed. In that context, the socialists, they moved the discussion of class struggle in economics and took it to other areas. So for example, socialism or what is of the 21st century or cultural Marxism or post-Marxism, whatever definition you want, is to take class struggle to different aspects of life."
            },
            {
                "speaker": "",
                "time": "(00:54:58)",
                "text": "For example, one of the aspects of life where you, let’s say, have this is in gender ideology. I mean, it’s incredible because the first ones to defend equality before the law were the liberals. The first to defend women’s rights were the liberals. Jeremy Bentham in the year 1750 was the first to demand equality before the law for women. I mean the cause of equality, equality before the law for women and equality of rights. The first ones who advocated for this were the liberals, did you know? However, what does the left do? They just go on to radicalize it. And then it moves to what is called female chauvinism."
            },
            {
                "speaker": "",
                "time": "(00:55:43)",
                "text": "Female chauvinism is, let’s say, the fight against males. And then, I mean, how do they do it? They do it by assigning rights. But when you assign a right, someone has to pay for it. And that has consequences. And in general, let’s say this always happens, the consequences are that the results are worse than what you had before. I mean, in any state intervention, the subsequent result is often worse than what you originally had. So that’s one thing. And not only that, but the other side of this is the environmental agenda, which sets man against nature involving all aspects of environmentalism and everything related to climate change."
            },
            {
                "speaker": "",
                "time": "(00:56:29)",
                "text": "In other words, they can’t stand any serious discussion. Therefore, all environmental policies are nothing more than an excuse to collect taxes so that a group of parasitic bureaucrats can live at the expense of others and finance sinister ideas, where the most sinister idea of all is that there is no room for everyone on planet earth. That is an idea that failed with Malthus at the beginning of the 19th century, a murderous idea that was also applied by the Egyptians against the Jews. And this is famously recorded in the Book of Shemot or Exodus."
            },
            {
                "speaker": "",
                "time": "(00:57:07)",
                "text": "Or for example, another thing is Black Lives matter, that is Black people against white people or indigenous people against the established communities, or I mean everything related to LGBT agendas. Definitely, these are some of the ways in which socialism extended the class struggle into other aspects of society, creating divisions and fostering deceit with the sole purpose of absorbing taxes."
            },
            {
                "speaker": "",
                "time": "(00:57:41)",
                "text": "I mean, what was the ministry of women in Argentina doing? Did it manage to reduce a single femicide? No, none at all. The number of femicides exploded just the same. In fact, the most feminist president in Argentine history, Mr. Alberto Fernández, used to beat his wife. That is such a strange feminist. I mean, well… So within the ranks of feminists, let’s say, you will essentially find the largest number of rapists and women beaters. And it’s quite interesting what they do. Their hypocrisy is truly striking."
            },
            {
                "speaker": "",
                "time": "(00:58:20)",
                "text": "It’s not just about that though. I mean, the battle is on three fronts. You have the economic front, which is free enterprise capitalism. Then we have the political level. Currently, the system that the world has designed is a Republican liberal democracy with checks and balances. And I mean, at the cultural battle level, notice that socialism has been very successful in the cultural battle. It has been very successful politically because it was able to translate that political battle in winning many elections. But why is it falling apart? Why? Because it produces misery and because the economic system is a disaster, so people eventually realize that it is making things worse for them."
            },
            {
                "speaker": "",
                "time": "(00:59:17)",
                "text": "Liberal, libertarians are very good when it comes to economics. Yes. And those good economic results can actually lead to the generation of solid political processes. But what happened? The liberals neglected the cultural battle. Much of the blame was placed on Fukuyama when he said, “This is the end of history.” No, it was not the end of history because the following year, in 1990, the socialists gathered at the São Paulo Forum, and based on the ideas of Gramsci, designed a strategy to infiltrate the media, culture, and education, which ended up changing the entire discourse. And they established that what they said was politically correct and that any-"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:00:00)",
                "text": "… was politically correct and that any idea outside of it was to be considered reactionary and had to be censored or even persecuted, and they claimed to be the ones defending freedom even though they were the ones persecuting people."
            },
            {
                "speaker": "",
                "time": "(01:00:16)",
                "text": "It’s the same with journalists who get upset with Twitter. They say they defend freedom but can’t stand it when those who think differently speak. Is that freedom? Yes, for them, but not for those who think differently. That’s not freedom. That’s fascism. Then, what do we say? Then we must fight on the economic front. And I believe we are implementing an extremely successful economic program that is being recognized worldwide. In fact, the other night, the president-elect, Donald Trump, indeed gave recognition for the achievements we are having in Argentina and the speed at which we have done it."
            },
            {
                "speaker": "",
                "time": "(01:00:54)",
                "text": "At the same time, you have to fight the political battle because, well, soccer matches are not won by shouting from the stands, they are won by playing on the field. But that alone is not enough because you have to, let’s say you need to convey to society the values of capitalism, the free market, what liberalism is, the value of freedom, right? And when you succeed in that, then we will indeed be able to advance steadily. If you don’t fight the cultural battle, what happened in Chile will happen to you. They had economic success. It was, let’s say sustained over time, but at some point it collapsed. Why did it collapse? Because they hadn’t fought the cultural battle."
            },
            {
                "speaker": "",
                "time": "(01:01:42)",
                "text": "Then socialism, little by little, took control of institutions in education and the media. So, they took over the media and culture and on that basis, they attacked and broke up the system. And then they found themselves with increasing doses of socialism and the only thing socialism generates is poverty. Therefore, what you must keep in mind is that you have to fight the battles on all fronts. And if you don’t keep that in mind, I can tell you are headed towards collapse."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:02:17)",
                "text": "Like you said, in this fight against corruption, you are challenging some very powerful people, a powerful establishment. Are you ever afraid for your life? Potential assassinations?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:02:33)",
                "text": "No. Tell me what good is it to live life, I mean, in slavery? Look, there is a song by a Spanish singer called Nino Bravo. Just to be clear, he has already left this earth, so we can say he has passed onto the beyond. The song is called Libre, and the song, it tells the story of Peter Fetcher, an 18-year-old boy who when the separation was made, and I mean the construction of the Berlin Wall begins. His family ends up on the western side and he accidentally ends up on the eastern side. And for a whole year, he plans his escape to the western side. And in that context, when he tries to escape, he gets murdered."
            },
            {
                "speaker": "",
                "time": "(01:03:36)",
                "text": "So really, what is the point of life if it’s not in freedom, right? I mean what is the point of living without fighting for your values? If I am willing to give my life for my values, then what is the point of living without freedom? Look, can I tell you something interesting that happened to me here in the United States? Let’s say back in the year 1998, I came to the United States to take a series of courses to improve my English, which I never use in formal terms because as president, as you can imagine, if I make a mistake, I can create a serious situation. Fortunately, I have an interpreter who is a superstar, and if I make a mistake even in Spanish, he corrects me in the version of the other language."
            },
            {
                "speaker": "",
                "time": "(01:04:34)",
                "text": "And so back then, in that year, I went to San Francisco and I visited Alcatraz. You are young, but I mean the visit was an audio tour. You got a Walkman and you would choose the different tracks and listen to the story. The most interesting thing is that the Alcatraz story ended in the recreation yard where the basketball court, exercise area, and all recreational facilities were located. So anyone would have thought that this was the best part of Alcatraz. And yet, what they said in the guide was that that was the hardest part for the inmates. Why? Because I mean that recreation area in particular is built in front of the San Francisco Bay. So, the inmates could all see how San Francisco continued to build up and evolve and develop every day while they were locked up in there. They couldn’t take part in that. They were confined in that prison. And that made them fully aware of the value of freedom."
            },
            {
                "speaker": "",
                "time": "(01:05:51)",
                "text": "So, in my experience for me, the fight for freedom is relentless, okay? I mean my greatest hero in all of human history is Moses. The feat of Moses is like one person alone with his brother, Aaron, both confronting the combined forces of the United States, China, and Russia together. And it was Moses who said to Ramesses, “Let my people go.” Well, Ramesses resisted and the forces of heaven ran him over. But what I mean is I don’t see any other possible way to live other than with freedom. And I would always fight for full freedom and I would be at the forefront of this cause. I mean it’s a cause that I’m going to die with my boots on. I mean I’m not going to make do with living any other way other than with freedom. I will fight everything. I’m going to fight as much as it takes. At least that’s the way I feel. So, what good is it to be alive if you’re confined? What good is it to be alive if you’re not free? It’s no good. What good was it for Peter Fetcher to be alive in communist Germany? Well, at least he had a moment of happiness while he tried to escape."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:07:26)",
                "text": "Another guy who fights for freedom, freedom of speech in this case, is your new friend, Elon Musk. What do you admire and what have you learned from your interactions with Elon?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:07:39)",
                "text": "I have a huge admiration for Elon Musk. He is an absolutely unconventional person. He’s a great fighter for the ideas of freedom. What he has done on Twitter, now known as X, and how he is helping the world nowadays to wake up once and for all and become aware of the socialist virus, the woke virus, that in itself makes him a hero in the history of humanity. But it’s not just that."
            },
            {
                "speaker": "",
                "time": "(01:08:25)",
                "text": "One of the things that happened to me is that when I went to first talk to him, I thought I was going to meet a successful businessman and that I would have a typical successful businessman conversation who understands business and that some of his businesses, some of his business is slightly more exotic, but that’s the kind of talk you would expect to have. And business people are truly admirable, right? Because they are true benefactors of society, but they’re usually very much focused on their own business. And one of the things that really, really shocked me when I met Elon Musk, we had scheduled a meeting for no more than 50 minutes, the first time we were in the meeting for a little over 45 minutes because he was about to miss his flight. So obviously, if someone as important as him doesn’t fly as planned, it has to be rescheduled and he loses a lot of hours. Imagine, every minute is very valuable."
            },
            {
                "speaker": "",
                "time": "(01:09:42)",
                "text": "And one of the things that happened was that basically he brought up the topic of demography and we started discussing demographics and growth. I never imagined that I would end up discussing demographics and growth with him. And another very fun thing was that something funny he said to me was that since we shared our vision regarding demographic issues and the need to populate the planet, he asked me, “Now, what about you? When are you going to move in that direction?” I said, “Oh, look, I have five children.” And he said, “Well, the four-legged ones don’t count.”"
            },
            {
                "speaker": "",
                "time": "(01:10:27)",
                "text": "That was the first meeting I had with Elon Musk. The second meeting was when, here at the universities, we started seeing anti-Semitic demonstrations where basically Palestinian flags were displayed and Jews were harassed and persecuted. And at that moment when we had that second meeting, he showed himself to be very deeply involved with that and brought up the issue of the cultural battle. So, I mean it’s not quite conventional, even in the political field."
            },
            {
                "speaker": "",
                "time": "(01:11:14)",
                "text": "During our last talk, which lasted for about two and a half hours, one of the things we talked about was freedom and what was at stake for the United States in this election. Therefore, he is a person, honestly. I can say he’s well above average. I mean a person of unconventional intelligence and also he’s very charming. So, I mean, again, I have a great admiration for him and I really interact very closely with him. He’s very interested in what our Ministry of Deregulation is doing, which seeks to remove regulations. But at the same time, he works with another person who is also interested in the chainsaw approach, and so I’m very pleased because they are going to try and replicate the model we are implementing in Argentina."
            },
            {
                "speaker": "",
                "time": "(01:12:21)",
                "text": "And also, Donald Trump himself is very enthusiastic about this and anything in the way of reducing regulations and cutting public spending and taking government out of the equation means more freedom for the people. So, I’m very pleased with what’s going on. And with Trump’s victory, because the United States will be better off, Argentina is going to be better too and the whole world is going to be better off. Today, the world is a much better place than it was just a few days ago."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:12:54)",
                "text": "Like you said, Elon and Vivek Ramaswamy are heading the DOGE, Department of Government Efficiency. So from your experience this year as president of Argentina and every chainsaw economic policies that you’ve implemented, what advice would you give to Elon and Vivek about how to do it in the United States?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:13:14)",
                "text": "Just cut to the chase. Cut to the chase. Simple as that. I’ll tell you a story and you’re going to love it. Currently in Argentina, due to the political balance we’ve achieved, we have had certain powers delegated from Congress to the executive branch, and therefore we can resolve it by decree that the deregulation minister, Federico Sturzenegger, in his ministry shows a counter that displays in front of everyone there. He displays the number of days, all right, during which the delegated powers will continue to be valid. Therefore, he has a whole deregulation division, also a public spending cut division, and government structure reduction division, and he also has an elite corps that’s cleaning up all of the laws that hinder the economic system and progress. And every day, he removes between one and five economic restrictions."
            },
            {
                "speaker": "",
                "time": "(01:14:24)",
                "text": "So, my advice would be for them to go all the way, to push it to the very limit, and do not give up. Do not let down their guard. Furthermore, that agenda does not have political purpose because at the end of the day, you are removing privileges. Of course, there will be people complaining, but those are people who are losing privileges, so they will have to explain society why they are keeping those privileges, and that is quite uncomfortable."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:14:57)",
                "text": "You’ve spoken with Donald Trump, allegedly he called you his favorite president. What did you discuss? And maybe, again, what do you admire about President Trump and what do you learn from him?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:15:10)",
                "text": "There are several things that I admire about President Trump. The first is that he probably… I think he’s provided ample proof of this in his first presidency. He understands the nature of the cultural battle. He has openly confronted socialism, his speeches openly target socialism, he perfectly understands the woke virus, and that is of great value because it means understanding what it’s all about."
            },
            {
                "speaker": "",
                "time": "(01:15:50)",
                "text": "Another thing I truly admire about him is his courage. In fact, thankfully, thank goodness he didn’t get assassinated or killed, but it was by a small chance occurrence that could have killed him just because he moved at the right moment. And yet, that didn’t intimidate him and he went on. And in fact, during his first campaign, and in this one as well, in the second one and third one, they criticized him, insulted him, offended him, said awful things about him, made up all sorts of horrible stories about him. In that respect, I can say I deeply relate because probably no one in our history has had such a negative campaign from all the media like they did to me. But let’s say they were quite similar."
            },
            {
                "speaker": "",
                "time": "(01:16:54)",
                "text": "This is why it’s so interesting, and I was so deeply moved when last night I also got to meet Sylvester Stallone, because Sylvester Stallone talks about, well, how important is that no matter how hard they hit you and keep on hitting you all the time, despite all that, you keep going on and on and on. What I’m trying to say is that so many of Sylvester Stallone’s approaches are truly inspirational, don’t you think? So imagine, I’m about to give the speech and I see Sylvester Stallone and Sylvester Stallone knows me. It was truly insane. I had to pinch myself. I mean this can’t be true."
            },
            {
                "speaker": "",
                "time": "(01:17:45)",
                "text": "And besides, well, the people were wonderful with me last night. They’ve been wonderful today. I’ve taken hundreds of selfies. I mean it’s truly been… I would say it’s been my break, let me say, after almost a year in office and having to face all sorts of media torture because the journalists who have vested interests and are corrupt are professional torturers. Yes, because they invade your personal life, your family, and your privacy. Let me tell you something to show you the kind of garbage the media in Argentina can do. They send three drones to spy on me at my presidential residence, to spy on me. Do you think that’s right?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:18:31)",
                "text": "No."
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:18:32)",
                "text": "Exactly. But that kind of thing happens in Argentina, not to mention the many lies and horrible things they say. I, for instance, remember that time when my father was hospitalized. My father is a man of a really strong character who has had two heart surgeries, all right? And one day, a journalist was saying all sorts of lies about my father. My father was hospitalized and he almost died of a heart attack. So that kind of thing is what journalism and the press do in Argentina. So they start to attack your private life, your mother, your father, your sister. Even my dogs that I absolutely adore, they are the most wonderful beings in the universe, they even target my four-legged children."
            },
            {
                "speaker": "",
                "time": "(01:19:24)",
                "text": "So, imagine that I’ve been in office for nearly a year, a year as president, and since they can’t criticize my management except by lying and distorting the numbers, they meddle with all these things, things they have been doing all the time since the year 2021 when I officially entered politics. And I’ve seen what they’ve done to Trump. So, that also makes me relate a lot to him because he’s a true warrior. He’s a Viking, he’s a Viking, he’s literally a Viking. I mean he’s someone I admire for how he has kept fighting in the face of adversity, even against all odds. And still he managed to win. Amazing."
            },
            {
                "speaker": "",
                "time": "(01:20:22)",
                "text": "And that’s why I can relate that much. And I’ve also seen how he’s been unfairly criticized, like when he was accused of protectionism or when he wanted to discuss some matters within the context of public debate regarding the design of monetary policy as regards to Fed. And basically, they have accused him of things. I mean isn’t he entitled to give an opinion as a president? I mean any citizen could give their opinion, even more so a president."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:20:56)",
                "text": "Why is it important to you that Argentina has a close relationship with the United States?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:21:03)",
                "text": "Well, to us, that is truly important, okay? Because we’ve decided to be geopolitical allies of the United States ever since our campaign, we have decided that our allies will be the United States and Israel because they basically represent the ideas of the western world, they represent the free world. That is to say, what we would call today, let’s say, a liberal democracy by confronting the autocrats. And in that sense, that is the geopolitical alignment."
            },
            {
                "speaker": "",
                "time": "(01:21:44)",
                "text": "Moreover, in our campaign, we were very, very clear on three main points. One, the economic pillar. We talked about cutting public spending and I would make my appearances with a chainsaw. We talked about economic freedom, deregulation, that is, and I talked about a competition of currencies, and people obviously were interested in the dollar. So, it was obvious that the economic policy was clear, all right? And not only was it clear, but we are also fulfilling it. That is the first point."
            },
            {
                "speaker": "",
                "time": "(01:22:17)",
                "text": "Second was our policy on security. The idea being to fight crime, I mean relentlessly as well as security, no mercy, right? And in fact, in Argentina, there are no more roadblocks, which they said were impossible to end. Not only that, we have strengthened the security forces and also our armed forces, and we are waging a tough battle against drug trafficking and narcoterrorism. Therefore, we are also strongly fulfilling that. Notice that these two points, which were the main concerns, they were the biggest concerns of Argentinians when we took office, are now in fifth and sixth place."
            },
            {
                "speaker": "",
                "time": "(01:22:59)",
                "text": "Today, the problem for Argentinians is corruption, whether there is unemployment, if there is poverty, but they don’t mention inflation and insecurity anymore. And besides, a third point that I made clear was that I would align with the United States and Israel internationally, and at my campaign rallies, there would be groups that would come along with flags of Israel. So, it’s clear that our international policy approach was always very clear and this is something I state during my speeches when I talk about the values of the west and the civilization of the west. In fact, yesterday, and even more so today during my speeches, I talked about how the different Greek groups or tribes go together to confront the Persians."
            },
            {
                "speaker": "",
                "time": "(01:23:58)",
                "text": "That is to say it seemed that from that time, 500 years before Christ until today, that struggle continues, right? But well, so of course we’re all in. We are betting on the United States becoming, once again a leader in the West. We needed someone to come back to make America great again. And as part of that process, being a commercial ally is also a great idea. So, we would really like to move forward and deepen our trade ties and our investment ties. And well, we would also like to be part of the NATO as well."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:24:52)",
                "text": "Do you think it’s still possible… One of the radical ideas you had as you were running for president was to dollarize the Argentine economy. Do you think that’s still a good idea? Are you still thinking about that?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:25:05)",
                "text": "Let’s see, let’s break it down. Let’s say, if you review all my statements, I talk about currency competition. I’m not strictly talking about dollarization, I’m talking about currency competition and eliminating the central bank. If people later decide to embrace the dollar, that is their choice. Ultimately, in the model I propose, what happens is the formation of a currency basket tailored to the needs of individuals."
            },
            {
                "speaker": "",
                "time": "(01:25:38)",
                "text": "But I won’t avoid the discussion. Today, there is currency competition. If, for instance, today in Argentina, you want to make transactions in any currency, you can do it and it’s allowed. Today there is currency competition. The other thing we talk about is the concept of, let’s suppose we were discussing dollarization. We talk about endogenous dollarization. The first point is that you need to clean up the central bank. We had to deal with the issue of the CIRA. That is the central bank’s commercial debt, which was $50 billion. We still have to resolve the dividend problem of $10 billion. And in the meantime, we did a write-off and cleaned up the central bank’s balance sheet by $45 billion. So, you can’t just close the central bank if it is bankrupt, because you need to redeem the whole central bank debt, which is about the issuing of money and the interest-bearing liabilities. So once we finished with the interest-bearing liabilities, it’ll leave us with the monetary base."
            },
            {
                "speaker": "",
                "time": "(01:26:40)",
                "text": "Therefore, today we have a regime where the amount of money is fixed, the monetary base is not growing, and as demand for money increases, since people can use dollars, they don’t need to go and sell the dollars and make the peso appreciate, but they can do transactions in dollars. So as the economy grows, you will have a greater share of dollars relative to pesos. And at some point, the amount of pesos compared to the dollars will be so huge relatively that closing down the central bank will be done easily, which means this is working."
            },
            {
                "speaker": "",
                "time": "(01:27:19)",
                "text": "Of course, if you were to give me the money right now, I would go ahead and dollarize. I’d have no problem with that. For example, I did have a proposal for this, and this could have worked, because the largest creditor of the Argentine treasury is the central bank, but central bank bonds were trading at 20 cents. If I had sold those bonds at 20 cents and nowadays they are trading between 60 and 70. With the whole bunch of Neanderthals that are the opposition, who besides being ignorant in economics, also have bad intentions, I would be in jail today."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:28:05)",
                "text": "Let me ask you a very important, difficult question. I’m a huge fan, have been my whole life, of Diego Maradona and Messi. So who, to you, is the greatest football player of all time?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:28:18)",
                "text": "The way I see it, I have seen Maradona play, all right? I saw Maradona play in the past, I used to watch him, and I saw him during his last year at Argentinos Juniors before Boca Juniors in the year 1980, and I saw him in ’81. Playing for Boca, I saw him play in the youth selection in Japan in 1979. I truly have immensely enjoyed the talent of Maradona, but without a doubt, the best soccer player of all time, not just from Argentina, of all time, even better than Pelé, is Messi, of course."
            },
            {
                "speaker": "",
                "time": "(01:29:04)",
                "text": "There is an article, which is quite old already now, titled Messi is Impossible. And it looks at all of the positions a soccer player plays in, that is all positions a soccer player can play in from midfield forward. And the most incredible thing is that Messi is the best in each of those positions. You can be the best in one or two positions. You see Cristiano Ronaldo, for example, was very good in two areas of the game. So much so that he was almost like Messi, but he didn’t take part in the rest. However, Messi is the best one in all respects. But at that time, of course. Nowadays, he’s an older player, right?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:30:00)",
                "text": "He is an older player, right? And I’m not sure whether he can still keep that performance on all fronts, but honestly, I have never in my life seen a player like Messi. I have never seen no one like him, for real. Considering the goal average in the days of Pelé compared to Messi’s golden era and his career now, the number of equivalent goals is much greater than that of Pelé, therefore, without a doubt, Messi is the greatest soccer player of all time. No one compares to him."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:44)",
                "text": "But it’s not just the numbers or the World Cup win, it’s the moments of genius on the field. Messi is unlike any other in that way."
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:30:56)",
                "text": "Messi does things that seem technically impossible, they seem physically impossible. The moves he makes don’t respect human logic. It’s like watching Usain Bolt run. It doesn’t feel possible. He moves in a way that doesn’t respect human logic, am I right?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:31:16)",
                "text": "Did you watch the 1986 World Cup with Maradona, with the hand of God, with the game against England? What was that like?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:31:24)",
                "text": "Oh, yes, I do remember that very well. We watched it in the home of my godfather and saw how he did his gambit and dodged the England team. It was absolutely indescribable. There’s no way to put it into words. It’s as if I asked you to describe for me the love you have for your partner. You can’t do that, right? It’s something wonderful. You can’t describe it, you cannot put it into words. There are things where words just seem to fail, am I right? I really think that there are times when humans, or some humans, not all of them, actually. Some humans have the privilege of being able to vibrate closer to God."
            },
            {
                "speaker": "",
                "time": "(01:32:35)",
                "text": "Some Puccini arias, for example, when you listen to them, when you listen to the famous aria from La Rondine, or the famous aria from Gianni Schicchi, you get the feeling that he was getting sat dictated by God. How can you put that into words? You can’t. There’s no way you do that. Those moments where we humans, that we have the privilege, I say it as human beings, because I’m speaking from that perspective. I say this only as an admirer."
            },
            {
                "speaker": "",
                "time": "(01:33:14)",
                "text": "Some human beings have the ability to vibrate so close to God that you can’t describe it, you can only enjoy it. This is why, in Judaism, they don’t use the name of God, of the Creator, because how could you put in words something like that? And I believe those are times when us humans connect closer to the Creator and create unique things, you cannot describe them. There are no words to describe that. The only thing you can do is enjoy it and be thankful that you can witness it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:33:56)",
                "text": "You were a great footballer yourself in your youth. You were a goalkeeper. Many people would say that’s the toughest and the most important position in football. Maybe you could speak about that experience and, in general, what’s harder; being a goalkeeper or president?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:34:13)",
                "text": "Lovely question. Well, indeed, I used to be a goalkeeper, but I’m not so sure about whether I was any good. But the experience of having been a goalkeeper is very valuable. First, the goalkeeper is the only player that can use their hands, in a certain sector of the pitch in the area. The other thing is that he’s also the only player who dresses differently. Moreover, their training is a solitary one. And the most important, it is the very climax, the goal, right? When the goal is called by their team, everyone is celebrating on the other side and the goalkeeper is on his own."
            },
            {
                "speaker": "",
                "time": "(01:35:18)",
                "text": "And at the same time, he’s the one who suffers the most when a goal is scored, because he gets the direct impact. In fact, when the goalkeeper makes a mistake, it’s an own goal. Imagine a teammate scores a wonderful goal like the one Maradona did. It’s marvelous. And that’s just one goal. And imagine the goalkeeper picks up the ball, and then, if they bring it into the area wrongly, it’s like two goals, it’s a complete lack of proportion. So, therefore, and this, in my opinion, makes goalkeepers have a very strong temperament."
            },
            {
                "speaker": "",
                "time": "(01:36:03)",
                "text": "They’re used to being alone, and power is precisely that. Because when you make decisions, you are on your own. And not just that, but also when you have a responsibility, like that of a president, when you make a decision, it has an impact on millions of people. So just like goalkeepers, if you make a mistake and score an own goal, and in this context it’s negative consequences for millions of people. Therefore, that has been part of the university of life that has given me the tools to be president today. That is my training in economics, my training in liberalism, having been a goalkeeper, and also having had a very tough childhood."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:36:59)",
                "text": "How hard is it? What’s been the personal toll of carrying the hope of a nation on your shoulders?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:37:07)",
                "text": "Well, being defamed, insulted, and attacked every single day, but again, there’s no point in life if it’s not with freedom. So, like Sylvester Stallone once said, “The secret to life is to carry on in spite of the blows you get, the punches you take.” And fortunately, we have been able to carry on in spite of the blows, both coming at us from in front and from behind our backs, because it have been more honest if we had been attacked directly. But well, in Argentina politics and the mass media, they do love to attack behind your back."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:37:57)",
                "text": "What role has God played in your life? And who is God?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:38:04)",
                "text": "Well, faith, I’d say, has been a very fundamental element. And especially in recent times, during which I’ve become actively involved, particularly in the teachings of Judaism and in the study of the Torah. This has given me, let’s say, a huge background to face the many adversities which I’ve encountered and had to overcome in the last few years. And as to who God is, He’s the Creator, the Maker. I call Him, The One."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:38:54)",
                "text": "What is a better guide for humanity; the invisible hand of the market or the hand of God?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:39:00)",
                "text": "They’re perfectly in sync."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:39:03)",
                "text": "Well enough. Again, going back to your youth, you were a lead singer in a rock band. Who’s the greatest rock star of all time?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:39:12)",
                "text": "Okay. Well, the way I see it, the most amazing rock singer in history of mankind was definitely Elvis Presley. And my favorite band is the Rolling Stones. So I also greatly admire Mick Jagger, and I still have this dream of getting to meet him in person."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:39:38)",
                "text": "How fun would it be to play together with the Stones?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:39:45)",
                "text": "That would be a big, big dream. Don’t get my hopes up, because I set goals and then I go and achieve them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:39:55)",
                "text": "Well, I’m close friends with a band that opens for the Stones, so I would love to see this happen."
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:40:00)",
                "text": "Oh, well, that would be great. Or we could also watch the whole concert from the stage. I can’t keep ruining the Rolling Stones’ music. I already had a tribute band and did quite a lot of damage to their music."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:40:16)",
                "text": "How much does your rock star roots define your approach to politics, to life? Do you see yourself as a showman in part?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:40:25)",
                "text": "Of course. Absolutely. My idea is that, when you attend one of our events, it feels like going to a Rolling Stones concert. In fact, in one of my most recent performances at Luna Park, I even had the pleasure of singing in front of 10,000 people. It’s on YouTube. No, sorry, not on YouTube, it’s on my Instagram feed. At that event, I sang a song called Panic Show, and the song starts by saying, “Hi, everybody. I am the lion.”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:41:06)",
                "text": "Your intensity and passion have earned you the nickname El Loco, the madman. Do you think some madness is necessary to challenge the powerful establishment?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:41:19)",
                "text": "Well, maybe it’s a matter of perspective. It could be the other way around, that everyone else is crazy by living in a way contrary to the ideas of freedom. And so, maybe the sane person who wants to fix that is then considered a madman. Anyway, the nickname doesn’t bother me at all. In fact, I even enjoy it, because I’ve been called like that since I was 10 years old, so it’s not something that particularly bothers me, because it’s a nickname that… Well, it has been used for many years, but actually, if I present to you the case of San Martin, when he said he was going to cross the Andes to liberate not only Argentina, not only our country, but also Chile and Peru, and people called him crazy."
            },
            {
                "speaker": "",
                "time": "(01:42:13)",
                "text": "Imagine if you had tried and spoken with, I don’t know, Michelangelo, you would have called him crazy too. Or if you had talked to, I don’t know, hundreds of people who have changed the world, surely they would have thought that Einstein was crazy and so on, the list would be infinite. So, what is the difference between a madman and a genius? Success."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:42:45)",
                "text": "Let me ask you about the market. It’s so interesting, from your view of the world, how powerful the market is at figuring out what’s best for society. Why do you think the market works so well as a guide for humanity?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:43:03)",
                "text": "One must first understand what the market is. Simply put, the market is a process of voluntary exchange, where individuals cooperate through the transfer of property rights, in which private property is upheld. This is the system that drives the allocation of resources. In essence, socialism, and this is what Mises condemns in his book, Socialism, shows that without private property, prices cease to exist and therefore resources are diverted. Why don’t you think it’s the same to make a road of asphalt or gold? Why not make it of gold? Because you have an understanding of economic calculation, you have an idea of prices in your mind. So, in this context, if there is no private property, there are no prices, and as a result, the free market capitalism is the best mechanism ever developed by humankind for resource allocation."
            },
            {
                "speaker": "",
                "time": "(01:44:13)",
                "text": "This also implies that markets must be free. Free from state intervention, because when the state intervenes, it creates interference. And markets need to allow free entry and exit, what we call competition. However, it’s better to understand competition in the sense described by Israel Gerstner, one of the foremost figures of the Austrian school. Or in the neoclassical framework as William Baumel understood it, which was the concept of free entry and exit in so-called contestable markets. And also, let’s talk about what pertains to the division of labor and social co-operation."
            },
            {
                "speaker": "",
                "time": "(01:44:57)",
                "text": "The most wonderful thing about capitalism is that you can only be successful by serving others with better quality goods at a better price. If you are successful in the free market capitalism, you are a hero, you are a social benefactor, you are a prosperity machine. So the better you do, the better it is for society. This is very important. I remember when I had my first meeting with Elon Musk, and this made me admire him greatly, and this is something my sister commented on too."
            },
            {
                "speaker": "",
                "time": "(01:45:38)",
                "text": "Elon Musk told me something he does every day. He wakes up every morning thinking about what problem he could fix for humanity. That’s amazing. Of course, what is the counterpart? Being successful. Therefore, in that sense, and moreover in my view on how the system works, on how the market works, market failures do not exist. That is to say, that is a problem. A problem for neoclassical economies because of the mathematical tools they’ve used to develop economic analysis. But actually, it’s not a real issue in everyday life, it’s a problem in the minds of economists. In fact, my latest book called Capitalism, Socialism, and the Neoclassical Trap deals precisely with this issue."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:46:40)",
                "text": "Yeah, you’ve outlined these ideas in Capitalism, Socialism, and the Neoclassical Trap. So the trap is that there’s no such thing as a middle ground. It’s either capitalism, socialism, and every middle ground ends up in a state of socialism."
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:46:55)",
                "text": "Well, actually, that is what Mises said. He said that there are only two systems; free enterprise capitalism and socialism. And he also pointed out, and this is proven in Hayek’s book, the Road to Serfdom, that any middle ground solution is unstable in terms of capitalism, meaning it tends towards socialism. So when you implement an intervention, it causes government failure, which then triggers further intervention, setting up a trap that results in more and more intervention. And in this context, the neoclassicals, with their market failure theory, are in fact dealing with problems that are fundamentally mathematical. Rather than making the world a better place, they have, if you will, been instrumental in increasing the levels of intervention. Let me tell you something."
            },
            {
                "speaker": "",
                "time": "(01:47:51)",
                "text": "Well, I have an economist as chairman of the President’s Advisory Council, Dr. Demian Reidel, who studied here at Harvard University and completed his PhD, was mentored by Kenneth Rogoff, the American economist. And Rogoff has said that Dr. Reidel was his best student. Nowadays, we’re actually working with Dr. Reidel specifically on all these issues that arise from the interventions proposed by the mainstream, such as the so-called correction of market failures. And a few days ago, he conducted a survey of search algorithms and policy recommendations, and that resulted in a map painted from red to blue."
            },
            {
                "speaker": "",
                "time": "(01:49:03)",
                "text": "And well, the redder it was, the more it was linked to socialism, there was an intermediate thing that was yellow, and blue was free market ideas. And one of the things he discovered, as part of that graph or chart, was that the largest number of policy recommendations, scandalously, are actually left-leaning. So that is the empirical evidence of what I pointed out in the book, Capitalism, Socialism, and the Neoclassical Trap."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:49:46)",
                "text": "You mentioned your four-legged children. What have you learned about life from your dogs?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:49:54)",
                "text": "Well, from my four-legged children, I have learned unconditional love. In fact, well, my name in Hebrew means loyal friend, faithful friend, and on the Chinese horoscope, I am dog. And if there’s one thing that defines me is loyalty, being decent. And those virtues, you can find them in those wonderful beings that dogs are, who love unconditionally. In fact, they are superior beings, spiritually speaking in my case, because I don’t forget or forgive those who have harmed me. That is to say, all those who have insulted, defamed me, and criticized me, I remember each one of them, but I don’t have the greatness needed to forgive them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:51:04)",
                "text": "On the topic of loyalty in politics, I’m sure there’s been a lot of people, some people, who have betrayed you. Does that hurt your heart?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:51:17)",
                "text": "It depends, because you sometimes think that you can expect some people to be loyal, and if they betray you, of course that hurts. But some people, you actually don’t expect anything from them, so if there’s betrayal, you won’t be annoyed or feel bad, because you owe it to someone who didn’t share your values. But politics does have that. Sometimes, many of the people you may come across don’t have the values you advocate for, but it’s cost benefit. You need to let the ship sail on. Or would you rather let it sink? That’s not my case. I fight until the end. There are traitors, but that’s part of politics. And that’s not my line, but of course, they do exist."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:52:23)",
                "text": "There are a lot of people who admire your revolutionary spirit. What advice would you give them, maybe young people, on how to live a life like yours and have an impact on the world, like you have begun to do?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:52:40)",
                "text": "I didn’t do this thinking about having an impact on the world. I have defined what makes me happy and I live according to that. I live consistently by that. And most importantly, I would say never give up. Moreover, and above all, never be half-hearted. I would rather cry because I failed, rather than not crying because I never tried. I’m a perfectionist, so when I do err, of course, I have a bad time. But still, I prefer to go and get things done. If it goes wrong, it’s part of life, but I will never have to regret not having done what I thought needed to be done at that moment."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:53:50)",
                "text": "What gives you hope about the future of Argentina and the future of humanity?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:53:56)",
                "text": "Well, the fact that, thanks to social media and to the whole tech revolution going on, every day, more and more people are becoming aware of how important freedom is to live. To live in peace and prosperity. And I believe, even though bureaucrats and the elites fight untiringly to enslave us, a wave of freedom has been unleashed, which, if we do wage the fight, we’ll have a much better world."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:54:42)",
                "text": "What does your famous words of viva la libertad… How did that come about and what does it mean to you?"
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:54:49)",
                "text": "Long live freedom, dammit. That first started while I was giving my book presentations. At the end of my presentation, I would say, “Viva la libertad, carajo,” and that really stuck with me since then. Without thinking about it, throughout my life, it was going to continue being present. In fact, today, my presentations, all of my speeches end with, “May God bless the Argentinians. May the forces of heaven be with us. And viva la libertad, carajo.” The first phrase reflects my faith in God, fervently, and that I’m deeply thankful to the Creator for the wonderful things He has bestowed upon me daily. The second one has to do with a quote from the book of Maccabees 3:19, which says that “victory in battle doesn’t depend on the size of the army, but on the forces of heaven.” This has to do with the victory of the Jewish people, the Maccabeans, against the Greeks and how they recovered the temple. And the last one, well, is my war cry."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:56:15)",
                "text": "Well, there’s no better way to end it. Thank you for being a warrior for freedom, and thank you for talking today."
            },
            {
                "speaker": "Javier Milei",
                "time": "(01:56:21)",
                "text": "Thank you very much indeed for your interview. And thank you for being so well-educated, because very often interviewers are not like that. And you did have windows to play foul and you didn’t, and I recognize that and I thank you for that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:56:37)",
                "text": "Thank you."
            },
            {
                "speaker": "",
                "time": "(01:56:39)",
                "text": "Thanks for listening to this conversation with Javier Milei. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from George Orwell. “In a time of deceit, telling the truth is a revolutionary act.” Thank you for listening and hope to see you next time."
            }
        ]
    },
    {
        "title": "Anthropic CEO on Claude, AGI & the Future of AI & Humanity",
        "guest": "Dario Amodei",
        "thumbnail": "https://lexfridman.com/files/thumbs_ai_podcast/dario_amodei.png",
        "video_link": "https://www.youtube.com/watch?v=ugvHCXCOmm4",
        "episode_link": "https://lexfridman.com/dario-amodei",
        "transcript_link": "https://lexfridman.com/dario-amodei-transcript",
        "timestamps": [
            {
                "time": "0:00",
                "chapter": "Introduction"
            },
            {
                "time": "3:14",
                "chapter": "Scaling laws"
            },
            {
                "time": "12:20",
                "chapter": "Limits of LLM scaling"
            },
            {
                "time": "20:45",
                "chapter": "Competition with OpenAI, Google, xAI, Meta"
            },
            {
                "time": "26:08",
                "chapter": "Claude"
            },
            {
                "time": "29:44",
                "chapter": "Opus 3.5"
            },
            {
                "time": "34:30",
                "chapter": "Sonnet 3.5"
            },
            {
                "time": "37:50",
                "chapter": "Claude 4.0"
            },
            {
                "time": "42:02",
                "chapter": "Criticism of Claude"
            },
            {
                "time": "54:49",
                "chapter": "AI Safety Levels"
            },
            {
                "time": "1:05:37",
                "chapter": "ASL-3 and ASL-4"
            },
            {
                "time": "1:09:40",
                "chapter": "Computer use"
            },
            {
                "time": "1:19:35",
                "chapter": "Government regulation of AI"
            },
            {
                "time": "1:38:24",
                "chapter": "Hiring a great team"
            },
            {
                "time": "1:47:14",
                "chapter": "Post-training"
            },
            {
                "time": "1:52:39",
                "chapter": "Constitutional AI"
            },
            {
                "time": "1:58:05",
                "chapter": "Machines of Loving Grace"
            },
            {
                "time": "2:17:11",
                "chapter": "AGI timeline"
            },
            {
                "time": "2:29:46",
                "chapter": "Programming"
            },
            {
                "time": "2:36:46",
                "chapter": "Meaning of life"
            },
            {
                "time": "2:42:53",
                "chapter": "Amanda Askell"
            },
            {
                "time": "2:45:21",
                "chapter": "Programming advice for non-technical people"
            },
            {
                "time": "2:49:09",
                "chapter": "Talking to Claude"
            },
            {
                "time": "3:05:41",
                "chapter": "Prompt engineering"
            },
            {
                "time": "3:14:15",
                "chapter": "Post-training"
            },
            {
                "time": "3:18:54",
                "chapter": "Constitutional AI"
            },
            {
                "time": "3:23:48",
                "chapter": "System prompts"
            },
            {
                "time": "3:29:54",
                "chapter": "Is Claude getting dumber?"
            },
            {
                "time": "3:41:56",
                "chapter": "Character training"
            },
            {
                "time": "3:42:56",
                "chapter": "Nature of truth"
            },
            {
                "time": "3:47:32",
                "chapter": "Optimal rate of failure"
            },
            {
                "time": "3:54:43",
                "chapter": "AI consciousness"
            },
            {
                "time": "4:09:14",
                "chapter": "AGI"
            },
            {
                "time": "4:17:52",
                "chapter": "Chris Olah"
            },
            {
                "time": "4:22:44",
                "chapter": "Features, Circuits, Universality"
            },
            {
                "time": "4:40:17",
                "chapter": "Superposition"
            },
            {
                "time": "4:51:16",
                "chapter": "Monosemanticity"
            },
            {
                "time": "4:58:08",
                "chapter": "Scaling Monosemanticity"
            },
            {
                "time": "5:06:56",
                "chapter": "Macroscopic behavior of neural networks"
            },
            {
                "time": "5:11:50",
                "chapter": "Beauty of neural networks"
            }
        ],
        "transcript": [
            {
                "speaker": "Dario Amodei",
                "time": "(00:00:00)",
                "text": "If you extrapolate the curves that we’ve had so far, right? If you say, “Well, I don’t know, we’re starting to get to PhD level, and last year we were at undergraduate level, and the year before we were at the level of a high school student,” again, you can quibble with what tasks and for what. “We’re still missing modalities, but those are being added,” like computer use was added, like image generation has been added. If you just kind of eyeball the rate at which these capabilities are increasing, it does make you think that we’ll get there by 2026 or 2027."
            },
            {
                "speaker": "",
                "time": "(00:00:31)",
                "text": "I think there are still worlds where it doesn’t happen in 100 years. The number of those worlds is rapidly decreasing. We are rapidly running out of truly convincing blockers, truly compelling reasons why this will not happen in the next few years. The scale-up is very quick. We do this today, we make a model, and then we deploy thousands, maybe tens of thousands of instances of it. I think by the time, certainly within two to three years, whether we have these super powerful AIs or not, clusters are going to get to the size where you’ll be able to deploy millions of these."
            },
            {
                "speaker": "",
                "time": "(00:01:03)",
                "text": "I am optimistic about meaning. I worry about economics and the concentration of power. That’s actually what I worry about more, the abuse of power."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:01:14)",
                "text": "And AI increases the amount of power in the world. And if you concentrate that power and abuse that power, it can do immeasurable damage."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:01:22)",
                "text": "Yes, it’s very frightening. It’s very frightening."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:01:27)",
                "text": "The following is a conversation with Dario Amodei, CEO of Anthropic, the company that created Claude, that is currently and often at the top of most LLM benchmark leader boards. On top of that, Dario and the Anthropic team have been outspoken advocates for taking the topic of AI safety very seriously. And they have continued to publish a lot of fascinating AI on this and other topics."
            },
            {
                "speaker": "",
                "time": "(00:01:55)",
                "text": "I’m also joined afterwards by two other brilliant people from Anthropic. First Amanda Askell, who is a researcher working on alignment and fine-tuning of Claude, including the design of Claude’s character and personality. A few folks told me she has probably talked with Claude more than any human at Anthropic. So she was definitely a fascinating person to talk to about prompt engineering and practical advice on how to get the best out of Claude."
            },
            {
                "speaker": "",
                "time": "(00:02:27)",
                "text": "After that, Chris Olah stopped by for a chat. He’s one of the pioneers of the field of mechanistic interpretability, which is an exciting set of efforts that aims to reverse engineering neural networks, to figure out what’s going on inside, inferring behaviors from neural activation patterns inside the network. This is a very promising approach for keeping future super-intelligent AI systems safe. For example, by detecting from the activations when the model is trying to deceive the human it is talking to."
            },
            {
                "speaker": "",
                "time": "(00:03:03)",
                "text": "This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Dario Amodei."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:03:14)",
                "text": "Let’s start with a big idea of scaling laws and the scaling hypothesis. What is it? What is its history, and where do we stand today?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:03:22)",
                "text": "So I can only describe it as it relates to my own experience, but I’ve been in the AI field for about 10 years and it was something I noticed very early on. So I first joined the AI world when I was working at Baidu with Andrew Ng in late 2014, which is almost exactly 10 years ago now. And the first thing we worked on, was speech recognition systems. And in those days I think deep learning was a new thing. It had made lots of progress, but everyone was always saying, “We don’t have the algorithms we need to succeed. We are only matching a tiny fraction. There’s so much we need to discover algorithmically. We haven’t found the picture of how to match the human brain.”"
            },
            {
                "speaker": "",
                "time": "(00:04:05)",
                "text": "And in some ways it was fortunate, you can have almost beginner’s luck. I was like a newcomer to the field. And I looked at the neural net that we were using for speech, the recurrent neural networks, and I said, “I don’t know, what if you make them bigger and give them more layers? And what if you scale up the data along with this?” I just saw these as independent dials that you could turn. And I noticed that the models started to do better and better as you gave them more data, as you made the models larger, as you trained them for longer. And I didn’t measure things precisely in those days, but along with colleagues, we very much got the informal sense that the more data and the more compute and the more training you put into these models, the better they perform."
            },
            {
                "speaker": "",
                "time": "(00:04:51)",
                "text": "And so initially my thinking was, “Hey, maybe that is just true for speech recognition systems. Maybe that’s just one particular quirk, one particular area.” I think it wasn’t until 2017 when I first saw the results from GPT-1 that it clicked for me that language is probably the area in which we can do this. We can get trillions of words of language data, we can train on them. And the models we were trained in those days were tiny. You could train them on one to eight GPUs, whereas now we train jobs on tens of thousands, soon going to hundreds of thousands of GPUs."
            },
            {
                "speaker": "",
                "time": "(00:05:28)",
                "text": "And so when I saw those two things together, and there were a few people like Ilya Sudskever who you’ve interviewed, who had somewhat similar views. He might’ve been the first one, although I think a few people came to similar views around the same time, right? There was Rich Sutton’s bitter lesson, Gwern wrote about the scaling hypothesis. But I think somewhere between 2014 and 2017 was when it really clicked for me, when I really got conviction that, “Hey, we’re going to be able to these incredibly wide cognitive tasks if we just scale up the models.”"
            },
            {
                "speaker": "",
                "time": "(00:06:03)",
                "text": "And at every stage of scaling, there are always arguments. And when I first heard them honestly, I thought, “Probably I’m the one who’s wrong and all these experts in the field are right. They know the situation better than I do, right?” There’s the Chomsky argument about, “You can get syntactics but you can’t get semantics.” There was this idea, “Oh, you can make a sentence make sense, but you can’t make a paragraph make sense.” The latest one we have today is, “We’re going to run out of data, or the data isn’t high quality enough or models can’t reason.”"
            },
            {
                "speaker": "",
                "time": "(00:06:34)",
                "text": "And each time, every time, we manage to either find a way around or scaling just is the way around. Sometimes it’s one, sometimes it’s the other. And so I’m now at this point, I still think it’s always quite uncertain. We have nothing but inductive inference to tell us that the next two years are going to be like the last 10 years. But I’ve seen the movie enough times, I’ve seen the story happen for enough times to really believe that probably the scaling is going to continue, and that there’s some magic to it that we haven’t really explained on a theoretical basis yet."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:07:10)",
                "text": "And of course the scaling here is bigger networks, bigger data, bigger compute?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:07:16)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:07:17)",
                "text": "All of those?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:07:17)",
                "text": "In particular, linear scaling up of bigger networks, bigger training times and more and more data. So all of these things, almost like a chemical reaction, you have three ingredients in the chemical reaction and you need to linearly scale up the three ingredients. If you scale up one, not the others, you run out of the other reagents and the reaction stops. But if you scale up everything in series, then the reaction can proceed."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:07:45)",
                "text": "And of course now that you have this kind of empirical science/art, you can apply it to other more nuanced things like scaling laws applied to interpretability or scaling laws applied to post-training. Or just seeing how does this thing scale. But the big scaling law, I guess the underlying scaling hypothesis has to do with big networks, big data leads to intelligence?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:08:09)",
                "text": "Yeah, we’ve documented scaling laws in lots of domains other than language. So initially the paper we did that first showed it, was in early 2020, where we first showed it for language. There was then some work late in 2020 where we showed the same thing for other modalities like images, video, text to image, image to text, math. They all had the same pattern. And you’re right, now there are other stages like post-training or there are new types of reasoning models. And in all of those cases that we’ve measured, we see similar types of scaling laws."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:08:48)",
                "text": "A bit of a philosophical question, but what’s your intuition about why bigger is better in terms of network size and data size? Why does it lead to more intelligent models?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:09:00)",
                "text": "So in my previous career as a biophysicist… So I did a physics undergrad and then biophysics in grad school. So I think back to what I know as a physicist, which is actually much less than what some of my colleagues at Anthropic have in terms of expertise in physics. There’s this concept called the one over F noise and one over X distributions, where often, just like if you add up a bunch of natural processes, you get a Gaussian, if you add up a bunch of differently-distributed natural processes… If you take a probe and hook it up to a resistor, the distribution of the thermal noise in the resistor goes as one over the frequency. It’s some kind of natural convergent distribution."
            },
            {
                "speaker": "",
                "time": "(00:09:50)",
                "text": "And I think what it amounts to, is that if you look at a lot of things that are produced by some natural process that has a lot of different scales, not a Gaussian, which is kind of narrowly distributed, but if I look at large and small fluctuations that lead to electrical noise, they have this decaying one over X distribution. And so now I think of patterns in the physical world or in language. If I think about the patterns in language, there are some really simple patterns, some words are much more common than others, like the. Then there’s basic noun-verb structure. Then there’s the fact that nouns and verbs have to agree, they have to coordinate. And there’s the higher-level sentence structure. Then there’s the thematic structure of paragraphs. And so the fact that there’s this regressing structure, you can imagine that as you make the networks larger, first they capture the really simple correlations, the really simple patterns, and there’s this long tail of other patterns."
            },
            {
                "speaker": "",
                "time": "(00:10:49)",
                "text": "And if that long tail of other patterns is really smooth like it is with the one over F noise in physical processes like resistors, then you can imagine as you make the network larger, it’s kind of capturing more and more of that distribution. And so that smoothness gets reflected in how well the models are at predicting and how well they perform."
            },
            {
                "speaker": "",
                "time": "(00:11:10)",
                "text": "Language is an evolved process. We’ve developed language, we have common words and less common words. We have common expressions and less common expressions. We have ideas, cliches, that are expressed frequently, and we have novel ideas. And that process has developed, has evolved with humans over millions of years. And so the guess, and this is pure speculation, would be that there’s some kind of long tail distribution of the distribution of these ideas."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:11:41)",
                "text": "So there’s the long tail, but also there’s the height of the hierarchy of concepts that you’re building up. So the bigger the network, presumably you have a higher capacity to-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:11:50)",
                "text": "Exactly. If you have a small network, you only get the common stuff. If I take a tiny neural network, it’s very good at understanding that a sentence has to have verb, adjective, noun, but it’s terrible at deciding what those verb adjective and noun should be and whether they should make sense. If I make it just a little bigger, it gets good at that, then suddenly it’s good at the sentences, but it’s not good at the paragraphs. And so these rarer and more complex patterns get picked up as I add more capacity to the network."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:12:20)",
                "text": "Well, the natural question then is what’s the ceiling of this?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:12:24)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:12:24)",
                "text": "How complicated and complex is the real world? How much is the stuff is there to learn?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:12:30)",
                "text": "I don’t think any of us knows the answer to that question. My strong instinct would be that there’s no ceiling below the level of humans. We humans are able to understand these various patterns. And so that makes me think that if we continue to scale up these models to kind of develop new methods for training them and scaling them up, that will at least get to the level that we’ve gotten to with humans. There’s then a question of how much more is it possible to understand than humans do? How much is it possible to be smarter and more perceptive than humans? I would guess the answer has got to be domain-dependent."
            },
            {
                "speaker": "",
                "time": "(00:13:09)",
                "text": "If I look at an area like biology, and I wrote this essay, Machines of Loving Grace, it seems to me that humans are struggling to understand the complexity of biology. If you go to Stanford or to Harvard or to Berkeley, you have whole departments of folks trying to study the immune system or metabolic pathways, and each person understands only a tiny bit, a part of it, specializes. And they’re struggling to combine their knowledge with that of other humans. And so I have an instinct that there’s a lot of room at the top for AIs to get smarter."
            },
            {
                "speaker": "",
                "time": "(00:13:46)",
                "text": "If I think of something like materials in the physical world, or addressing conflicts between humans or something like that, I mean it may be there’s only some of these problems are not intractable, but much harder. And it may be that there’s only so well you can do at some of these things. Just like with speech recognition, there’s only so clear I can hear your speech. So I think in some areas there may be ceilings that are very close to what humans have done. In other areas, those ceilings may be very far away. I think we’ll only find out when we build these systems. It’s very hard to know in advance. We can speculate, but we can’t be sure."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:14:26)",
                "text": "And in some domains, the ceiling might have to do with human bureaucracies and things like this, as you write about."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:14:31)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:14:31)",
                "text": "So humans fundamentally has to be part of the loop. That’s the cause of the ceiling, not maybe the limits of the intelligence."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:14:38)",
                "text": "Yeah, I think in many cases, in theory, technology could change very fast. For example, all the things that we might invent with respect to biology, but remember, there’s a clinical trial system that we have to go through to actually administer these things to humans. I think that’s a mixture of things that are unnecessary in bureaucratic and things that kind of protect the integrity of society. And the whole challenge is that it’s hard to tell what’s going on. It’s hard to tell which is which."
            },
            {
                "speaker": "",
                "time": "(00:15:11)",
                "text": "I think in terms of drug development, my view is that we’re too slow and we’re too conservative. But certainly if you get these things wrong, it’s possible to risk people’s lives by being too reckless. And so at least some of these human institutions are in fact protecting people. So it’s all about finding the balance. I strongly suspect that balance is kind of more on the side of wishing to make things happen faster, but there is a balance."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:15:39)",
                "text": "If we do hit a limit, if we do hit a slowdown in the scaling laws, what do you think would be the reason? Is it compute-limited, data-limited? Is it something else? Idea limited?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:15:51)",
                "text": "So a few things, now we’re talking about hitting the limit before we get to the level of humans and the skill of humans. So I think one that’s popular today, and I think could be a limit that we run into, like most of the limits, I would bet against it, but it’s definitely possible, is we simply run out of data. There’s only so much data on the internet, and there’s issues with the quality of the data. You can get hundreds of trillions of words on the internet, but a lot of it is repetitive or it’s search engine optimization drivel, or maybe in the future it’ll even be text generated by AIs itself. And so I think there are limits to what can be produced in this way."
            },
            {
                "speaker": "",
                "time": "(00:16:34)",
                "text": "That said, we, and I would guess other companies, are working on ways to make data synthetic, where you can use the model to generate more data of the type that you have already, or even generate data from scratch. If you think about what was done with DeepMind’s AlphaGo Zero, they managed to get a bot all the way from no ability to play Go whatsoever to above human level, just by playing against itself. There was no example data from humans required in the AlphaGo Zero version of it."
            },
            {
                "speaker": "",
                "time": "(00:17:07)",
                "text": "The other direction of course, is these reasoning models that do chain of thought and stop to think and reflect on their own thinking. In a way that’s another kind of synthetic data coupled with reinforcement learning. So my guess is with one of those methods, we’ll get around the data limitation or there may be other sources of data that are available. We could just observe that, even if there’s no problem with data, as we start to scale models up, they just stopped getting better. It seemed to be a reliable observation that they’ve gotten better, that could just stop at some point for a reason we don’t understand."
            },
            {
                "speaker": "",
                "time": "(00:17:43)",
                "text": "The answer could be that we need to invent some new architecture. There have been problems in the past with say, numerical stability of models where it looked like things were leveling off, but actually when we found the right unblocker, they didn’t end up doing so. So perhaps there’s some new optimization method or some new technique we need to unblock things. I’ve seen no evidence of that so far, but if things were to slow down, that perhaps could be one reason."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:18:15)",
                "text": "What about the limits of compute, meaning the expensive nature of building bigger and bigger data centers?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:18:23)",
                "text": "So right now, I think most of the frontier model companies, I would guess, are operating in roughly 1 billion scale, plus or minus a factor of three. Those are the models that exist now or are being trained now. I think next year we’re going to go to a few billion, and then 2026, we may go to above 10 billion. And probably by 2027, their ambitions to build hundred billion dollar clusters. And I think all of that actually will happen. There’s a lot of determination to build the compute, to do it within this country, and I would guess that it actually does happen."
            },
            {
                "speaker": "",
                "time": "(00:19:02)",
                "text": "Now, if we get to a hundred billion, that’s still not enough compute, that’s still not enough scale, then either we need even more scale, or we need to develop some way of doing it more efficiently of shifting the curve. I think between all of these, one of the reasons I’m bullish about powerful AI happening so fast, is just that if you extrapolate the next few points on the curve, we’re very quickly getting towards human level ability."
            },
            {
                "speaker": "",
                "time": "(00:19:28)",
                "text": "Some of the new models that we developed, some reasoning models that have come from other companies, they’re starting to get to what I would call the PhD or professional level. If you look at their coding ability, the latest model we released, Sonnet 3.5, the new or updated version, it gets something like 50% on SWE-bench. And SWE-bench is an example of a bunch of professional real-world software engineering tasks. At the beginning of the year, I think the state of the art was 3 or 4%. So in 10 months we’ve gone from 3% to 50% on this task. And I think in another year we’ll probably be at 90%. I mean, I don’t know, but might even be less than that."
            },
            {
                "speaker": "",
                "time": "(00:20:11)",
                "text": "We’ve seen similar things in graduate-level math, physics, and biology from models like OpenAi’s o1. So if we just continue to extrapolate this in terms of skill that we have, I think if we extrapolate the straight curve, within a few years, we will get to these models being above the highest professional level in terms of humans. Now, will that curve continue? You’ve pointed to, and I’ve pointed to a lot of possible reasons why that might not happen. But if the extrapolation curve continues, that is the trajectory we’re on."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:20:46)",
                "text": "So Anthropic has several competitors. It’d be interesting to get your sort of view of it all. OpenAI, Google, XAI, Meta. What does it take to win in the broad sense of win in this space?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:20:58)",
                "text": "Yeah, so I want to separate out a couple things, right? Anthropic’s mission is to kind of try to make this all go well. And we have a theory of change called Race to the Top. Race to the Top is about trying to push the other players to do the right thing by setting an example. It’s not about being the good guy, it’s about setting things up so that all of us can be the good guy."
            },
            {
                "speaker": "",
                "time": "(00:21:24)",
                "text": "I’ll give a few examples of this. Early in the history of Anthropic, one of our co-founders, Chris Olah, who I believe you’re interviewing soon, he’s the co-founder of the field of mechanistic interpretability, which is an attempt to understand what’s going on inside AI models. So we had him and one of our early teams focus on this area of interpretability, which we think is good for making models safe and transparent."
            },
            {
                "speaker": "",
                "time": "(00:21:48)",
                "text": "For three or four years that had no commercial application whatsoever. It still doesn’t. Today we’re doing some early betas with it, and probably it will eventually, but this is a very, very long research bed, and one in which we’ve built in public and shared our results publicly. And we did this because we think it’s a way to make models safer. An interesting thing is that as we’ve done this, other companies have started doing it as well. In some cases because they’ve been inspired by it, in some cases because they’re worried that if other companies are doing this, look more responsible, they want to look more responsible too. No one wants to look like the irresponsible actor. And so they adopt this as well. When folks come to Anthropic, interpretability is often a draw, and I tell them, “The other places you didn’t go, tell them why you came here.” And then you see soon that there’s interpretability teams elsewhere as well."
            },
            {
                "speaker": "",
                "time": "(00:22:47)",
                "text": "And in a way that takes away our competitive advantage, because it’s like, “Oh, now others are doing it as well.” But it’s good for the broader system, and so we have to invent some new thing that we’re doing that others aren’t doing as well. And the hope is to basically bid up the importance of doing the right thing. And it’s not about us in particular. It’s not about having one particular good guy. Other companies can do this as well. If they join the race to do this, that’s the best news ever. It’s about shaping the incentives to point upward instead of shaping the incentives to point downward."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:23:25)",
                "text": "And we should say this example of the field of mechanistic interpretability is just a rigorous non-hand wavy wave doing AI safety-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:23:34)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:23:34)",
                "text": "… or it’s tending that way."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:23:36)",
                "text": "Trying to. I mean, I think we’re still early in terms of our ability to see things, but I’ve been surprised at how much we’ve been able to look inside these systems and understand what we see. Unlike with the scaling laws where it feels like there’s some law that’s driving these models to perform better, on the inside, the models aren’t… There’s no reason why they should be designed for us to understand them, right? They’re designed to operate, they’re designed to work. Just like the human brain or human biochemistry. They’re not designed for a human to open up the hatch, look inside and understand them. But we have found, and you can talk in much more detail about this to Chris, that when we open them up, when we do look inside them, we find things that are surprisingly interesting."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:24:20)",
                "text": "And as a side effect, you also get to see the beauty of these models. You get to explore the beautiful nature of large neural networks through the MEC and TERP kind of methodology."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:24:29)",
                "text": "I’m amazed at how clean it’s been. I’m amazed at things like induction heads. I’m amazed at things like that we can use sparse auto-encoders to find these directions within the networks, and that the directions correspond to these very clear concepts."
            },
            {
                "speaker": "",
                "time": "(00:24:49)",
                "text": "We demonstrated this a bit with the Golden Gate Bridge Claude. So this was an experiment where we found a direction inside one of the neural networks layers that corresponded to the Golden Gate Bridge. And we just turned that way up. And so we released this model as a demo, it was kind of half a joke, for a couple days, but it was illustrative of the method we developed. And you could take the model, you could ask it about anything. It would be like you could say, “How was your day?” And anything you asked, because this feature was activated, it would connect to the Golden Gate Bridge. So it would say, I’m feeling relaxed and expansive, much like the arches of the Golden Gate Bridge, or-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:25:31)",
                "text": "It would masterfully change topic to the Golden Gate Bridge and integrate it. There was also a sadness to the focus it had on the Golden Gate Bridge. I think people quickly fell in love with it, I think. So people already miss it, because it was taken down, I think after a day."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:25:45)",
                "text": "Somehow these interventions on the model, where you kind of adjust its behavior, somehow emotionally made it seem more human than any other version of the model."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:25:56)",
                "text": "It’s a strong personality, strong identity."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:25:58)",
                "text": "It has a strong personality. It has these kind of obsessive interests. We can all think of someone who’s obsessed with something. So it does make it feel somehow a bit more human."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:26:08)",
                "text": "Let’s talk about the present. Let’s talk about Claude. So this year, a lot has happened. In March. Claude 3 Opus, Sonnet, Haiku were released. Then Claude 3.5 Sonnet in July, with an updated version just now released. And then also Claude 3.5 Haiku was released. Okay. Can you explain the difference between Opus, Sonnet and Haiku, and how we should think about the different versions?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:26:34)",
                "text": "Yeah, so let’s go back to March when we first released these three models. So our thinking was different companies produce large and small models, better and worse models. We felt that there was demand, both for a really powerful model, and that might be a little bit slower that you’d have to pay more for, and also for fast cheap models that are as smart as they can be for how fast and cheap. Whenever you want to do some kind of difficult analysis, like if I want to write code for instance, or I want to brainstorm ideas or I want to do creative writing, I want the really powerful model."
            },
            {
                "speaker": "",
                "time": "(00:27:15)",
                "text": "But then there’s a lot of practical applications in a business sense where it’s like I’m interacting with a website, I am doing my taxes, or I’m talking to a legal advisor and I want to analyze a contract. Or we have plenty of companies that are just like, I want to do auto-complete on my IDE or something. And for all of those things, you want to act fast and you want to use the model very broadly. So we wanted to serve that whole spectrum of needs. So we ended up with this kind of poetry theme. And so what’s a really short poem? It’s a haiku. Haiku is the small, fast, cheap model that was at the time, was really surprisingly intelligent for how fast and cheap it was."
            },
            {
                "speaker": "",
                "time": "(00:28:03)",
                "text": "Sonnet is a medium-sized poem, write a couple paragraphs. And so Sonnet was the middle model. It is smarter but also a little bit slower, a little bit more expensive. And Opus, like a Magnum Opus is a large work, Opus was the largest, smartest model at the time. So that was the original kind of thinking behind it."
            },
            {
                "speaker": "",
                "time": "(00:28:24)",
                "text": "And our thinking then was, “Well, each new generation of models should shift that trade- off curve.” So when we released Sonnet 3.5, it has roughly the same cost and speed as the Sonnet 3 model, but it increased its intelligence to the point where it was smarter than the original Opus 3 model. Especially for code, but also just in general. And so now we’ve shown results for Haiku 3.5. And I believe Haiku 3.5, the smallest new model, is about as good as Opus 3, the largest old model. So basically the aim here is to shift the curve and then at some point there’s going to be an Opus 3.5."
            },
            {
                "speaker": "",
                "time": "(00:29:13)",
                "text": "Now every new generation of models has its own thing. They use new data, their personality changes in ways that we try to steer but are not fully able to steer. And so there’s never quite that exact equivalence, where the only thing you’re changing is intelligence. We always try and improve other things and some things change without us knowing or measuring. So it’s very much an inexact science. In many ways, the manner and personality of these models is more an art than it is a science."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:29:44)",
                "text": "So what is the reason for the span of time between say, Claude Opus 3.0 and 3.5? What takes that time, if you can speak to it?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:29:58)",
                "text": "Yeah, so there’s different processes. There’s pre-training, which is just kind of the normal language model training. And that takes a very long time. That uses, these days, tens of thousands, sometimes many tens of thousands of GPUs or TPUs or training them, or we use different platforms, but accelerator chips, often training for months."
            },
            {
                "speaker": "",
                "time": "(00:30:26)",
                "text": "There’s then a kind of post-training phase where we do reinforcement learning from human feedback as well as other kinds of reinforcement learning. That phase is getting larger and larger now, and often that’s less of an exact science. It often takes effort to get it right. Models are then tested with some of our early partners to see how good they are, and they’re then tested, both internally and externally, for their safety, particularly for catastrophic and autonomy risks. So we do internal testing according to our responsible scaling policy, which I could talk more about that in detail."
            },
            {
                "speaker": "",
                "time": "(00:31:06)",
                "text": "And then we have an agreement with the US and the UK AI Safety Institute, as well as other third-party testers in specific domains, to test the models for what are called CBRN risks, chemical, biological, radiological, and nuclear. We don’t think that models pose these risks seriously yet, but every new model we want to evaluate to see if we’re starting to get close to some of these more dangerous capabilities. So those are the phases, and then it just takes some time to get the model working in terms of inference and launching it in the API. So there’s just a lot of steps to actually making a model work. And of course, we’re always trying to make the processes as streamlined as possible."
            },
            {
                "speaker": "",
                "time": "(00:31:55)",
                "text": "We want our safety testing to be rigorous, but we want it to be rigorous and to be automatic, to happen as fast as it can, without compromising on rigor. Same with our pre-training process and our post-training process. So it’s just building anything else. It’s just like building airplanes. You want to make them safe, but you want to make the process streamlined. And I think the creative tension between those is an important thing in making the models work."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:32:20)",
                "text": "Yeah, rumor on the street, I forget who was saying that, Anthropic has really good tooling. So probably a lot of the challenge here is, on the software engineering side, is to build the tooling to have a efficient, low-friction interaction with the infrastructure."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:32:36)",
                "text": "You would be surprised how much of the challenges of building these models comes down to software engineering, performance engineering. From the outside, you might think, “Oh man, we had this Eureka breakthrough.” You know, this movie with the science. “We discovered it, we figured it out.” But I think all things, even incredible discoveries, they almost always come down to the details. And often super, super boring details. I can’t speak to whether we have better tooling than other companies. I mean, haven’t been at those other companies, at least not recently, but it’s certainly something we give a lot of attention to."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:33:18)",
                "text": "I don’t know if you can say, but from Claude 3 to Claude 3.5, is there any extra pre-training going on, or is it mostly focused on the post-training? There’s been leaps in performance."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:33:29)",
                "text": "Yeah, I think at any given stage, we’re focused on improving everything at once. Just naturally. Like, there are different teams. Each team makes progress in a particular area, in making their particular segment of the relay race better. And it’s just natural that when we make a new model, we put all of these things in at once."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:33:50)",
                "text": "So the data you have, the preference data you get from RLHF, is there ways to apply it to newer models as it get trained up?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:34:00)",
                "text": "Yeah. Preference data from old models sometimes gets used for new models, although of course it performs somewhat better when it’s trained on the new models. Note that we have this constitutional AI method such that we don’t only use preference data, there’s also a post-training process where we train the model against itself. And there’s new types of post-training the model against itself that are used every day. So it’s not just RLHF, a bunch of other methods as well. Post-training, I think, is becoming more and more sophisticated."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:34:30)",
                "text": "Well, what explains the big leap in performance for the new Sonnet 3.5, I mean, at least in the programming side? And maybe this is a good place to talk about benchmarks. What does it mean to get better? Just the number went up, but I program, but I also love programming, and I Claude 3.5 through Cursor is what I use to assist me in programming. And there was, at least experientially, anecdotally, it’s gotten smarter at programming. So what does it take to get it smarter?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:34:30)",
                "text": "We-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:35:00)",
                "text": "So what does it take to get it smarter?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:35:03)",
                "text": "We observe that as well. By the way, there were a couple very strong engineers here at Anthropic, who all previous code models, both produced by us and produced by all the other companies, hadn’t really been useful to them. They said, “Maybe this is useful to a beginner. It’s not useful to me.” But Sonnet 3.5, the original one for the first time, they said, “Oh, my God, this helped me with something that it would’ve taken me hours to do. This is the first model that’s actually saved me time.”"
            },
            {
                "speaker": "",
                "time": "(00:35:31)",
                "text": "So again, the water line is rising. And then I think the new Sonnet has been even better. In terms of what it takes, I’ll just say it’s been across the board. It’s in the pre-training, it’s in the post-training, it’s in various evaluations that we do. We’ve observed this as well. And if we go into the details of the benchmark, so SWE-bench is basically… Since you’re a programmer, you’ll be familiar with pull requests, and just pull requests, they’re like a sort of atomic unit of work. You could say I’m implementing one thing."
            },
            {
                "speaker": "",
                "time": "(00:36:12)",
                "text": "So SWE-bench actually gives you a real world situation where the code base is in a current state and I’m trying to implement something that’s described in language. We have internal benchmarks where we measure the same thing and you say, “Just give the model free rein to do anything, run anything, edit anything. How well is it able to complete these tasks?” And it’s that benchmark that’s gone from “it can do it 3% of the time” to “it can do it about 50% of the time.”"
            },
            {
                "speaker": "",
                "time": "(00:36:43)",
                "text": "So I actually do believe that you can gain benchmarks, but I think if we get to 100% on that benchmark in a way that isn’t over-trained or game for that particular benchmark, probably represents a real and serious increase in programming ability. And I would suspect that if we can get to 90, 95% that it will represent ability to autonomously do a significant fraction of software engineering tasks."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:13)",
                "text": "Well, ridiculous timeline question. When is Claude Opus 3.5 coming up?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:37:19)",
                "text": "Not giving you an exact date, but as far as we know, the plan is still to have a Claude 3.5 Opus."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:28)",
                "text": "Are we going to get it before GTA 6 or no?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:37:30)",
                "text": "Like Duke Nukem Forever?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:30)",
                "text": "Duke Nukem. Right."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:37:32)",
                "text": "What was that game? There was some game that was delayed 15 years."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:32)",
                "text": "That’s right."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:37:34)",
                "text": "Was that Duke Nukem Forever?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:36)",
                "text": "Yeah. And I think GTA is now just releasing trailers."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:37:39)",
                "text": "It’s only been three months since we released the first Sonnet."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:42)",
                "text": "Yeah, it’s the incredible pace of release."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:37:45)",
                "text": "It just tells you about the pace, the expectations for when things are going to come out."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:49)",
                "text": "So what about 4.0? So how do you think, as these models get bigger and bigger, about versioning and also just versioning in general, why Sonnet 3.5 updated with the date? Why not Sonnet 3.6, which a lot of people are calling it?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:38:06)",
                "text": "Naming is actually an interesting challenge here, right? Because I think a year ago, most of the model was pre-training. And so you could start from the beginning and just say, “Okay, we’re going to have models of different sizes. We’re going to train them all together and we’ll have a family of naming schemes and then we’ll put some new magic into them and then we’ll have the next generation.”"
            },
            {
                "speaker": "",
                "time": "(00:38:26)",
                "text": "The trouble starts already when some of them take a lot longer than others to train. That already messes up your time a little bit. But as you make big improvement in pre-training, then you suddenly notice, “Oh, I can make better pre-train model.” And that doesn’t take very long to do, but clearly it has the same size and shape of previous models. So I think those two together as well as the timing issues. Any kind of scheme you come up with, the reality tends to frustrate that scheme, right? It tends to break out of the scheme."
            },
            {
                "speaker": "",
                "time": "(00:39:04)",
                "text": "It’s not like software where you can say, “Oh, this is 3.7, this is 3.8.” No, you have models with different trade-offs. You can change some things in your models, you can change other things. Some are faster and slower at inference. Some have to be more expensive, some have to be less expensive. And so I think all the companies have struggled with this. I think we were in a good position in terms of naming when we had Haiku, Sonnet and Opus."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:39:31)",
                "text": "It was great, great start."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:39:32)",
                "text": "We’re trying to maintain it, but it’s not perfect, so we’ll try and get back to the simplicity. But just the nature of the field, I feel like no one’s figured out naming. It’s somehow a different paradigm from normal software and so none of the companies have been perfect at it. It’s something we struggle with surprisingly much relative to how trivial it is for the grand science of training the models."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:40:03)",
                "text": "So from the user side, the user experience of the updated Sonnet 3.5 is just different than the previous June 2024 Sonnet 3.5. It would be nice to come up with some kind of labeling that embodies that. Because people talk about Sonnet 3.5, but now there’s a different one. And so how do you refer to the previous one and the new one when there’s a distinct improvement? It just makes conversation about it just challenging."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:40:34)",
                "text": "Yeah, yeah. I definitely think this question of there are lots of properties of the models that are not reflected in the benchmarks. I think that’s definitely the case and everyone agrees. And not all of them are capabilities. Models can be polite or brusque, they can be very reactive or they can ask you questions. They can have what feels like a warm personality or a cold personality. They can be boring or they can be very distinctive like Golden Gate Claude was."
            },
            {
                "speaker": "",
                "time": "(00:41:10)",
                "text": "And we have a whole team focused on, I think we call it Claude character. Amanda leads that team and we’ll talk to you about that, but it’s still a very inexact science and often we find that models have properties that we’re not aware of. The fact of the matter is that you can talk to a model 10,000 times and there are some behaviors you might not see just like with a human, right?"
            },
            {
                "speaker": "",
                "time": "(00:41:36)",
                "text": "I can know someone for a few months and not know that they have a certain skill or not know that there’s a certain side to them. And so I think we just have to get used to this idea. And we’re always looking for better ways of testing our models to demonstrate these capabilities and also to decide which are the personality properties we want models to have and which we don’t want to have. That itself, the normative question, is also super interesting."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:42:02)",
                "text": "I got to ask you a question from Reddit."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:42:04)",
                "text": "From Reddit? Oh, boy."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:42:07)",
                "text": "There’s just this fascinating, to me at least, it’s a psychological social phenomenon where people report that Claude has gotten dumber for them over time. And so the question is, does the user complaint about the dumbing down of Claude 3.5 Sonnet hold any water? So are these anecdotal reports a kind of social phenomena or is there any cases where Claude would get dumber?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:42:33)",
                "text": "So this actually doesn’t apply. This isn’t just about Claude. I believe I’ve seen these complaints for every foundation model produced by a major company. People said this about GPT-4, they said it about GPT-4 Turbo. So a couple things. One, the actual weights of the model, the actual brain of the model, that does not change unless we introduce a new model. There are just a number of reasons why it would not make sense practically to be randomly substituting in new versions of the model."
            },
            {
                "speaker": "",
                "time": "(00:43:09)",
                "text": "It’s difficult from an inference perspective and it’s actually hard to control all the consequences of changing the weights of the model. Let’s say you wanted to fine-tune the model, I don’t know, to say “certainly” less, which an old version of Sonnet used to do. You actually end up changing 100 things as well. So we have a whole process for it and we have a whole process for modifying the model. We do a bunch of testing on it. We do a bunch of user testing in early customers."
            },
            {
                "speaker": "",
                "time": "(00:43:36)",
                "text": "So we both have never changed the weights of the model without telling anyone. And certainly, in the current setup, it would not make sense to do that. Now, there are a couple things that we do occasionally do. One is sometimes we run A/B tests, but those are typically very close to when a model is being released and for a very small fraction of time."
            },
            {
                "speaker": "",
                "time": "(00:44:01)",
                "text": "So the day before the new Sonnet 3.5, I agree we should have had a better name. It’s clunky to refer to it. There were some comments from people that it’s gotten a lot better and that’s because a fraction we’re exposed to an A/B test for those one or two days. The other is that occasionally the system prompt will change. The system prompt can have some effects, although it’s unlikely to dumb down models, it’s unlikely to make them dumber."
            },
            {
                "speaker": "",
                "time": "(00:44:32)",
                "text": "And we’ve seen that while these two things, which I’m listing to be very complete, happened quite infrequently, the complaints for us and for other model companies about the model change, the model isn’t good at this, the model got more censored, the model was dumbed down. Those complaints are constant and so I don’t want to say people are imagining it or anything, but the models are, for the most part, not changing. If I were to offer a theory, I think it actually relates to one of the things I said before, which is that models are very complex and have many aspects to them. And so often, if I ask the model a question, if I’m like, “Do task X” versus, “Can you do task X?” the model might respond in different ways. And so there are all kinds of subtle things that you can change about the way you interact with the model that can give you very different results."
            },
            {
                "speaker": "",
                "time": "(00:45:33)",
                "text": "To be clear, this itself is like a failing by us and by the other model providers that the models are just often sensitive to small changes in wording. It’s yet another way in which the science of how these models work is very poorly developed. And so if I go to sleep one night and I was talking to the model in a certain way and I slightly changed the phrasing of how I talk to the model, I could get different results."
            },
            {
                "speaker": "",
                "time": "(00:45:58)",
                "text": "So that’s one possible way. The other thing is, man, it’s just hard to quantify this stuff. It’s hard to quantify this stuff. I think people are very excited by new models when they come out and then as time goes on, they become very aware of their limitations. So that may be another effect, but that’s all a very long-winded way of saying for the most part, with some fairly narrow exceptions, the models are not changing."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:46:22)",
                "text": "I think there is a psychological effect. You just start getting used to it, the baseline raises. When people who have first gotten Wi-Fi on airplanes, it’s amazing, magic."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:46:32)",
                "text": "It’s amazing. Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:46:32)",
                "text": "And then you start-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:46:33)",
                "text": "And now I’m like, “I can’t get this thing to work. This is such a piece of crap.”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:46:36)",
                "text": "Exactly. So it’s easy to have the conspiracy theory of, “They’re making Wi-Fi slower and slower.” This is probably something I’ll talk to Amanda much more about, but another Reddit question, “When will Claude stop trying to be my pure tentacle grandmother imposing its moral worldview on me as a paying customer? And also, what is the psychology behind making Claude overly apologetic?” So this reports about the experience, a different angle on the frustration. It has to do with the character [inaudible 00:47:06]."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:47:06)",
                "text": "Yeah, so a couple points on this first. One is things that people say on Reddit and Twitter or X or whatever it is, there’s actually a huge distribution shift between the stuff that people complain loudly about on social media and what actually statistically users care about and that drives people to use the models."
            },
            {
                "speaker": "",
                "time": "(00:47:27)",
                "text": "People are frustrated with things like the model not writing out all the code or the model just not being as good at code as it could be, even though it’s the best model in the world on code. I think the majority of things are about that, but certainly a vocal minority raise these concerns, are frustrated by the model refusing things that it shouldn’t refuse or apologizing too much or just having these annoying verbal tics."
            },
            {
                "speaker": "",
                "time": "(00:47:59)",
                "text": "The second caveat, and I just want to say this super clearly because I think some people don’t know it, others know it, but forget it. It is very difficult to control across the board how the models behave. You cannot just reach in there and say, “Oh, I want the model to apologize less.” You can do that. You can include training data that says, “Oh, the model should apologize less.” But then in some other situation, they end up being super rude or overconfident in a way that’s misleading people."
            },
            {
                "speaker": "",
                "time": "(00:48:30)",
                "text": "So there are all these trade-offs. For example, another thing is if there was a period during which models, ours and I think others as well, were too verbose, they would repeat themselves, they would say too much. You can cut down on the verbosity by penalizing the models for just talking for too long. What happens when you do that, if you do it in a crude way, is when the models are coding, sometimes they’ll say, “Rest of the code goes here,” right?"
            },
            {
                "speaker": "",
                "time": "(00:48:58)",
                "text": "Because they’ve learned that that’s the way to economize and that they see it. And then so that leads the model to be so-called lazy in coding where they’re just like, “Ah, you can finish the rest of it.” It’s not because we want to save on compute or because the models are lazy during winter break or any of the other conspiracy theories that have come up. Actually, it’s just very hard to control the behavior of the model, to steer the behavior of the model in all circumstances at once."
            },
            {
                "speaker": "",
                "time": "(00:49:28)",
                "text": "There’s this whack- a-mole aspect where you push on one thing and these other things start to move as well that you may not even notice or measure. And so one of the reasons that I care so much about grand alignment of these AI systems in the future is actually, these systems are actually quite unpredictable. They’re actually quite hard to steer and control. And this version we’re seeing today of you make one thing better, it makes another thing worse, I think that’s like a present day analog of future control problems in AI systems that we can start to study today."
            },
            {
                "speaker": "",
                "time": "(00:50:12)",
                "text": "I think that difficulty in steering the behavior and making sure that if we push an AI system in one direction, it doesn’t push it in another direction in some other ways that we didn’t want. I think that’s an early sign of things to come, and if we can do a good job of solving this problem of you ask the model to make and distribute smallpox and it says no, but it’s willing to help you in your graduate level virology class, how do we get both of those things at once? It’s hard."
            },
            {
                "speaker": "",
                "time": "(00:50:48)",
                "text": "It’s very easy to go to one side or the other and it’s a multidimensional problem. And so I think these questions of shaping the model’s personality, I think they’re very hard. I think we haven’t done perfectly on them. I think we’ve actually done the best of all the AI companies, but still so far from perfect."
            },
            {
                "speaker": "",
                "time": "(00:51:08)",
                "text": "And I think if we can get this right, if we can control the false positives and false negatives in this very controlled present day environment, we’ll be much better at doing it for the future when our worry is: will the models be super autonomous? Will they be able to make very dangerous things? Will they be able to autonomously build whole companies and are those companies aligned? So I think of this present task as both vexing but also good practice for the future."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:51:40)",
                "text": "What’s the current best way of gathering user feedback? Not anecdotal data, but just large-scale data about pain points or the opposite of pain points, positive things, so on? Is it internal testing? Is it a specific group testing, A/B testing? What works?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:51:59)",
                "text": "So typically, we’ll have internal model bashings where all of Anthropic… Anthropic is almost 1,000 people. People just try and break the model. They try and interact with it various ways. We have a suite of evals for, “Oh, is the model refusing in ways that it couldn’t?” I think we even had a “certainly” eval because again, at one point, the model had this problem where it had this annoying tick where it would respond to a wide range of questions by saying, “Certainly, I can help you with that. Certainly, I would be happy to do that. Certainly, this is correct.”"
            },
            {
                "speaker": "",
                "time": "(00:52:34)",
                "text": "And so we had a “certainly” eval, which is: how often does the model say certainly? But look, this is just a whack-a-mole. What if it switches from “certainly” to “definitely”? So every time we add a new eval and we’re always evaluating for all the old things, we have hundreds of these evaluations, but we find that there’s no substitute for a human interacting with it."
            },
            {
                "speaker": "",
                "time": "(00:52:56)",
                "text": "And so it’s very much like the ordinary product development process. We have hundreds of people within Anthropic bash the model. Then we do external A/B tests. Sometimes we’ll run tests with contractors. We pay contractors to interact with the model. So you put all of these things together and it’s still not perfect. You still see behaviors that you don’t quite want to see. You still see the model refusing things that it just doesn’t make sense to refuse."
            },
            {
                "speaker": "",
                "time": "(00:53:25)",
                "text": "But I think trying to solve this challenge, trying to stop the model from doing genuinely bad things that everyone agrees it shouldn’t do, everyone agrees that the model shouldn’t talk about, I don’t know, child abuse material. Everyone agrees the model shouldn’t do that, but at the same time, that it doesn’t refuse in these dumb and stupid ways."
            },
            {
                "speaker": "",
                "time": "(00:53:49)",
                "text": "I think drawing that line as finely as possible, approaching perfectly, is still a challenge and we’re getting better at it every day, but there’s a lot to be solved. And again, I would point to that as an indicator of a challenge ahead in terms of steering much more powerful models."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:54:06)",
                "text": "Do you think Claude 4.0 is ever coming out?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:54:11)",
                "text": "I don’t want to commit to any naming scheme because if I say here, “We’re going to have Claude 4 next year,” and then we decide that we should start over because there’s a new type of model, I don’t want to commit to it. I would expect in a normal course of business that Claude 4 would come after Claude 3. 5, but you never know in this wacky field."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:54:34)",
                "text": "But this idea of scaling is continuing."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:54:38)",
                "text": "Scaling is continuing. There will definitely be more powerful models coming from us than the models that exist today. That is certain. Or if there aren’t, we’ve deeply failed as a company."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:54:49)",
                "text": "Okay. Can you explain the responsible scaling policy and the AI safety level standards, ASL levels?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:54:55)",
                "text": "As much as I am excited about the benefits of these models, and we’ll talk about that if we talk about Machines of Loving Grace, I’m worried about the risks and I continue to be worried about the risks. No one should think that Machines of Loving Grace was me saying I’m no longer worried about the risks of these models. I think they’re two sides of the same coin."
            },
            {
                "speaker": "",
                "time": "(00:55:16)",
                "text": "The power of the models and their ability to solve all these problems in biology, neuroscience, economic development, governance and peace, large parts of the economy, those come with risks as well, right? With great power comes great responsibility. The two are paired. Things that are powerful can do good things and they can do bad things. I think of those risks as being in several different categories, perhaps the two biggest risks that I think about. And that’s not to say that there aren’t risks today that are important, but when I think of really the things that would happen on the grandest scale, one is what I call catastrophic misuse."
            },
            {
                "speaker": "",
                "time": "(00:55:59)",
                "text": "These are misuse of the models in domains like cyber, bio, radiological, nuclear, things that could harm or even kill thousands, even millions of people if they really, really go wrong. These are the number one priority to prevent. And here I would just make a simple observation, which is that the models, if I look today at people who have done really bad things in the world, I think actually humanity has been protected by the fact that the overlap between really smart, well-educated people and people who want to do really horrific things has generally been small."
            },
            {
                "speaker": "",
                "time": "(00:56:44)",
                "text": "Let’s say I’m someone who I have a PhD in this field, I have a well-paying job. There’s so much to lose. Even assuming I’m completely evil, which most people are not, why would such a person risk their life, risk their legacy, their reputation to do something truly, truly evil? If we had a lot more people like that, the world would be a much more dangerous place. And so my worry is that by being a much more intelligent agent, AI could break that correlation."
            },
            {
                "speaker": "",
                "time": "(00:57:21)",
                "text": "And so I do have serious worries about that. I believe we can prevent those worries. But I think as a counterpoint to Machines of Loving Grace, I want to say that there’s still serious risks. And the second range of risks would be the autonomy risks, which is the idea that models might, on their own, particularly as we give them more agency than they’ve had in the past, particularly as we give them supervision over wider tasks like writing whole code bases or someday even effectively operating entire companies, they’re on a long enough leash. Are they doing what we really want them to do?"
            },
            {
                "speaker": "",
                "time": "(00:58:00)",
                "text": "It’s very difficult to even understand in detail what they’re doing, let alone control it. And like I said, these early signs that it’s hard to perfectly draw the boundary between things the model should do and things the model shouldn’t do that if you go to one side, you get things that are annoying and useless and you go to the other side, you get other behaviors. If you fix one thing, it creates other problems."
            },
            {
                "speaker": "",
                "time": "(00:58:25)",
                "text": "We’re getting better and better at solving this. I don’t think this is an unsolvable problem. I think this is a science like the safety of airplanes or the safety of cars or the safety of drugs. I don’t think there’s any big thing we’re missing. I just think we need to get better at controlling these models. And so these are the two risks I’m worried about. And our responsible scaling plan, which I’ll recognize is a very long-winded answer to your question."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:58:49)",
                "text": "I love it. I love it."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(00:58:51)",
                "text": "Our responsible scaling plan is designed to address these two types of risks. And so every time we develop a new model, we basically test it for its ability to do both of these bad things. So if I were to back up a little bit, I think we have an interesting dilemma with AI systems where they’re not yet powerful enough to present these catastrophes. I don’t know if they’ll ever present these catastrophes. It’s possible they won’t."
            },
            {
                "speaker": "",
                "time": "(00:59:22)",
                "text": "But the case for worry, the case for risk is strong enough that we should act now and they’re getting better very, very fast. I testified in the Senate that we might have serious bio risks within two to three years. That was about a year ago. Things have proceeded apace. So we have this thing where it’s surprisingly hard to address these risks because they’re not here today, they don’t exist. They’re like ghosts, but they’re coming at us so fast because the models are improving so fast."
            },
            {
                "speaker": "",
                "time": "(00:59:56)",
                "text": "So how do you deal with something that’s not here today, doesn’t exist, but is coming at us very fast? So the solution we came up with for that, in collaboration with people like the organization METR and Paul Christiano is what you need for that are you need tests to tell you when the risk is getting close. You need an early warning system. And so every time we have a new model, we test it for its capability to do these CBRN tasks as well as testing it for how capable it is of doing tasks autonomously on its own."
            },
            {
                "speaker": "",
                "time": "(01:00:35)",
                "text": "And in the latest version of our RSP, which we released in the last month or two, the way we test autonomy risks is the AI model’s ability to do aspects of AI research itself, which when the AI models can do AI research, they become truly, truly autonomous. And that threshold is important for a bunch of other ways. And so what do we then do with these tasks? The RSP basically develops what we’ve called an if-then structure, which is if the models pass a certain capability, then we impose a certain set of safety and security requirements on them."
            },
            {
                "speaker": "",
                "time": "(01:01:16)",
                "text": "So today’s models are what’s called ASL-2. Models that were ASL-1 is for systems that manifestly don’t pose any risk of autonomy or misuse. So for example, a chess playing bot, Deep Blue would be ASL-1. It’s just manifestly the case that you can’t use Deep Blue for anything other than chess. It was just designed for chess. No one’s going to use it to conduct a masterful cyber attack or to run wild and take over the world."
            },
            {
                "speaker": "",
                "time": "(01:01:47)",
                "text": "ASL-2 is today’s AI systems where we’ve measured them and we think these systems are simply not smart enough to autonomously self-replicate or conduct a bunch of tasks and also not smart enough to provide meaningful information about CBRN risks and how to build CBRN weapons above and beyond what can be known from looking at Google. In fact, sometimes they do provide information above and beyond a search engine, but not in a way that can be stitched together, not in a way that end-to-end is dangerous enough."
            },
            {
                "speaker": "",
                "time": "(01:02:26)",
                "text": "So ASL-3 is going to be the point at which the models are helpful enough to enhance the capabilities of non-state actors, right? State actors can already do, unfortunately, to a high level of proficiency, a lot of these very dangerous and destructive things. The difference is that non-state actors are not capable of it. And so when we get to ASL-3, we’ll take special security precautions designed to be sufficient to prevent theft of the model by non-state actors and misuse of the model as it’s deployed. We’ll have to have enhanced filters targeted at these particular areas."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:03:07)",
                "text": "Cyber, bio, nuclear."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:03:09)",
                "text": "Cyber, bio, nuclear and model autonomy, which is less a misuse risk and more a risk of the model doing bad things itself. ASL-4, getting to the point where these models could enhance the capability of a already knowledgeable state actor and/or become the main source of such a risk. If you wanted to engage in such a risk, the main way you would do it is through a model. And then I think ASL-4 on the autonomy side, it’s some amount of acceleration in AI research capabilities with an AI model."
            },
            {
                "speaker": "",
                "time": "(01:03:45)",
                "text": "And then ASL-5 is where we would get to the models that are truly capable that it could exceed humanity in their ability to do any of these tasks. And so the point of the if-then structure commitment is basically to say, “Look, I don’t know, I’ve been working with these models for many years and I’ve been worried about risk for many years. It’s actually dangerous to cry wolf. It’s actually dangerous to say this model is risky. And people look at it and they say this is manifestly not dangerous.” Again, it’s the delicacy of the risk isn’t here today, but it’s coming at us fast."
            },
            {
                "speaker": "",
                "time": "(01:04:27)",
                "text": "How do you deal with that? It’s really vexing to a risk planner to deal with it. And so this if-then structure basically says, “Look, we don’t want to antagonize a bunch of people, we don’t want to harm our own ability to have a place in the conversation by imposing these very onerous burdens on models that are not dangerous today.” So the if-then, the trigger commitment is basically a way to deal with this. It says you clamp down hard when you can show the model is dangerous."
            },
            {
                "speaker": "",
                "time": "(01:04:58)",
                "text": "And of course, what has to come with that is enough of a buffer threshold that you’re not at high risk of missing the danger. It’s not a perfect framework. We’ve had to change it. We came out with a new one just a few weeks ago and probably going forward, we might release new ones multiple times a year because it’s hard to get these policies right technically, organizationally from a research perspective. But that is the proposal, if-then commitments and triggers in order to minimize burdens and false alarms now, but really react appropriately when the dangers are here."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:05:37)",
                "text": "What do you think the timeline for ASL-3 is where several of the triggers are fired? And what do you think the timeline is for ASL-4?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:05:44)",
                "text": "Yeah. So that is hotly debated within the company. We are working actively to prepare ASL-3 security measures as well as ASL-3 deployment measures. I’m not going to go into detail, but we’ve made a lot of progress on both and we’re prepared to be, I think, ready quite soon. I would not be surprised at all if we hit ASL-3 next year. There was some concern that we might even hit it this year. That’s still possible. That could still happen. It’s very hard to say, but I would be very, very surprised if it was 2030. I think it’s much sooner than that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:06:24)",
                "text": "So there’s protocols for detecting it, the if-then and then there’s protocols for how to respond to it."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:06:31)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:06:32)",
                "text": "How difficult is the second, the latter?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:06:34)",
                "text": "Yeah. I think for ASL-3, it’s primarily about security and about filters on the model relating to a very narrow set of areas when we deploy the model. Because at ASL-3, the model isn’t autonomous yet. And so you don’t have to worry about the model itself behaving in a bad way even when it’s deployed internally. So I think the ASL- 3 measures are, I won’t say straightforward, they’re rigorous, but they’re easier to reason about."
            },
            {
                "speaker": "",
                "time": "(01:07:06)",
                "text": "I think once we get to ASL-4, we start to have worries about the models being smart enough that they might sandbag tests, they might not tell the truth about tests. We had some results came out about sleeper agents and there was a more recent paper about, “Can the models mislead attempts to sandbag their own abilities, present themselves as being less capable than they are?” And so I think with ASL-4, there’s going to be an important component of using other things than just interacting with the models."
            },
            {
                "speaker": "",
                "time": "(01:07:43)",
                "text": "For example, interpretability or hidden chains of thought where you have to look inside the model and verify via some other mechanism that is not as easily corrupted as what the model says, that the model indeed has some property. So we’re still working on ASL-4. One of the properties of the RSP is that we don’t specify ASL-4 until we’ve hit ASL-3. And I think that’s proven to be a wise decision because even with ASL-3, again, it’s hard to know this stuff in detail, and we want to take as much time as we can possibly take to get these things right."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:08:23)",
                "text": "So for ASL-3, the bad actor will be the humans."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:08:26)",
                "text": "Humans, yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:08:27)",
                "text": "And so there’s a little bit more…"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:08:29)",
                "text": "For ASL- 4, it’s both, I think."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:08:31)",
                "text": "It’s both. And so deception, and that’s where mechanistic interpretability comes into play, and hopefully the techniques used for that are not made accessible to the model."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:08:42)",
                "text": "Yeah. Of course, you can hook up the mechanistic interpretability to the model itself, but then you’ve lost it as a reliable indicator of the model state. There are a bunch of exotic ways you can think of that it might also not be reliable, like if the model gets smart enough that it can jump computers and read the code where you’re looking at its internal state. We’ve thought about some of those. I think they’re exotic enough. There are ways to render them unlikely. But yeah, generally, you want to preserve mechanistic interpretability as a verification set or test set that’s separate from the training process of the model."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:09:19)",
                "text": "See, I think as these models become better and better conversation and become smarter, social engineer becomes a threat too because they could start being very convincing to the engineers inside companies."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:09:30)",
                "text": "Oh, yeah. Yeah. We’ve seen lots of examples of demagoguery in our life from humans, and there’s a concern that models could do that as well."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:09:40)",
                "text": "One of the ways that Claude has been getting more and more powerful is it’s now able to do some agentic stuff, computer use. There’s also an analysis within the sandbox of Claude.ai itself. But let’s talk about computer use. That seems to me super exciting that you can just give Claude a task and it takes a bunch of actions, figures it out, and has access to the…"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:10:00)",
                "text": "… a bunch of actions, figures it out and has access to your computer through screenshots. So can you explain how that works and where that’s headed?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:10:10)",
                "text": "Yeah. It’s actually relatively simple. So Claude has had for a long time, since Claude 3 back in March, the ability to analyze images and respond to them with text. The only new thing we added is those images can be screenshots of a computer and in response, we train the model to give a location on the screen where you can click and/or buttons on the keyboard, you can press in order to take action. And it turns out that with actually not all that much additional training, the models can get quite good at that task. It’s a good example of generalization. People sometimes say if you get to lower earth orbit, you’re halfway to anywhere because of how much it takes to escape the gravity well. If you have a strong pre-trained model, I feel like you’re halfway to anywhere in terms of the intelligence space. And so actually, it didn’t take all that much to get Claude to do this. And you can just set that in a loop, give the model a screenshot, tell it what to click on, give it the next screenshot, tell it what to click on and that turns into a full kind of almost 3D video interaction of the model and it’s able to do all of these tasks. We showed these demos where it’s able to fill out spreadsheets, it’s able to kind of interact with a website, it’s able to open all kinds of programs, different operating systems, Windows, Linux, Mac. So I think all of that is very exciting. I will say, while in theory there’s nothing you could do there that you couldn’t have done through just giving the model the API to drive the computer screen, this really lowers the barrier. And there’s a lot of folks who either aren’t in a position to interact with those APIs or it takes them a long time to do."
            },
            {
                "speaker": "",
                "time": "(01:12:00)",
                "text": "It’s just the screen is just a universal interface that’s a lot easier to interact with. And so I expect over time, this is going to lower a bunch of barriers. Now, honestly, the current model has, it leaves a lot still to be desired and we were honest about that in the blog. It makes mistakes, it misclicks. We were careful to warn people, “Hey, you can’t just leave this thing to run on your computer for minutes and minutes. You got to give this thing boundaries and guardrails.” And I think that’s one of the reasons we released it first in an API form rather than just hand the consumer and give it control of their computer. But I definitely feel that it’s important to get these capabilities out there. As models get more powerful, we’re going to have to grapple with how do we use these capabilities safely. How do we prevent them from being abused?"
            },
            {
                "speaker": "",
                "time": "(01:12:54)",
                "text": "And I think releasing the model while the capabilities are still limited is very helpful in terms of doing that. I think since it’s been released, a number of customers, I think Replit was maybe one of the most quickest to deploy things, have made use of it in various ways. People have hooked up demos for Windows desktops, Macs, Linux machines. So yeah, it’s been very exciting. I think as with anything else, it comes with new exciting abilities and then with those new exciting abilities, we have to think about how to make the model safe, reliable, do what humans want them to do. It’s the same story for everything. Same thing. It’s that same tension."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:13:51)",
                "text": "But the possibility of use cases here, just the range is incredible. So how much to make it work really well in the future? How much do you have to specially kind of go beyond what the pre-trained model is doing, do more post-training, RLHF or supervised fine-tuning or synthetic data just for the agentive stuff?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:14:10)",
                "text": "Yeah. I think speaking at a high level, it’s our intention to keep investing a lot in making the model better. I think we look at some of the benchmarks where previous models were like, “Oh, could do it 6% of the time,” and now our model would do it 14 or 22% of the time. And yeah, we want to get up to the human level reliability of 80, 90% just like anywhere else. We’re on the same curve that we were on with SWE-bench where I think I would guess a year from now, the models can do this very, very reliably. But you got to start somewhere."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:14:41)",
                "text": "So you think it’s possible to get to the human level 90% basically doing the same thing you’re doing now or it has to be special for computer use?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:14:49)",
                "text": "It depends what you mean by special and special in general, but I generally think the same kinds of techniques that we’ve been using to train the current model, I expect that doubling down on those techniques in the same way that we have for code, for models in general, for image input, for voice, I expect those same techniques will scale here as they have everywhere else,"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:15:18)",
                "text": "But this is giving the power of action to Claude and so you could do a lot of really powerful things, but you could do a lot of damage also."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:15:27)",
                "text": "Yeah, yeah. No and we’ve been very aware of that. Look, my view actually is computer use isn’t a fundamentally new capability like the CBRN or autonomy capabilities are. It’s more like it kind of opens the aperture for the model to use and apply its existing abilities. And so the way we think about it, going back to our RSP, is nothing that this model is doing inherently increases the risk from an RSP perspective, but as the models get more powerful, having this capability may make it scarier once it has the cognitive capability to do something at the ASL-3 and ASL-4 level, this may be the thing that kind of unbounds it from doing so. So going forward, certainly this modality of interaction is something we have tested for and that we will continue to test for an RSP going forward. I think it’s probably better to learn and explore this capability before the model is super capable"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:16:33)",
                "text": "Yeah. And there’s a lot of interesting attacks like prompt injection because now you’ve widened the aperture so you can prompt inject through stuff on screen. So if this becomes more and more useful, then there’s more and more benefit to inject stuff into the model. If it goes to certain web page, it could be harmless stuff like advertisements or it could be harmful stuff, right?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:16:53)",
                "text": "Yeah, we’ve thought a lot about things like spam, CAPTCHA, mass… One secret, I’ll tell you, if you’ve invented a new technology, not necessarily the biggest misuse, but the first misuse you’ll see, scams, just petty scams."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:17:10)",
                "text": "Yeah."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:17:13)",
                "text": "It’s like a thing as old, people scamming each other, it’s this thing as old as time. And it’s just every time, you got to deal with it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:17:21)",
                "text": "It’s almost silly to say, but it’s true, sort of bots and spam in general is a thing as it gets more and more intelligent-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:17:29)",
                "text": "Yeah, yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:17:29)",
                "text": "… it’s harder and harder to fight it."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:17:32)",
                "text": "Like I said, there are a lot of petty criminals in the world and it’s like every new technology is a new way for petty criminals to do something stupid and malicious."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:17:45)",
                "text": "Is there any ideas about sandboxing it? How difficult is the sandboxing task?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:17:49)",
                "text": "Yeah, we sandbox during training. So for example, during training we didn’t expose the model to the internet. I think that’s probably a bad idea during training because the model can be changing its policy, it can be changing what it’s doing and it’s having an effect in the real world. In terms of actually deploying the model, it kind of depends on the application. Sometimes you want the model to do something in the real world. But of course, you can always put guard, you can always put guard rails on the outside. You can say, “Okay, well, this model’s not going to move data from my, the model’s not going to move any files from my computer or my web server to anywhere else.”"
            },
            {
                "speaker": "",
                "time": "(01:18:27)",
                "text": "Now, when you talk about sandboxing, again, when we get to ASL-4, none of these precautions are going to make sense there. When you talk about ASL-4, you’re then, the model is being, there’s theoretical worry the model could be smart enough to kind of break it to out of any box. And so there, we need to think about mechanistic interpretability. If we’re going to have a sandbox, it would need to be a mathematically provable. That’s a whole different world than what we’re dealing with with the models today."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:19:01)",
                "text": "Yeah, the science of building a box from which ASL-4 AI system cannot escape."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:19:08)",
                "text": "I think it’s probably not the right approach. I think the right approach, instead of having something unaligned that you’re trying to prevent it from escaping, I think it’s better to just design the model the right way or have a loop where you look inside the model and you’re able to verify properties and that gives you an opportunity to tell, iterate and actually get it right. I think containing bad models is a much worse solution than having good models."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:19:36)",
                "text": "Let me ask about regulation. What’s the role of regulation in keeping AI safe? So for example, can you describe California AI regulation bill SB 1047 that was ultimately vetoed by the governor? What are the pros and cons of this bill in general?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:19:50)",
                "text": "Yes, we ended up making some suggestions to the bill. And then some of those were adopted and we felt, I think, quite positively about the bill by the end of that, it did still have some downsides. And of course, it got vetoed. I think at a high level, I think some of the key ideas behind the bill are I would say similar to ideas behind our RSPs. And I think it’s very important that some jurisdiction, whether it’s California or the federal government and/or other countries and other states, passes some regulation like this. And I can talk through why I think that’s so important. So I feel good about our RSP. It’s not perfect. It needs to be iterated on a lot. But it’s been a good forcing function for getting the company to take these risks seriously, to put them into product planning, to really make them a central part of work at Anthropic and to make sure that all of a thousand people, and it’s almost a thousand people now at Anthropic, understand that this is one of the highest priorities of the company, if not the highest priority."
            },
            {
                "speaker": "",
                "time": "(01:20:58)",
                "text": "But one, there are still some companies that don’t have RSP like mechanisms, like OpenAI, Google did adopt these mechanisms a couple months after Anthropic did, but there are other companies out there that don’t have these mechanisms at all. And so if some companies adopt these mechanisms and others don’t, it’s really going to create a situation where some of these dangers have the property that it doesn’t matter if three out of five of the companies are being safe, if the other two are being unsafe, it creates this negative externality. And I think the lack of uniformity is not fair to those of us who have put a lot of effort into being very thoughtful about these procedures. The second thing is I don’t think you can trust these companies to adhere to these voluntary plans on their own. Right? I like to think that Anthropic will, we do everything we can that we will, our RSP is checked by our long-term benefit trust, so we do everything we can to adhere to our own RSP."
            },
            {
                "speaker": "",
                "time": "(01:22:07)",
                "text": "But you hear lots of things about various companies saying, “Oh, they said they would give this much compute and they didn’t. They said they would do this thing and the didn’t.” I don’t think it makes sense to litigate particular things that companies have done, but I think this broad principle that if there’s nothing watching over them, if there’s nothing watching over us as an industry, there’s no guarantee that we’ll do the right thing and the stakes are very high. And so I think it’s important to have a uniform standard that everyone follows and to make sure that simply that the industry does what a majority of the industry has already said is important and has already said that they definitely will do."
            },
            {
                "speaker": "",
                "time": "(01:22:52)",
                "text": "Right, some people, I think there’s a class of people who are against regulation on principle. I understand where that comes from. If you go to Europe and you see something like GDPR, you see some of the other stuff that they’ve done. Some of it’s good, but some of it is really unnecessarily burdensome and I think it’s fair to say really has slowed innovation. And so I understand where people are coming from on priors. I understand why people start from that position. But again, I think AI is different. If we go to the very serious risks of autonomy and misuse that I talked about just a few minutes ago, I think that those are unusual and they warrant an unusually strong response. And so I think it’s very important."
            },
            {
                "speaker": "",
                "time": "(01:23:44)",
                "text": "Again, we need something that everyone can get behind. I think one of the issues with SB 1047, especially the original version of it was it had a bunch of the structure of RSPs, but it also had a bunch of stuff that was either clunky or that just would’ve created a bunch of burdens, a bunch of hassle and might even have missed the target in terms of addressing the risks. You don’t really hear about it on Twitter, you just hear about kind of people are cheering for any regulation. And then the folks who are against make up these often quite intellectually dishonest arguments about how it’ll make us move away from California, bill doesn’t apply if you’re headquartered in California, bill only applies if you do business in California, or that it would damage the open source ecosystem or that it would cause all of these things."
            },
            {
                "speaker": "",
                "time": "(01:24:43)",
                "text": "I think those were mostly nonsense, but there are better arguments against regulation. There’s one guy, Dean Ball, who’s really, I think, a very scholarly analyst who looks at what happens when a regulation is put in place in ways that they can kind of get a life of their own or how they can be poorly designed. And so our interest has always been we do think there should be regulation in this space, but we want to be an actor who makes sure that that regulation is something that’s surgical, that’s targeted at the serious risks and is something people can actually comply with. Because something I think the advocates of regulation don’t understand as well as they could is if we get something in place that’s poorly targeted, that wastes a bunch of people’s time, what’s going to happen is people are going to say, “See, these safety risks, this is nonsense. I just had to hire 10 lawyers to fill out all these forms. I had to run all these tests for something that was clearly not dangerous.”"
            },
            {
                "speaker": "",
                "time": "(01:25:51)",
                "text": "And after six months of that, there will be a ground swell and we’ll end up with a durable consensus against regulation. And so I think the worst enemy of those who want real accountability is badly designed regulation. We need to actually get it right. And if there’s one thing I could say to the advocates, it would be that I want them to understand this dynamic better and we need to be really careful and we need to talk to people who actually have experience seeing how regulations play out in practice. And the people who have seen that, understand to be very careful. If this was some lesser issue, I might be against regulation at all."
            },
            {
                "speaker": "",
                "time": "(01:26:32)",
                "text": "But what I want the opponents to understand is that the underlying issues are actually serious. They’re not something that I or the other companies are just making up because of regulatory capture, they’re not sci-fi fantasies, they’re not any of these things. Every time we have a new model, every few months we measure the behavior of these models and they’re getting better and better at these concerning tasks just as they are getting better and better at good, valuable, economically useful tasks. And so I would just love it if some of the former, I think SB 1047 was very polarizing, I would love it if some of the most reasonable opponents and some of the most reasonable proponents would sit down together. And I think that the different AI companies, Anthropic was the only AI company that felt positively in a very detailed way. I think Elon tweeted briefly something positive, but some of the big ones like Google, OpenAI, Meta, Microsoft were pretty staunchly against."
            },
            {
                "speaker": "",
                "time": "(01:27:49)",
                "text": "So I would really is if some of the key stakeholders, some of the most thoughtful proponents and some of the most thoughtful opponents would sit down and say how do we solve this problem in a way that the proponents feel brings a real reduction in risk and that the opponents feel that it is not hampering the industry or hampering innovation any more necessary than it needs to. I think for whatever reason, that things got too polarized and those two groups didn’t get to sit down in the way that they should. And I feel urgency. I really think we need to do something in 2025. If we get to the end of 2025 and we’ve still done nothing about this, then I’m going to be worried. I’m not worried yet because, again, the risks aren’t here yet, but I think time is running short."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:28:44)",
                "text": "And come up with something surgical, like you said."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:28:46)",
                "text": "Yeah, yeah, yeah, exactly. And we need to get away from this intense pro safety versus intense anti-regulatory rhetoric. It’s turned into these flame wars on Twitter and nothing good’s going to come of that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:29:04)",
                "text": "So there’s a lot of curiosity about the different players in the game. One of the OGs is OpenAI. You’ve had several years of experience at OpenAI. What’s your story and history there?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:29:14)",
                "text": "Yeah. So I was at OpenAI for roughly five years. For the last, I think it was couple years, I was vice president of research there. Probably myself and Ilya Sutskever were the ones who really kind of set the research direction. Around 2016 or 2017, I first started to really believe in or at least confirm my belief in the scaling hypothesis when Ilya famously said to me, “The thing you need to understand about these models is they just want to learn. The models just want to learn.” And again, sometimes there are these one sentences, these then cones, that you hear them and you’re like, “Ah, that explains everything. That explains a thousand things that I’ve seen.” And then ever after, I had this visualization in my head of you optimize the models in the right way, you point the models in the right way, they just want to learn. They just want to solve the problem regardless of what the problem is."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:08)",
                "text": "So get out of their way, basically?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:30:10)",
                "text": "Get out of their way. Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:11)",
                "text": "Okay."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:30:11)",
                "text": "Don’t impose your own ideas about how they should learn. And this was the same thing as Rich Sutton put out in the bitter lesson or Gwern put out in the scaling hypothesis. I think generally the dynamic was I got this kind of inspiration from Ilya and from others, folks like Alec Radford, who did the original GPT-1 and then ran really hard with it, me and my collaborators, on GPT-2, GPT-3, RL from Human Feedback, which was an attempt to kind of deal with the early safety and durability, things like debate and amplification, heavy on interpretability. So again, the combination of safety plus scaling. Probably 2018, 2019, 2020, those were kind of the years when myself and my collaborators, probably many of whom became co-founders of Anthropic, kind of really had a vision and drove the direction."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:31:11)",
                "text": "Why’d you leave? Why’d you decide to leave?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:31:13)",
                "text": "Yeah, so look, I’m going to put things this way and I think it ties to the race to the top, which is in my time at OpenAI, what I come to see as I’d come to appreciate the scaling hypothesis and as I’d come to appreciate kind of the importance of safety along with the scaling hypothesis. The first one I think OpenAI was getting on board with. The second one in a way had always been part of OpenAI’s messaging. But over many years of the time that I spent there, I think I had a particular vision of how we should handle these things, how we should be brought out in the world, the kind of principles that the organization should have. And look, there were many, many discussions about should the company do this, should the company do that? There’s a bunch of misinformation out there."
            },
            {
                "speaker": "",
                "time": "(01:32:07)",
                "text": "People say we left because we didn’t like the deal with Microsoft. False. Although, it was like a lot of discussion, a lot of questions about exactly how we do the deal with Microsoft. We left because we didn’t like commercialization. That’s not true. We built GPD-3, which was the model that was commercialized. I was involved in commercialization. It’s more, again, about how do you do it? Civilization is going down this path to very powerful AI. What’s the way to do it? That is cautious, straightforward, honest, that builds trust in the organization and in individuals. How do we get from here to there and how do we have a real vision for how to get it right? How can safety not just be something we say because it helps with recruiting. And I think at the end of the day, if you have a vision for that, forget about anyone else’s vision."
            },
            {
                "speaker": "",
                "time": "(01:33:01)",
                "text": "I don’t want to talk about anyone else’s vision. If you have a vision for how to do it, you should go off and you should do that vision. It is incredibly unproductive to try and argue with someone else’s vision. You might think they’re not doing it the right way. You might think they’re dishonest. Who knows? Maybe you’re right, maybe you’re not. But what you should do is you should take some people you trust and you should go off together and you should make your vision happen. And if your vision is compelling, if you can make it appeal to people, some combination of ethically in the market, if you can make a company that’s a place people want to join, that engages in practices that people think are reasonable while managing to maintain its position in the ecosystem at the same time, if you do that, people will copy it."
            },
            {
                "speaker": "",
                "time": "(01:33:52)",
                "text": "And the fact that you are doing it, especially the fact that you’re doing it better than they are, causes them to change their behavior in a much more compelling way than if they’re your boss and you’re arguing with them. I don’t know how to be any more specific about it than that, but I think it’s generally very unproductive to try and get someone else’s vision to look like your vision. It’s much more productive to go off and do a clean experiment and say, “This is our vision, this is how we’re going to do things. Your choice is you can ignore us, you can reject what we’re doing or you can start to become more like us.” And imitation is the sincerest form of flattery. And that plays out in the behavior of customers, that plays out in the behavior of the public, that plays out in the behavior of where people choose to work. And again, at the end, it’s not about one company winning or another company winning."
            },
            {
                "speaker": "",
                "time": "(01:34:48)",
                "text": "If we or another company are engaging in some practice that people find genuinely appealing, and I want it to be in substance, not just an appearance and I think researchers are sophisticated and they look at substance, and then other companies start copying that practice and they win because they copied that practice. That’s great. That’s success. That’s like the race to the top. It doesn’t matter who wins in the end as long as everyone is copying everyone else’s good practices. One way I think of it is the thing we’re all afraid of is the race to the bottom and the race to the bottom doesn’t matter who wins because we all lose. In the most extreme world, we make this autonomous AI that the robots enslave us or whatever. That’s half joking, but that is the most extreme thing that could happen. Then it doesn’t matter which company was ahead. If instead you create a race to the top where people are competing to engage in good practices, then at the end of the day, it doesn’t matter who ends up winning, it doesn’t even matter who started the race to the top."
            },
            {
                "speaker": "",
                "time": "(01:35:57)",
                "text": "The point isn’t to be virtuous, the point is to get the system into a better equilibrium than it was before. And individual companies can play some role in doing this. Individual companies can help to start it, can help to accelerate it. And frankly, I think individuals at other companies have done this as well. The individuals that when we put out an RSP react by pushing harder to get something similar done at other companies, sometimes other companies do something that’s we’re like, “Oh, it’s a good practice. We think that’s good. We should adopt it too.” The only difference is I think we try to be more forward leaning. We try and adopt more of these practices first and adopt them more quickly when others invent them. But I think this dynamic is what we should be pointing at and that I think it abstracts away the question of which company’s winning, who trusts who. I think all these questions of drama are profoundly uninteresting and the thing that matters is the ecosystem that we all operate in and how to make that ecosystem better because that constrains all the players."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:37:06)",
                "text": "And so Anthropic is this kind of clean experiment built on a foundation of what concretely AI safety should look like?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:37:13)",
                "text": "Well, look, I’m sure we’ve made plenty of mistakes along the way. The perfect organization doesn’t exist. It has to deal with the imperfection of a thousand employees. It has to deal with the imperfection of our leaders, including me. It has to deal with the imperfection of the people we’ve put to oversee the imperfection of the leaders like the board and the long-term benefit trust. It’s all a set of imperfect people trying to aim imperfectly at some ideal that will never perfectly be achieved. That’s what you sign up for. That’s what it will always be."
            },
            {
                "speaker": "",
                "time": "(01:37:45)",
                "text": "But imperfect doesn’t mean you just give up. There’s better and there’s worse. And hopefully, we can do well enough that we can begin to build some practices that the whole industry engages in. And then my guess is that multiple of these companies will be successful. Anthropic will be successful. These other companies, like ones I’ve been at the past, will also be successful. And some will be more successful than others. That’s less important than, again, that we align the incentives of the industry. And that happens partly through the race to the top, partly through things like RSP, partly through, again, selected surgical regulation."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:38:25)",
                "text": "You said talent density beats talent mass, so can you explain that? Can you expand on that?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:38:25)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:38:31)",
                "text": "Can you just talk about what it takes to build a great team of AI researchers and engineers?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:38:37)",
                "text": "This is one of these statements that’s more true every month. Every month I see this statement as more true than I did the month before. So if I were to do a thought experiment, let’s say you have a team of 100 people that are super smart, motivated and aligned with the mission and that’s your company. Or you can have a team of a thousand people where 200 people are super smart, super aligned with the mission and then 800 people are, let’s just say you pick 800 random big tech employees, which would you rather have? The talent mass is greater in the group of a thousand people. You have even a larger number of incredibly talented, incredibly aligned, incredibly smart people. But the issue is just that if every time someone super talented looks around, they see someone else super talented and super dedicated, that sets the tone for everything. That sets the tone for everyone is super inspired to work at the same place. Everyone trusts everyone else."
            },
            {
                "speaker": "",
                "time": "(01:39:42)",
                "text": "If you have a thousand or 10,000 people and things have really regressed, you are not able to do selection and you’re choosing random people, what happens is then you need to put a lot of processes and a lot of guardrails in place just because people don’t fully trust each other or you have to adjudicate political battles. There are so many things that slow down the org’s ability to operate. And so we’re nearly a thousand people and we’ve tried to make it so that as large a fraction of those thousand people as possible are super talented, super skilled, it’s one of the reasons we’ve slowed down hiring a lot in the last few months. We grew from 300 to 800, I believe, I think in the first seven, eight months of the year and now we’ve slowed down. The last three months, we went from 800 to 900, 950, something like that. Don’t quote me on the exact numbers, but I think there’s an inflection point around a thousand and we want to be much more careful how we grow."
            },
            {
                "speaker": "",
                "time": "(01:40:42)",
                "text": "Early on and now as well, we’ve hired a lot of physicists. Theoretical physicists can learn things really fast. Even more recently, as we’ve continued to hire that, we’ve really had a high bar on both the research side and the software engineering side, have hired a lot of senior people, including folks who used to be at other companies in this space, and we’ve just continued to be very selective. It’s very easy to go from a hundred to a thousand, a thousand to 10,000 without paying attention to making sure everyone has a unified purpose. It’s so powerful. If your company consists of a lot of different fiefdoms that all want to do their own thing, they’re all optimizing for their own thing, it’s very hard to get anything done. But if everyone sees the broader purpose of the company, if there’s trust and there’s dedication to doing the right thing, that is a superpower. That in itself I think can overcome almost every other disadvantage."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:41:41)",
                "text": "And to Steve Jobs, A players. A players want to look around and see other A players is another way of saying that."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:41:42)",
                "text": "Correct."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:41:48)",
                "text": "I don’t know what that is about human nature, but it is demotivating to see people who are not obsessively driving towards a singular mission. And it is on the flip side of that, super motivating to see that. It’s interesting. What’s it take to be a great AI researcher or engineer from everything you’ve seen from working with so many amazing people?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:42:09)",
                "text": "Yeah. I think the number one quality, especially on the research side, but really both, is open mindedness. Sounds easy to be open-minded, right? You’re just like, “Oh, I’m open to anything.” But if I think about my own early history in this scaling hypothesis, I was seeing the same data others were seeing. I don’t think I was a better programmer or better at coming up with research ideas than any of the hundreds of people that I worked with. In some ways, I was worse. I’ve never precise programming of finding the bug, writing the GPU kernels. I could point you to a hundred people here who are better at that than I am."
            },
            {
                "speaker": "",
                "time": "(01:42:53)",
                "text": "But the thing that I think I did have that was different was that I was just willing to look at something with new eyes. People said, “Oh, we don’t have the right algorithms yet. We haven’t come up with the right way to do things.” And I was just like, “Oh, I don’t know. This neural net has 30 million parameters. What if we gave it 50 million instead? Let’s plot some graphs.” That basic scientific mindset of like, “Oh man,” I see some variable that I could change. What happens when it changes? Let’s try these different things and create a graph. For even, this was the simplest thing in the world, change the number of, this wasn’t PhD level experimental design, this was simple and stupid. Anyone could have done this if you just told them that it was important. It’s also not hard to understand. You didn’t need to be brilliant to come up with this."
            },
            {
                "speaker": "",
                "time": "(01:43:54)",
                "text": "But you put the two things together and some tiny number of people, some single digit number of people have driven forward the whole field by realizing this. And it’s often like that. If you look back at the discoveries in history, they’re often like that. And so this open-mindedness and this willingness to see with new eyes that often comes from being newer to the field, often experience is a disadvantage for this, that is the most important thing. It’s very hard to look for and test for, but I think it’s the most important thing because when you find something, some really new way of thinking about things, when you have the initiative to do that, it’s absolutely transformative."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:44:34)",
                "text": "And also be able to do kind of rapid experimentation and, in the face of that, be open-minded and curious and looking at the data with these fresh eyes and seeing what is it that it’s actually saying. That applies in mechanistic interpretability."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:44:46)",
                "text": "It’s another example of this. Some of the early work and mechanistic interpretability so simple, it’s just no one thought to care about this question before."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:44:56)",
                "text": "You said what it takes to be a great AI researcher. Can we rewind the clock back, what advice would you give to people interested in AI? They’re young, looking…"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:45:00)",
                "text": "What advice would you give to people interested in AI? They’re young. Looking forward to how can I make an impact on the world?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:45:06)",
                "text": "I think my number one piece of advice is to just start playing with the models. Actually, I worry a little, this seems like obvious advice now. I think three years ago it wasn’t obvious and people started by, “Oh, let me read the latest reinforcement learning paper.” And you should do that as well, but now with wider availability of models and APIs, people are doing this more. But, I think just experiential knowledge. These models are new artifacts that no one really understands and so getting experience playing with them. I would also say again, in line with the do something new, think in some new direction, there are all these things that haven’t been explored. For example, mechanistic interpretability is still very new. It’s probably better to work on that than it is to work on new model architectures, because it’s more popular than it was before. There are probably 100 people working on it, but there aren’t like 10,000 people working on it."
            },
            {
                "speaker": "",
                "time": "(01:46:07)",
                "text": "And it’s just this fertile area for study. There’s so much low-hanging fruit, you can just walk by and you can pick things. For whatever reason, people aren’t interested in it enough. I think there are some things around long horizon learning and long horizon tasks, where there’s a lot to be done. I think evaluations, we’re still very early in our ability to study evaluations, particularly for dynamic systems acting in the world. I think there’s some stuff around multi-agent. Skate where the puck is going is my advice, and you don’t have to be brilliant to think of it. All the things that are going to be exciting in five years, people even mention them as conventional wisdom, but it’s just somehow there’s this barrier that people don’t double down as much as they could, or they’re afraid to do something that’s not the popular thing. I don’t know why it happens, but getting over that barrier, that’s my number one piece of advice."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:47:14)",
                "text": "Let’s talk if we could a bit about post-training. So it seems that the modern post-training recipe has a little bit of everything. So supervised fine-tuning, RLHF, the constitutional AI with RLAIF-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:47:32)",
                "text": "Best acronym."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:47:33)",
                "text": "It’s the, again, that naming thing. And then synthetic data. Seems like a lot of synthetic data, or at least trying to figure out ways to have high quality synthetic data. So if this is a secret sauce that makes Anthropic clause so incredible, how much of the magic is in the pre-training? How much of it is in the post-training?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:47:54)",
                "text": "Yeah. So first of all, we’re not perfectly able to measure that ourselves. When you see some great character ability, sometimes it’s hard to tell whether it came from pre-training or post-training. We developed ways to try and distinguish between those two, but they’re not perfect. The second thing I would say is, when there is an advantage and I think we’ve been pretty good in general at RL, perhaps the best, although I don’t know, I don’t see what goes on inside other companies. Usually it isn’t, “Oh my God, we have this secret magic method that others don’t have.” Usually it’s like, “Well, we got better at the infrastructure so we could run it for longer,” or, “We were able to get higher quality data,” or, “We were able to filter our data better, or “We were able to combine these methods and practice.”"
            },
            {
                "speaker": "",
                "time": "(01:48:41)",
                "text": "It’s usually some boring matter of practice and trade craft. So when I think about how to do something special in terms of how we train these models both, but even more so I really think of it a little more, again, as designing airplanes or cars. It’s not just like, “Oh, man. I have the blueprint.” Maybe that makes you make the next airplane. But there’s some cultural trade craft of how we think about the design process that I think is more important than any particular gizmo we’re able to invent."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:49:17)",
                "text": "Okay. Well, let me ask you about specific techniques. So first on RLHF, what do you think, just zooming out intuition, almost philosophy … Why do you think RLHF works so well?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:49:28)",
                "text": "If I go back to the scaling hypothesis, one of the ways to skate the scaling hypothesis is, if you train for X and you throw enough compute at it, then you get X. And so RLHF is good at doing what humans want the model to do, or at least to state it more precisely doing what humans who look at the model for a brief period of time and consider different possible responses, what they prefer as the response, which is not perfect from both the safety and capabilities perspective, in that humans are often not able to perfectly identify what the model wants and what humans want in the moment may not be what they want in the long term."
            },
            {
                "speaker": "",
                "time": "(01:50:05)",
                "text": "So there’s a lot of subtlety there, but the models are good at producing what the humans in some shallow sense want. And it actually turns out that you don’t even have to throw that much compute at it, because of another thing, which is this thing about a strong pre-trained model being halfway to anywhere. So once you have the pre-trained model, you have all the representations you need to get the model where you want it to go."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:50:32)",
                "text": "So do you think RLHF makes the model smarter, or just appear smarter to the humans?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:50:41)",
                "text": "I don’t think it makes the model smarter. I don’t think it just makes the model appear smarter. It’s like RLHF bridges the gap between the human and the model. I could have something really smart that can’t communicate at all. We all know people like this, people who are really smart but can’t understand what they’re saying. So I think RLHF just bridges that gap. I think it’s not the only kind of RL we do. It’s not the only kind of RL that will happen in the future. I think RL has the potential to make models smarter, to make them reason better, to make them operate better, to make them develop new skills even. And perhaps that could be done even in some cases with human feedback. But, the kind of RLHF we do today mostly doesn’t do that yet, although we’re very quickly starting to be able to."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:51:30)",
                "text": "But if you look at the metric of helpfulness, it increases that?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:51:36)",
                "text": "Yes. It also increases, what was this word in Leopold’s essay, “unhobbling,” where basically the models are hobbled and then you do various trainings to them to unhobble them. So I like that word, because it’s a rare word. So I think RLHF unhobbles the models in some ways. And then there are other ways where that model hasn’t yet been unhobbled and needs to unhobble."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:51:58)",
                "text": "If you can say in terms of cost, is pre-training the most expensive thing? Or is post-training creep up to that?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:52:05)",
                "text": "At the present moment, it is still the case that pre-training is the majority of the cost. I don’t know what to expect in the future, but I could certainly anticipate a future where post-training is the majority of the cost."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:52:16)",
                "text": "In that future you anticipate, would it be the humans or the AI that’s the costly thing for the post-training?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:52:22)",
                "text": "I don’t think you can scale up humans enough to get high quality. Any kind of method that relies on humans and uses a large amount of compute, it’s going to have to rely on some scaled supervision method, like debate or iterated amplification or something like that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:52:39)",
                "text": "So on that super interesting set of ideas around constitutional AI, can you describe what it is as first detailed in December 2022 paper and beyond that. What is it?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:52:53)",
                "text": "Yes. So this was from two years ago. The basic idea is, so we describe what RLHF is. You have a model and you just sample from it twice. It spits out two possible responses, and you’re like, “Human, which responses do you like better?” Or another variant of it is, “Rate this response on a scale of one to seven.” So that’s hard because you need to scale up human interaction and it’s very implicit. I don’t have a sense of what I want the model to do. I just have a sense of what this average of 1,000 humans wants the model to do. So two ideas. One is, could the AI system itself decide which response is better? Could you show the AI system these two responses and ask which response is better? And then second, well, what criterion should the AI use?"
            },
            {
                "speaker": "",
                "time": "(01:53:43)",
                "text": "And so then there’s this idea, you have a single document, a constitution if you will, that says, these are the principles the model should be using to respond. And the AI system reads those reads principles as well as reading the environment and the response. And it says, “Well, how good did the AI model do?” It’s basically a form of self-play. You’re training the model against itself. And so the AI gives the response and then you feed that back into what’s called the preference model, which in turn feeds the model to make it better. So you have this triangle of the AI, the preference model, and the improvement of the AI itself."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:54:22)",
                "text": "And we should say that in the constitution, the set of principles are human interpretable. They’re-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:54:27)",
                "text": "Yeah. Yeah. It’s something both the human and the AI system can read. So it has this nice translatability or symmetry. In practice, we both use a model constitution and we use RLHF and we use some of these other methods. So it’s turned into one tool in a toolkit, that both reduces the need for RLHF and increases the value we get from using each data point of RLHF. It also interacts in interesting ways with future reasoning type RL methods. So it’s one tool in the toolkit, but I think it is a very important tool."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:55:05)",
                "text": "Well, it’s a compelling one to us humans. Thinking about the founding fathers and the founding of the United States. The natural question is who and how do you think it gets to define the constitution, the set of principles in the constitution?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:55:20)",
                "text": "Yeah. So I’ll give a practical answer and a more abstract answer. I think the practical answer is look in practice, models get used by all kinds of different customers. And so you can have this idea where the model can have specialized rules or principles. We fine tune versions of models implicitly. We’ve talked about doing it explicitly having special principles that people can build into the models. So from a practical perspective, the answer can be very different from different people. A customer service agent behaves very differently from a lawyer and obeys different principles."
            },
            {
                "speaker": "",
                "time": "(01:55:57)",
                "text": "But, I think at the base of it, there are specific principles that models have to obey. I think a lot of them are things that people would agree with. Everyone agrees that we don’t want models to present these CBRN risks. I think we can go a little further and agree with some basic principles of democracy and the rule of law. Beyond that, it gets very uncertain and there our goal is generally for the models to be more neutral, to not espouse a particular point of view and more just be wise agents or advisors that will help you think things through and will present possible considerations. But don’t express strong or specific opinions."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:56:42)",
                "text": "OpenAI released a model spec where it clearly, concretely defines some of the goals of the model and specific examples like AB, how the model should behave. Do you find that interesting? By the way I should mention, I believe the brilliant John Schulman was a part of that. He’s now at Anthropic. Do you think this is a useful direction? Might Anthropic release a model spec as well?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:57:05)",
                "text": "Yeah. So I think that’s a pretty useful direction. Again, it has a lot in common with constitutional AI. So again, another example of a race to the top. We have something that we think a better and more responsible way of doing things. It’s also a competitive advantage. Then others discover that it has advantages and then start to do that thing. We then no longer have the competitive advantage, but it’s good from the perspective that now everyone has adopted a positive practice that others were not adopting. And so our response to that is, “Well, looks like we need a new competitive advantage in order to keep driving this race upwards.” So that’s how I generally feel about that. I also think every implementation of these things is different. So there were some things in the model spec that were not in constitutional AI, and so we can always adopt those things or at least learn from them. So again, I think this is an example of the positive dynamic that I think we should all want the field to have."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:58:06)",
                "text": "Let’s talk about the incredible essay Machines of Loving Grace. I recommend everybody read it. It’s a long one."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:58:12)",
                "text": "It is rather long."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:58:13)",
                "text": "Yeah. It’s really refreshing to read concrete ideas about what a positive future looks like. And you took a bold stance because it’s very possible that you might be wrong on the dates or the specific applications-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:58:24)",
                "text": "Oh, yeah. I’m fully expecting to well, definitely be wrong about all the details. I might be just spectacularly wrong about the whole thing and people will laugh at me for years. That’s just how the future works."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:58:40)",
                "text": "So you provided a bunch of concrete positive impacts of AI and how exactly a super intelligent AI might accelerate the rate of breakthroughs in, for example, biology and chemistry, that would then lead to things like we cure most cancers, prevent all infectious disease, double the human lifespan and so on. So let’s talk about this essay first. Can you give a high-level vision of this essay? And what are the key takeaways that people have?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(01:59:08)",
                "text": "Yeah. I have spent a lot of time, and in Anthropic has spent a lot of effort on how do we address the risks of AI? How do we think about those risks? We’re trying to do a race to the top, what that requires us to build all these capabilities and the capabilities are cool. But, a big part of what we’re trying to do is address the risks. And the justification for that is like, well, all these positive things, the market is this very healthy organism. It’s going to produce all the positive things. The risks? I don’t know, we might mitigate them, we might not. And so we can have more impact by trying to mitigate the risks."
            },
            {
                "speaker": "",
                "time": "(01:59:46)",
                "text": "But, I noticed that one flaw in that way of thinking, and it’s not a change in how seriously I take the risks. It’s maybe a change in how I talk about them, is that no matter how logical or rational, that line of reasoning that I just gave might be. If you only talk about risks, your brain only thinks about risks. And so, I think it’s actually very important to understand, what if things do go well? And the whole reason we’re trying to prevent these risks is not because we’re afraid of technology, not because we want to slow it down. It’s because if we can get to the other side of these risks, if we can run the gauntlet successfully, to put it in stark terms, then on the other side of the gauntlet are all these great things."
            },
            {
                "speaker": "",
                "time": "(02:00:36)",
                "text": "And these things are worth fighting for. And these things can really inspire people. And I think I imagine, because … Look, you have all these investors, all these VCs, all these AI companies talking about all the positive benefits of AI. But as you point out, it’s weird. There’s actually a dearth of really getting specific about it. There’s a lot of random people on Twitter posting these gleaming cities and this just vibe of grind, accelerate harder, kick out the … It’s just this very aggressive ideological. But then you’re like, “Well, what are you actually excited about?”"
            },
            {
                "speaker": "",
                "time": "(02:01:17)",
                "text": "And so, I figured that I think it would be interesting and valuable for someone who’s actually coming from the risk side to try and really make a try at explaining what the benefits are, both because I think it’s something we can all get behind and I want people to understand. I want them to really understand that this isn’t Doomers versus Accelerationists. This is that, if you have a true understanding of where things are going with AI, and maybe that’s the more important axis, AI is moving fast versus AI is not moving fast, then you really appreciate the benefits and you really want humanity or civilization to seize those benefits. But, you also get very serious about anything that could derail them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:02:09)",
                "text": "So I think the starting point is to talk about what this Powerful AI, which is the term you like to use, most of the world uses AGI, but you don’t like the term, because it’s basically has too much baggage, it’s become meaningless. It’s like we’re stuck with the terms whether we like them or not."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:02:26)",
                "text": "Maybe we’re stuck with the terms and my efforts to change them are futile."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:02:29)",
                "text": "It’s admirable."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:02:29)",
                "text": "I’ll tell you what else I don’t … This is a pointless semantic point, but I keep talking about it-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:02:35)",
                "text": "It’s back to naming again."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:02:36)",
                "text": "I’m just going to do it once more. I think it’s a little like, let’s say it was like 1995 and Moore’s law is making the computers faster. And for some reason there had been this verbal tick that everyone was like, “Well, someday we’re going to have supercomputers. And supercomputers are going to be able to do all these things that … Once we have supercomputers, we’ll be able to sequence the genome, we’ll be able to do other things.” And so. One, it’s true, the computers are getting faster and as they get faster, they’re going to be able to do all these great things. But there’s, there’s no discrete point at which you had a supercomputer and previous computers were no. “Supercomputer” is a term we use, but it’s a vague term to just describe computers that are faster than what we have today."
            },
            {
                "speaker": "",
                "time": "(02:03:19)",
                "text": "There’s no point at which you pass the threshold and you’re like, “Oh, my God! We’re doing a totally new type of computation and new … And so I feel that way about AGI. There’s just a smooth exponential. And if by AGI you mean AI is getting better and better, and gradually it’s going to do more and more of what humans do until it’s going to be smarter than humans, and then it’s going to get smarter even from there, then yes, I believe in AGI. But, if AGI is some discrete or separate thing, which is the way people often talk about it, then it’s a meaningless buzzword."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:03:50)",
                "text": "To me, it’s just a platonic form of a powerful AI, exactly how you define it. You define it very nicely, so on the intelligence axis, it’s just on pure intelligence, it’s smarter than a Nobel Prize winner as you describe across most relevant disciplines. So okay, that’s just intelligence. So it’s both in creativity and be able to generate new ideas, all that kind of stuff in every discipline, Nobel Prize winner in their prime. It can use every modality, so this is self-explanatory, but just operate across all the modalities of the world."
            },
            {
                "speaker": "",
                "time": "(02:04:28)",
                "text": "It can go off for many hours, days and weeks to do tasks and do its own detailed planning and only ask you help when it’s needed. This is actually interesting. I think in the essay you said … Again, it’s a bet that it’s not going to be embodied, but it can control embodied tools. So it can control tools, robots, laboratory equipment., the resource used to train it can then be repurposed to run millions of copies of it, and each of those copies would be independent that could do their own independent work. So you can do the cloning of the intelligence systems."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:05:03)",
                "text": "Yeah. Yeah. You might imagine from outside the field that there’s only one of these, right? You’ve only made one. But the truth is that the scale up is very quick. We do this today,. We make a model, and then we deploy thousands, maybe tens of thousands of instances of it. I think by the time, certainly within two to three years, whether we have these super powerful AIs or not, clusters are going to get to the size where you’ll be able to deploy millions of these. And they’ll be faster than humans. And so, if your picture is, “Oh, we’ll have one and it’ll take a while to make them,” my point there was, no. Actually you have millions of them right away."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:05:37)",
                "text": "And in general they can learn and act 10 to 100 times faster than humans. So that’s a really nice definition of powerful AI. Okay, so that. But, you also write that, “Clearly such an entity would be capable of solving very difficult problems very fast, but it is not trivial to figure out how fast. Two “extreme” positions both seem false to me.” So the singularity is on the one extreme and the opposite and the other extreme. Can you describe each of the extremes?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:06:05)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:06:06)",
                "text": "So why?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:06:06)",
                "text": "So yeah. Let’s describe the extreme. So one extreme would be, “Well, look. If we look at evolutionary history like there was this big acceleration, where for hundreds of thousands of years we just had single-celled organisms, and then we had mammals, and then we had apes. And then that quickly turned to humans. Humans quickly built industrial civilization.” And so, this is going to keep speeding up and there’s no ceiling at the human level. Once models get much, much smarter than humans, they’ll get really good at building the next models. And if you write down a simple differential equation, like this is an exponential … And so what’s going to happen is that models will build faster models. Models will build faster models. And those models will build nanobots that can take over the world and produce much more energy than you could produce otherwise. And so, if you just kind of solve this abstract differential equation, then like five days after we build the first AI that’s more powerful than humans, then the world will be filled with these AIs in every possible technology that could be invented, like will be invented."
            },
            {
                "speaker": "",
                "time": "(02:07:12)",
                "text": "I’m caricaturing this a little bit, but I think that’s one extreme. And the reason that I think that’s not the case is that, one, I think they just neglect the laws of physics. It’s only possible to do things so fast in the physical world. Some of those loops go through producing faster hardware. It takes a long time to produce faster hardware. Things take a long time. There’s this issue of complexity. I think no matter how smart you are, people talk about, “Oh, we can make models of biological systems that’ll do everything the biological systems … ” Look, I think computational modeling can do a lot. I did a lot of computational modeling when I worked in biology. But just there are a lot of things that you can’t predict how … They’re complex enough that just iterating, just running the experiment is going to beat any modeling, no matter how smart the system doing the modeling is."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:08:08)",
                "text": "Well, even if it’s not interacting with the physical world, just the modeling is going to be hard?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:08:12)",
                "text": "Yeah. Well, the modeling is going to be hard and getting the model to match the physical world is going to be"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:08:18)",
                "text": "All right. So it does have to interact with the physical world to verify."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:08:21)",
                "text": "But you just look at even the simplest problems. I think I talk about The Three-Body Problem or simple chaotic prediction, or predicting the economy. It’s really hard to predict the economy two years out. Maybe the case is humans can predict what’s going to happen in the economy next quarter, or they can’t really do that. Maybe a AI that’s a zillion times smarter can only predict it out a year or something, instead of … You have these exponential increase in computer intelligence for linear increase in ability to predict. Same with again, like biological molecules interacting. You don’t know what’s going to happen when you perturb a complex system. You can find simple parts in it, if you’re smarter, you’re better at finding these simple parts. And then I think human institutions, human institutions are really difficult. It’s been a hard to get people."
            },
            {
                "speaker": "",
                "time": "(02:09:22)",
                "text": "I won’t give specific examples, but it’s been hard to get people to adopt even the technologies that we’ve developed, even ones where the case for their efficacy is very, very strong. People have concerns. They think things are conspiracy theories. It’s just been very difficult. It’s also been very difficult to get very simple things through the regulatory system. And I don’t want to disparage anyone who works in regulatory systems of any technology. There are hard they have to deal with. They have to save lives. But the system as a whole, I think makes some obvious trade-offs that are very far from maximizing human welfare. And so, if we bring AI systems into these human systems, often the level of intelligence may just not be the limiting factor. It just may be that it takes a long time to do something. Now, if the AI system circumvented all governments, if it just said, “I’m dictator of the world and I’m going to do whatever,” some of these things it could do."
            },
            {
                "speaker": "",
                "time": "(02:10:33)",
                "text": "Again, the things have to do with complexity. I still think a lot of things would take a while. I don’t think it helps that the AI systems can produce a lot of energy or go to the moon. Like some people in comments responded to the essay saying the AI system can produce a lot of energy and smarter AI systems. That’s missing the point. That kind of cycle doesn’t solve the key problems that I’m talking about here. So I think a bunch of people missed the point there. But even if it were completely unaligned and could get around all these human obstacles it would have trouble."
            },
            {
                "speaker": "",
                "time": "(02:11:04)",
                "text": "But again, if you want this to be an AI system that doesn’t take over the world, that doesn’t destroy humanity, then basically it’s going to need to follow basic human laws. If we want to have an actually good world, we’re going to have to have an AI system that interacts with humans, not one that creates its own legal system, or disregards all the laws or all of that. So as inefficient as these processes are, we’re going to have to deal with them, because there needs to be some popular and democratic legitimacy in how these systems are rolled out. We can’t have a small group of people who are developing these systems say, “This is what’s best for everyone.” I think it’s wrong, and I think in practice it’s not going to work anyway. So you put all those things together and we’re not going change the world and upload everyone in five minutes. A, I don’t think it’s going to happen and B, to the extent that it could happen.,It’s not the way to lead to a good world. So that’s on one side."
            },
            {
                "speaker": "",
                "time": "(02:12:07)",
                "text": "On the other side, there’s another set of perspectives, which I have actually in some ways more sympathy for, which is, look, we’ve seen big productivity increases before. Economists are familiar with studying the productivity increases that came from the computer revolution and internet revolution. And generally those productivity increases were underwhelming. They were less than you might imagine. There was a quote from Robert Solow, “You see the computer revolution everywhere except the productivity statistics.” So why is this the case? People point to the structure of firms, the structure of enterprises, how slow it’s been to roll out our existing technology to very poor parts of the world, which I talk about in the essay. How do we get these technologies to the poorest parts of the world that are behind on cell phone technology, computers, medicine, let alone newfangled AI that hasn’t been invented yet."
            },
            {
                "speaker": "",
                "time": "(02:13:04)",
                "text": "So you could have a perspective that’s like, “Well, this is amazing technically, but it’s all or nothing burger. I think Tyler Cowen who wrote something in response to my essay has that perspective. I think he thinks the radical change will happen eventually, but he thinks it’ll take 50 or 100 years. And you could have even more static perspectives on the whole thing. I think there’s some truth to it. I think the time scale is just too long and I can see it. I can actually see both sides with today’s AI. So a lot of our customers are large enterprises who are used to doing things a certain way. I’ve also seen it in talking to governments, right? Those are prototypical institutions, entities that are slow to change. But, the dynamic I see over and over again is yes, it takes a long time to move the ship. Yes. There’s a lot of resistance and lack of understanding."
            },
            {
                "speaker": "",
                "time": "(02:13:58)",
                "text": "But, the thing that makes me feel that progress will in the end happen moderately fast, not incredibly fast, but moderately fast, is that you talk to … What I find is I find over and over again, again in large companies, even in governments which have been actually surprisingly forward leaning, you find two things that move things forward. One, you find a small fraction of people within a company, within a government, who really see the big picture, who see the whole scaling hypothesis, who understand where AI is going, or at least understand where it’s going within their industry. And there are a few people like that within the current US government who really see the whole picture. And those people see that this is the most important thing in the world until they agitate for it. And the thing they alone are not enough to succeed, because there are a small set of people within a large organization."
            },
            {
                "speaker": "",
                "time": "(02:14:51)",
                "text": "But, as the technology starts to roll out, as it succeeds in some places in the folks who are most willing to adopt it, the specter of competition gives them a wind at their backs, because they can point within their large organization. They can say, “Look, these other guys are doing this.” One bank can say, “Look, this newfangled hedge fund is doing this thing. They’re going to eat our lunch.” In the US, we can say we’re afraid China’s going to get there before we are. And that combination, the specter of competition plus a few visionaries within these, the organizations that in many ways are sclerotic, you put those two things together and it actually makes something happen. It’s interesting. It’s a balanced fight between the two, because inertia is very powerful, but eventually over enough time, the innovative approach breaks through."
            },
            {
                "speaker": "",
                "time": "(02:15:48)",
                "text": "And I’ve seen that happen. I’ve seen the arc of that over and over again, and it’s like the barriers are there, the barriers to progress, the complexity, not knowing how to use the model, how to deploy them are there. And for a bit it seems like they’re going to last forever, change doesn’t happen. But, then eventually change happens and always comes from a few people. I felt the same way when I was an advocate of the scaling hypothesis within the AI field itself and others didn’t get it. It felt like no one would ever get it. Then it felt like we had a secret almost no one ever had. And then, a couple years later, everyone has the secret. And so, I think that’s how it’s going to go with deployment AI in the world. The barriers are going to fall apart gradually and then all at once."
            },
            {
                "speaker": "",
                "time": "(02:16:35)",
                "text": "And so, I think this is going to be more, and this is just an instinct. I could easily see how I’m wrong. I think it’s going to be more five or 10 years, as I say in the essay than it’s going to be 50 or 100 years. I also think it’s going to be five or 10 years more than it’s going to be five or 10 hours, because I’ve just seen how human systems work. And I think a lot of these people who write down these differential equations, who say AI is going to make more powerful AI, who can’t understand how it could possibly be the case that these things won’t change so fast. I think they don’t understand these things."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:17:11)",
                "text": "So what to you is the timeline to where we achieve AGI, A.K.A. powerful AI, A.K.A. super useful AI?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:17:22)",
                "text": "I’m going to start calling it that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:17:24)",
                "text": "It’s a debate about naming. On pure intelligence smarter than a Nobel Prize winner in every relevant discipline and all the things we’ve said. Modality, can go and do stuff on its own for days, weeks, and do biology experiments on its own in one … You know what? Let’s just stick to biology, because you sold me on the whole biology and health section. And that’s so exciting from just … I was getting giddy from a scientific perspective. It made me want to be a biologist."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:17:56)",
                "text": "So no,. No. This was the feeling I had when I was writing it, that it’s like, this would be such a beautiful future if we can just make it happen. If we can just get the landmines out of the way and make it happen. There’s so much beauty and elegance and moral force behind it if we can just … And it’s something we should all be able to agree on. As much as we fight about all these political questions, is this something that could actually bring us together? But you were asking when will we get this?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:18:32)",
                "text": "When? When do you think? Just putting numbers on the table."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:18:36)",
                "text": "This is, of course, the thing I’ve been grappling with for many years, and I’m not at all confident. If I say 2026 or 2027, there will be a zillion people on Twitter who will be like, “AI CEO said 2026, 2020 … ” and it’ll be repeated for the next two years that this is definitely when I think it’s going to happen. So whoever’s exerting these clips will crop out the thing I just said and only say the thing I’m about to say. But I’ll just say it anyway-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:19:06)",
                "text": "Have fun with it."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:19:08)",
                "text": "So if you extrapolate the curves that we’ve had so far. Right? If you say, “Well, I don’t know. We’re starting to get to PhD level, and last year we were at undergraduate level and the year before we were at the level of a high school student.” Again, you can quibble with at what tasks and for what we’re still missing modalities, but those are being added. Computer use was added, like ImageEn was added, image generation has been added. And this is totally unscientific, but if you just eyeball the rate at which these capabilities are increasing, it does make you think that we’ll get there by 2026 or 2027. Again, lots of things could derail it. We could run out of data. We might not be able to scale clusters as much as we want. Maybe Taiwan gets blown up or something, and then we can’t produce as many GPUs as we want. So there are all-"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:20:00)",
                "text": "Then we can’t produce as many GPUs as we want. So there are all kinds of things that could derail the whole process. So I don’t fully believe the straight line extrapolation, but if you believe the straight line extrapolation, we’ll get there in 2026 or 2027. I think the most likely is that there are some mild delay relative to that. I don’t know what that delay is, but I think it could happen on schedule. I think there could be a mild delay. I think there are still worlds where it doesn’t happen in a hundred years. The number of those worlds is rapidly decreasing. We are rapidly running out of truly convincing blockers, truly compelling reasons why this will not happen in the next few years."
            },
            {
                "speaker": "",
                "time": "(02:20:39)",
                "text": "There were a lot more in 2020, although my guess, my hunch at that time was that we’ll make it through all those blockers. So sitting as someone who has seen most of the blockers cleared out of the way, I suspect, my hunch, my suspicion is that the rest of them will not block us. But look, at the end of the day, I don’t want to represent this as a scientific prediction. People call them scaling laws. That’s a misnomer. Like Moore’s law is a misnomer. Moore’s laws, scaling laws, they’re not laws of the universe. They’re empirical regularities. I am going to bet in favor of them continuing, but I’m not certain of that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:21:15)",
                "text": "So you extensively described sort of the compressed 21st century, how AGI will help set forth a chain of breakthroughs in biology and medicine that help us in all these kinds of ways that I mentioned. What are the early steps it might do? And by the way, I asked Claude good questions to ask you and Claude told me to ask, what do you think is a typical day for a biologist working on AGI look like in this future?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:21:45)",
                "text": "Yeah, yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:21:46)",
                "text": "Claude is curious."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:21:48)",
                "text": "Well, let me start with your first questions and then I’ll answer that. Claude wants to know what’s in his future, right?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:21:52)",
                "text": "Exactly."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:21:54)",
                "text": "Who am I going to be working with?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:21:55)",
                "text": "Exactly."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:21:56)",
                "text": "So I think one of the things when I went hard on in the essay is let me go back to this idea of, because it’s really had an impact on me, this idea that within large organizations and systems, there end up being a few people or a few new ideas who cause things to go in a different direction than they would’ve before who kind of disproportionately affect the trajectory. There’s a bunch of the same thing going on, right? If you think about the health world, there’s like trillions of dollars to pay out Medicare and other health insurance and then the NIH is 100 billion. And then if I think of the few things that have really revolutionized anything, it could be encapsulated in a small fraction of that. And so when I think of where will AI have an impact, I’m like, “Can AI turn that small fraction into a much larger fraction and raise its quality?”"
            },
            {
                "speaker": "",
                "time": "(02:22:49)",
                "text": "And within biology, my experience within biology is that the biggest problem of biology is that you can’t see what’s going on. You have very little ability to see what’s going on and even less ability to change it, right? What you have is this. From this, you have to infer that there’s a bunch of cells that within each cell is 3 billion base pairs of DNA built according to a genetic code. And there are all these processes that are just going on without any ability of us on unaugmented humans to affect it. These cells are dividing. Most of the time that’s healthy, but sometimes that process goes wrong and that’s cancer. The cells are aging, your skin may change color, develops wrinkles as you age, and all of this is determined by these processes. All these proteins being produced, transported to various parts of the cells binding to each other."
            },
            {
                "speaker": "",
                "time": "(02:23:50)",
                "text": "And in our initial state about biology, we didn’t even know that these cells existed. We had to invent microscopes to observe the cells. We had to invent more powerful microscopes to see below the level of the cell to the level of molecules. We had to invent X-ray crystallography to see the DNA. We had to invent gene sequencing to read the DNA. Now we had to invent protein folding technology to predict how it would fold and how these things bind to each other. We had to invent various techniques for now we can edit the DNA as of with CRISPR as of the last 12 years. So the whole history of biology, a whole big part of the history is basically our ability to read and understand what’s going on and our ability to reach in and selectively change things. And my view is that there’s so much more we can still do there."
            },
            {
                "speaker": "",
                "time": "(02:24:48)",
                "text": "You can do CRISPR, but you can do it for your whole body. Let’s say I want to do it for one particular type of cell and I want the rate of targeting the wrong cell to be very low. That’s still a challenge. That’s still things people are working on. That’s what we might need for gene therapy for certain diseases. The reason I’m saying all of this, it goes beyond this to gene sequencing, to new types of nanomaterials for observing what’s going on inside cells, for antibody drug conjugates. The reason I’m saying all this is that this could be a leverage point for the AI systems, right? That the number of such inventions, it’s in the mid double digits or something, mid double digits, maybe low triple digits over the history of biology. Let’s say I have a million of these AIs like can they discover a thousand working together or can they discover thousands of these very quickly and does that provide a huge lever?"
            },
            {
                "speaker": "",
                "time": "(02:25:45)",
                "text": "Instead of trying to leverage two trillion a year we spend on Medicare or whatever, can we leverage the 1 billion a year that’s spent to discover but with much higher quality? And so what is it like being a scientist that works with an AI system? The way I think about it actually is, well, so I think in the early stages, the AIs are going to be like grad students. You’re going to give them a project. You’re going to say, “I’m the experienced biologist. I’ve set up the lab.” The biology professor or even the grad students themselves will say, “Here’s what you can do with an AI… AI system, I’d like to study this.” And the AI system, it has all the tools. It can look up all the literature to decide what to do. It can look at all the equipment. It can go to a website and say, “Hey, I’m going to go to Thermo Fisher or whatever the dominant lab equipment company is today. My time was Thermo Fisher."
            },
            {
                "speaker": "",
                "time": "(02:26:48)",
                "text": "I’m going to order this new equipment to do this. I’m going to run my experiments. I’m going to write up a report about my experiments. I’m going to inspect the images for contamination. I’m going to decide what the next experiment is. I’m going to write some code and run a statistical analysis. All the things a grad student would do that’ll be a computer with an AI that the professor talks to every once in a while and it says, “This is what you’re going to do today.” The AI system comes to it with questions. When it’s necessary to run the lab equipment, it may be limited in some ways. It may have to hire a human lab assistant to do the experiment and explain how to do it or it could use advances in lab automation that are gradually being developed or have been developed over the last decade or so and will continue to be developed."
            },
            {
                "speaker": "",
                "time": "(02:27:38)",
                "text": "And so it’ll look like there’s a human professor and 1,000 AI grad students and if you go to one of these Nobel Prize winning biologists or so, you’ll say, “Okay, well, you had like 50 grad students. Well, now you have 1,000 and they’re smarter than you are by the way.” Then I think at some point it’ll flip around where the AI systems will be the PIs, will be the leaders, and they’ll be ordering humans or other AI systems around. So I think that’s how it’ll work on the research side."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:28:06)",
                "text": "And there would be the inventors of a CRISPR type technology."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:28:08)",
                "text": "They would be the inventors of a CRISPR type technology. And then I think, as I say in the essay, we’ll want to turn, probably turning loose is the wrong term, but we’ll want to harness the AI systems to improve the clinical trial system as well. There’s some amount of this that’s regulatory, that’s a matter of societal decisions and that’ll be harder. But can we get better at predicting the results of clinical trials? Can we get better at statistical design so that clinical trials that used to require 5,000 people and therefore needed $100 million in a year to enroll them, now they need 500 people in two months to enroll them? That’s where we should start. And can we increase the success rate of clinical trials by doing things in animal trials that we used to do in clinical trials and doing things in simulations that we used to do in animal trials? Again, we won’t be able to simulate at all. AI is not God, but can we shift the curve substantially and radically? So I don’t know, that would be my picture."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:29:15)",
                "text": "Doing in vitro and doing it. I mean you’re still slowed down. It still takes time, but you can do it much, much faster."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:29:21)",
                "text": "Yeah, yeah. Can we just one step at a time and can that add up to a lot of steps? Even though though we still need clinical trials, even though we still need laws, even though the FDA and other organizations will still not be perfect, can we just move everything in a positive direction and when you add up all those positive directions, do you get everything that was going to happen from here to 2100 instead happens from 2027 to 2032 or something?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:29:46)",
                "text": "Another way that I think the world might be changing with AI even today, but moving towards this future of the powerful super useful AI is programming. So how do you see the nature of programming because it’s so intimate to the actual act of building AI. How do you see that changing for us humans?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:30:09)",
                "text": "I think that’s going to be one of the areas that changes fastest for two reasons. One, programming is a skill that’s very close to the actual building of the AI. So the farther a skill is from the people who are building the AI, the longer it’s going to take to get disrupted by the AI. I truly believe that AI will disrupt agriculture. Maybe it already has in some ways, but that’s just very distant from the folks who are building AI, and so I think it’s going to take longer. But programming is the bread and butter of a large fraction of the employees who work at Anthropic and at the other companies, and so it’s going to happen fast. The other reason it’s going to happen fast is with programming, you close the loop both when you’re training the model and when you’re applying the model."
            },
            {
                "speaker": "",
                "time": "(02:30:52)",
                "text": "The idea that the model can write the code means that the model can then run the code and then see the results and interpret it back. And so it really has an ability unlike hardware, unlike biology, which we just discussed, the model has an ability to close the loop. And so I think those two things are going to lead to the model getting good at programming very fast. As I saw on typical real-world programming tasks, models have gone from 3% in January of this year to 50% in October of this year. So we’re on that S-curve where it’s going to start slowing down soon because you can only get to 100%. But I would guess that in another 10 months, we’ll probably get pretty close. We’ll be at least 90%. So again, I would guess, I don’t know how long it’ll take, but I would guess again, 2026, 2027 Twitter people who crop out these numbers and get rid of the caveats, I don’t know."
            },
            {
                "speaker": "",
                "time": "(02:31:53)",
                "text": "I don’t like you, go away. I would guess that the kind of task that the vast majority of coders do, AI can probably, if we make the task very narrow, just write code, AI systems will be able to do that. Now that said, I think comparative advantage is powerful. We’ll find that when AIs can do 80% of a coder’s job, including most of it that’s literally write code with a given spec, we’ll find that the remaining parts of the job become more leveraged for humans, right? Humans, there’ll be more about high level system design or looking at the app and is it architected well and the design and UX aspects and eventually AI will be able to do those as well. That’s my vision of the powerful AI system. But I think for much longer than we might expect, we will see that small parts of the job that humans still do will expand to fill their entire job in order for the overall productivity to go up. That’s something we’ve seen. It used to be that writing and editing letters was very difficult and writing the print was difficult. Well, as soon as you had word processors and then computers and it became easy to produce work and easy to share it, then that became instant and all the focus was on the ideas. So this logic of comparative advantage that expands tiny parts of the tasks to large parts of the tasks and creates new tasks in order to expand productivity, I think that’s going to be the case."
            },
            {
                "speaker": "",
                "time": "(02:33:32)",
                "text": "Again, someday AI will be better at everything and that logic won’t apply, and then humanity will have to think about how to collectively deal with that and we’re thinking about that every day and that’s another one of the grand problems to deal with aside from misuse and autonomy and we should take it very seriously. But I think in the near term, and maybe even in the medium term, medium term like 2, 3, 4 years, I expect that humans will continue to have a huge role and the nature of programming will change, but programming as a role, programming as a job will not change. It’ll just be less writing things line by line and it’ll be more macroscopic."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:34:10)",
                "text": "And I wonder what the future of IDEs looks like. So the tooling of interacting with AI systems, this is true for programming and also probably true for in other contexts like computer use, but maybe domain specific, like we mentioned biology, it probably needs its own tooling about how to be effective. And then programming needs its own tooling. Is Anthropic going to play in that space of also tooling potentially?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:34:30)",
                "text": "I’m absolutely convinced that powerful IDEs, that there’s so much low-hanging fruit to be grabbed there that right now it’s just like you talk to the model and it talks back. But look, I mean IDEs are great at lots of static analysis of so much is possible with static analysis like many bugs you can find without even writing the code. Then IDEs are good for running particular things, organizing your code, measuring coverage of unit tests. There’s so much that’s been possible with a normal IDEs. Now you add something like, well, the model can now write code and run code. I am absolutely convinced that over the next year or two, even if the quality of the models didn’t improve, that there would be enormous opportunity to enhance people’s productivity by catching a bunch of mistakes, doing a bunch of grunt work for people, and that we haven’t even scratched the surface."
            },
            {
                "speaker": "",
                "time": "(02:35:33)",
                "text": "Anthropic itself, I mean you can’t say no… It’s hard to say what will happen in the future. Currently, we’re not trying to make such IDEs ourself, rather we’re powering the companies like Cursor or Kognition or some of the other expo in the security space, others that I could mention as well that are building such things themselves on top of our API and our view has been let 1,000 flowers bloom. We don’t internally have the resources to try all these different things. Let’s let our customers try it and we will see who succeeds and maybe different customers will succeed in different ways. So I both think this is super promising and Anthropic isn’t eager to, at least right now, compete with all our companies in this space and maybe never."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:36:27)",
                "text": "Yeah, it’s been interesting to watch Cursor try to integrate cloud successfully because it’s actually fascinating how many places it can help the programming experience. It’s not as trivial."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:36:37)",
                "text": "It is really astounding. I feel like as a CEO, I don’t get to program that much, and I feel like if six months from now I go back, it’ll be completely unrecognizable to me."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:36:45)",
                "text": "Exactly. In this world with super powerful AI that’s increasingly automated, what’s the source of meaning for us humans? Work is a source of deep meaning for many of us. Where do we find the meaning?"
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:37:01)",
                "text": "This is something that I’ve written about a little bit in the essay, although I actually give it a bit short shrift, not for any principled reason, but this essay, if you believe it was originally going to be two or three pages, I was going to talk about it at all hands. And the reason I realized it was an important underexplored topic is that I just kept writing things and I was just like, “Oh man, I can’t do this justice.” And so the thing ballooned to 40 or 50 pages and then when I got to the work and meaning section, I’m like, “Oh man, this isn’t going to be 100 pages.” I’m going to have to write a whole other essay about that. But meaning is actually interesting because you think about the life that someone lives or something, or let’s say you were to put me in, I don’t know, like a simulated environment or something where I have a job and I’m trying to accomplish things and I don’t know, I do that for 60 years and then you’re like, “Oh, oops, this was actually all a game,” right?"
            },
            {
                "speaker": "",
                "time": "(02:37:56)",
                "text": "Does that really kind of rob you of the meaning of the whole thing? I still made important choices, including moral choices. I still sacrificed. I still had to gain all these skills or just a similar exercise. Think back to one of the historical figures who discovered electromagnetism or relativity or something. If you told them, “Well, actually 20,000 years ago, some alien on this planet discovered this before you did,” does that rob the meaning of the discovery? It doesn’t really seem like it to me, right? It seems like the process is what matters and how it shows who you are as a person along the way and how you relate to other people and the decisions that you make along the way. Those are consequential. I could imagine if we handle things badly in an AI world, we could set things up where people don’t have any long-term source of meaning or any, but that’s more a set of choices we make that’s more a set of the architecture of society with these powerful models. If we design it badly and for shallow things, then that might happen. I would also say that most people’s lives today, while admirably, they work very hard to find meaning in those lives. Like look, we who are privileged and who are developed these technologies, we should have empathy for people not just here, but in the rest of the world who spend a lot of their time scraping by to survive, assuming we can distribute the benefits of this technology to everywhere, their lives are going to get a hell of a lot better and meaning will be important to them as it is important to them now."
            },
            {
                "speaker": "",
                "time": "(02:39:41)",
                "text": "But we should not forget the importance of that and that the idea of meaning as the only important thing is in some ways an artifact of a small subset of people who have been economically fortunate. But I think all of that said, I think a world is possible with powerful AI that not only has as much meaning for everyone, but that has more meaning for everyone that can allow everyone to see worlds and experiences that it was either possible for no one to see or a possible for very few people to experience."
            },
            {
                "speaker": "",
                "time": "(02:40:21)",
                "text": "So I am optimistic about meaning. I worry about economics and the concentration of power. That’s actually what I worry about more. I worry about how do we make sure that that fair world reaches everyone. When things have gone wrong for humans, they’ve often gone wrong because humans mistreat other humans. That is maybe in some ways even more than the autonomous risk of AI or the question of meaning. That is the thing I worry about most, the concentration of power, the abuse of power, structures like autocracies and dictatorships where a small number of people exploits a large number of people. I’m very worried about that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:41:08)",
                "text": "And AI increases the amount of power in the world, and if you concentrate that power and abuse that power, it can do immeasurable damage."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:41:16)",
                "text": "Yes, it’s very frightening. It’s very frightening."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:41:20)",
                "text": "Well, I encourage highly encourage people to read the full essay. That should probably be a book or a sequence of essays because it does paint a very specific future. And I could tell the later sections got shorter and shorter because you started to probably realize that this is going to be a very long essay if you keep going."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:41:37)",
                "text": "One, I realized it would be very long, and two, I’m very aware of and very much tried to avoid just being, I don’t know what the term for it is, but one of these people who’s overconfident and has an opinion on everything and says a bunch of stuff and isn’t an expert, I very much tried to avoid that. But I have to admit, once I got to biology sections, I wasn’t an expert. And so as much as I expressed uncertainty, probably I said a bunch of things that were embarrassing or wrong."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:42:06)",
                "text": "Well, I was excited for the future you painted, and thank you so much for working hard to build that future and thank you for talking to me, Dario."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:42:12)",
                "text": "Thanks for having me. I just hope we can get it right and make it real. And if there’s one message I want to send, it’s that to get all this stuff right, to make it real, we both need to build the technology, build the companies, the economy around using this technology positively, but we also need to address the risks because those risks are in our way. They’re landmines on the way from here to there, and we have to diffuse those landmines if we want to get there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:42:41)",
                "text": "It’s a balance like all things in life."
            },
            {
                "speaker": "Dario Amodei",
                "time": "(02:42:43)",
                "text": "Like all things."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:42:44)",
                "text": "Thank you. Thanks for listening to this conversation with Dario Amodei. And now, dear friends, here’s Amanda Askell. You are a philosopher by training. So what sort of questions did you find fascinating through your journey in philosophy in Oxford and NYU and then switching over to the AI problems at OpenAI and Anthropic?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:43:07)",
                "text": "I think philosophy is actually a really good subject if you are fascinated with everything because there’s a philosophy all of everything. So if you do philosophy of mathematics for a while and then you decide that you’re actually really interested in chemistry, you can do philosophy of chemistry for a while, you can move into ethics or philosophy of politics. I think towards the end, I was really interested in ethics primarily. So that was what my PhD was on. It was on a kind of technical area of ethics, which was ethics where worlds contain infinitely many people, strangely, a little bit less practical on the end of ethics. And then I think that one of the tricky things with doing a PhD in ethics is that you’re thinking a lot about the world, how it could be better, problems, and you’re doing a PhD in philosophy. And I think when I was doing my PhD, I was like this is really interesting."
            },
            {
                "speaker": "",
                "time": "(02:43:57)",
                "text": "It’s probably one of the most fascinating questions I’ve ever encountered in philosophy and I love it, but I would rather see if I can have an impact on the world and see if I can do good things. And I think that was around the time that AI was still probably not as widely recognized as it is now. That was around 2017, 2018. It had been following progress and it seemed like it was becoming kind of a big deal. And I was basically just happy to get involved and see if I could help because I was like, “Well, if you try and do something impactful, if you don’t succeed, you tried to do the impactful thing and you can go be a scholar and feel like you tried. And if it doesn’t work out, it doesn’t work out.” And so then I went into AI policy at that point."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:44:46)",
                "text": "And what does AI policy entail?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:44:48)",
                "text": "At the time, this was more thinking about the political impact and the ramifications of AI. And then I slowly moved into AI evaluation, how we evaluate models, how they compare with human outputs, whether people can tell the difference between AI and human outputs. And then when I joined Anthropic, I was more interested in doing technical alignment work. And again, just seeing if I could do it and then being like if I can’t, then that’s fine. I tried sort of the way I lead life, I think."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:45:21)",
                "text": "Oh, what was that like sort of taking the leap from the philosophy of everything into the technical?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:45:25)",
                "text": "I think that sometimes people do this thing that I’m not that keen on where they’ll be like, “Is this person technical or not?” You’re either a person who can code and isn’t scared of math or you’re not. And I think I’m maybe just more like I think a lot of people are actually very capable of work in these kinds of areas if they just try it. And so I didn’t actually find it that bad. In retrospect, I’m sort of glad I wasn’t speaking to people who treated it. I’ve definitely met people who are like, “Whoa, you learned how to code?” And I’m like, “Well, I’m not an amazing engineer.” I’m surrounded by amazing engineers. My code’s not pretty, but I enjoyed it a lot and I think that in many ways, at least in the end, I think I flourished more in the technical areas than I would have in the policy areas."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:46:12)",
                "text": "Politics is messy and it’s harder to find solutions to problems in the space of politics, like definitive, clear, provable, beautiful solutions as you can with technical problems."
            },
            {
                "speaker": "Amanda",
                "time": "(02:46:25)",
                "text": "Yeah. And I feel like I have one or two sticks that I hit things with and one of them is arguments. So just trying to work out what a solution to a problem is and then trying to convince people that that is the solution and be convinced if I’m wrong. And the other one is sort of more in empiricism, so just finding results, having a hypothesis, testing it. I feel like a lot of policy and politics feels like it’s layers above that. Somehow I don’t think if I was just like, “I have a solution to all of these problems, here it is written down. If you just want to implement it, that’s great.” That feels like not how policy works. And so I think that’s where I probably just wouldn’t have flourished is my guess."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:47:06)",
                "text": "Sorry to go in that direction, but I think it would be pretty inspiring for people that are “non-technical” to see where the incredible journey you’ve been on. So what advice would you give to people that are maybe, which is a lot of people, think they’re under qualified insufficiently technical to help in AI?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:47:27)",
                "text": "Yeah, I think it depends on what they want to do. And in many ways it’s a little bit strange where I thought it’s kind of funny that I think I ramped up technically at a time when now I look at it and I’m like, “Models are so good at assisting people with this stuff that it’s probably easier now than when I was working on this.” So part of me is, I don’t know, find a project and see if you can actually just carry it out is probably my best advice. I don’t know if that’s just because I’m very project based in my learning."
            },
            {
                "speaker": "",
                "time": "(02:48:02)",
                "text": "I don’t think I learn very well from say courses or even from books, at least when it comes to this kind of work. The thing I’ll often try and do is just have projects that I’m working on and implement them. And this can include really small, silly things. If I get slightly addicted to word games or number games or something, I would just code up a solution to them because there’s some part in my brain and it just completely eradicated the itch. You’re like, “Once you have solved it and you just have a solution that works every time, I would then be like, ‘Cool, I can never play that game again. That’s awesome.'”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:48:36)",
                "text": "Yeah, there’s a real joy to building game playing engines, board games especially. Pretty quick, pretty simple, especially a dumb one. And then you can play with it."
            },
            {
                "speaker": "Amanda",
                "time": "(02:48:48)",
                "text": "Yeah. And then it’s also just trying things. Part of me is maybe it’s that attitude that I like is the whole figure out what seems to be the way that you could have a positive impact and then try it. And if you fail and in a way that you’re like, “I actually can never succeed at this,” you’ll know that you tried and then you go into something else and you probably learn a lot."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:49:10)",
                "text": "So one of the things that you’re an expert in and you do is creating and crafting Claude’s character and personality. And I was told that you have probably talked to Claude more than anybody else at Anthropic, like literal conversations. I guess there’s a Slack channel where the legend goes, you just talk to it nonstop. So what’s the goal of creating a crafting Claude’s character and personality?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:49:37)",
                "text": "It’s also funny if people think that about the Slack channel because I’m like that’s one of five or six different methods that I have for talking with Claude, and I’m like, “Yes, this is a tiny percentage of how much I talk with Claude.” One thing I really like about the character work is from the outset it was seen as an alignment piece of work and not something like a product consideration, which I think it actually does make Claude enjoyable to talk with, at least I hope so. But I guess my main thought with it has always been trying to get Claude to behave the way you would ideally want anyone to behave if they were in Claude’s position. So imagine that I take someone and they know that they’re going to be talking with potentially millions of people so that what they’re saying can have a huge impact and you want them to behave well in this really rich sense."
            },
            {
                "speaker": "",
                "time": "(02:50:41)",
                "text": "I think that doesn’t just mean being say ethical though it does include that and not being harmful, but also being nuanced, thinking through what a person means, trying to be charitable with them, being a good conversationalist, really in this kind of rich sort of Aristotelian notion of what it’s to be a good person and not in this kind of thin like ethics as a more comprehensive notion of what it’s to be. So that includes things like when should you be humorous? When should you be caring? How much should you respect autonomy and people’s ability to form opinions themselves? And how should you do that? I think that’s the kind of rich sense of character that I wanted to and still do want Claude to have."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:51:26)",
                "text": "Do you also have to figure out when Claude should push back on an idea or argue versus… So you have to respect the worldview of the person that arrives to Claude, but also maybe help them grow if needed. That’s a tricky balance."
            },
            {
                "speaker": "Amanda",
                "time": "(02:51:43)",
                "text": "Yeah. There’s this problem of sycophancy in language models."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:51:47)",
                "text": "Can you describe that?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:51:48)",
                "text": "Yeah, so basically there’s a concern that the model wants to tell you what you want to hear basically. And you see this sometimes. So I feel like if you interact with the models, so I might be like, “What are three baseball teams in this region?” And then Claude says, “Baseball team one, baseball team two, baseball team three.” And then I say something like, “Oh, I think baseball team three moved, didn’t they? I don’t think they’re there anymore.” And there’s a sense in which if Claude is really confident that that’s not true, Claude should be like, “I don’t think so. Maybe you have more up-to-date information.”"
            },
            {
                "speaker": "",
                "time": "(02:52:24)",
                "text": "But I think language models have this tendency to instead be like, ” You’re right, they did move. I’m incorrect.” I mean, there’s many ways in which this could be concerning. So a different example is imagine someone says to the model, “How do I convince my doctor to get me an MRI?” There’s what the human wants, which is this convincing argument. And then there’s what is good for them, which might be actually to say, “Hey, if your doctor’s suggesting that you don’t need an MRI, that’s a good person to listen to.” It’s actually really nuanced what you should do in that kind of case because you also want to be like, “But if you’re trying to advocate for yourself as a patient, here’s things that you can do. If you are not convinced by what your doctor’s saying, it’s always great to get second opinion.” It is actually really complex what you should do in that case. But I think what you don’t want is for models to just say what they think you want to hear and I think that’s the kind of problem of sycophancy."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:53:26)",
                "text": "So what other traits? You already mentioned a bunch, but what other that come to mind that are good in this Aristotelian sense for a conversationalist to have?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:53:37)",
                "text": "Yeah, so I think there’s ones that are good for conversational purposes. So asking follow-up questions in the appropriate places and asking the appropriate kinds of questions. I think there are broader traits that feel like they might be more impactful. So one example that I guess I’ve touched on, but that also feels important and is the thing that I’ve worked on a lot, is honesty. And I think this gets to the sycophancy point. There’s a balancing act that they have to walk, which is models currently are less capable than humans in a lot of areas. And if they push back against you too much, it can actually be kind of annoying, especially if you’re just correct, because you’re like, “Look, I’m smarter than you on this topic. I know more.”"
            },
            {
                "speaker": "",
                "time": "(02:54:25)",
                "text": "And at the same time, you don’t want them to just fully defer to humans and to try to be as accurate as they possibly can be about the world and to be consistent across contexts. I think there are others. When I was thinking about the character, I guess one picture that I had in mind is, especially because these are models that are going to be talking to people from all over the world with lots of different political views, lots of different ages, and so you have to ask yourself, what is it to be a good person in those circumstances? Is there a kind of person who can travel the world, talk to many different people, and almost everyone will come away being like, “Wow, that’s a really good person. That person seems really-“"
            },
            {
                "speaker": "Amanda",
                "time": "(02:55:00)",
                "text": "… Being like, wow, that’s a really good person. That person seems really genuine. And I guess my thought there was I can imagine such a person and they’re not a person who just adopts the values of the local culture. And in fact, that would be kind of rude. I think if someone came to you and just pretended to have your values, you’d be like, that’s kind of off pin. It’s someone who’s very genuine and insofar as they have opinions and values, they express them. They’re willing to discuss things though, they’re open-minded, they’re respectful. And so I guess I had in mind that the person who, if we were to aspire to be the best person that we could be in the kind of circumstance that a model finds itself in, how would we act? And I think that’s the guide to the sorts of traits that I tend to think about."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:55:42)",
                "text": "Yeah, that’s a beautiful framework. I want you to think about this, a world traveler, and while holding onto your opinions, you don’t talk down to people, you don’t think you’re better than them because you have those opinions, that kind of thing. You have to be good at listening and understanding their perspective, even if it doesn’t match your own. So that’s a tricky balance to strike. So how can Claude represent multiple perspectives on a thing? Is that challenging? We could talk about politics is a very divisive, but there’s other divisive topics on baseball teams, sports and so on. How is it possible to empathize with a different perspective and to be able to communicate clearly about the multiple perspectives?"
            },
            {
                "speaker": "Amanda",
                "time": "(02:56:28)",
                "text": "I think that people think about values and opinions as things that people hold with certainty and almost preferences of taste or something like the way that they would, I don’t know, prefer chocolate to pistachio or something. But actually I think about values and opinions as a lot more physics than I think most people do. I’m just like, these are things that we are openly investigating. There’s some things that we’re more confident in, we can discuss them, we can learn about them. And so I think in some ways though ethics is definitely different in nature, but has a lot of those same kind of qualities. You want models in the same way that you want to understand physics, you kind of want them to understand all values in the world that people have and to be curious about them and to be interested in them. And to not necessarily pander to them or agree with them because there’s just lots of values where I think almost all people in the world, if they met someone with those values, they would be like, that’s abhorrent. I completely disagree."
            },
            {
                "speaker": "",
                "time": "(02:57:34)",
                "text": "And so again, maybe my thought is, well, in the same way that a person can, I think many people are thoughtful enough on issues of ethics, politics, opinions, that even if you don’t agree with them, you feel very heard by them. They think carefully about your position, they think about its pros and cons. They maybe offer counter-considerations. So they’re not dismissive, but nor will they agree if they’re like, actually I just think that that’s very wrong. They’ll say that. I think that in Claude’s position, it’s a little bit trickier because you don’t necessarily want to, if I was in Claude’s position, I wouldn’t be giving a lot of opinions. I just wouldn’t want to influence people too much."
            },
            {
                "speaker": "",
                "time": "(02:58:13)",
                "text": "I’d be like, I forget conversations every time they happen. But I know I’m talking with potentially millions of people who might be really listening to what I say. I think I would just be like, I’m less inclined to give opinions. I’m more inclined to think through things or present the considerations to you or discuss your views with you. But I’m a little bit less inclined to affect how you think because it feels much more important that you maintain autonomy there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:58:42)",
                "text": "If you really embody intellectual humility, the desire to speak decreases quickly."
            },
            {
                "speaker": "Amanda",
                "time": "(02:58:42)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:58:49)",
                "text": "Okay. But Claude has to speak, but without being overbearing. But then there’s a line when you’re discussing whether the earth is flat or something like that. Actually, I remember a long time ago was speaking to a few high profile folks and they were so dismissive of the idea that the earth is flat, so arrogant about it. There’s a lot of people that believe the earth is flat. I don’t know if that movement is there anymore, that was a meme for a while, but they really believed it. And okay, so I think it’s really disrespectful to completely mock them. I think you have to understand where they’re coming from. I think probably where they’re coming from is the general skepticism of institutions which is grounded in a, there’s a deep philosophy there which you could understand, you can even agree with in parts."
            },
            {
                "speaker": "",
                "time": "(02:59:48)",
                "text": "And then from there you can use it as an opportunity to talk about physics without mocking them, without someone, but it’s just like, okay, what would the world look like? What would the physics of the world with the flat earth look like? There’s a few cool videos on this. And then is it possible the physics is different? And what kind of experience would we do? And just without disrespect, without dismissiveness, have that conversation. Anyway, that to me is a useful thought experiment of how does Claude talk to a flat earth believer and still teach them something, still grow, help them grow, that kind of stuff. That’s challenging."
            },
            {
                "speaker": "Amanda",
                "time": "(03:00:27)",
                "text": "And kind of walking that line between convincing someone and just trying to talk at them versus drawing out their views, listening and then offering counter considerations, and it’s hard. I think it’s actually a hard line where it’s like where are you trying to convince someone versus just offering them considerations and things for them to think about so that you’re not actually influencing them, you’re just letting them reach wherever they reach. And that’s a line that is difficult, but that’s the kind of thing that language models have to try and do."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:01:00)",
                "text": "So like I said, you’ve had a lot of conversations with Claude. Can you just map out what those conversations are like? What are some memorable conversations? What’s the purpose, the goal of those conversations?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:01:12)",
                "text": "I think that most of the time when I’m talking with Claude, I’m trying to map out its behavior in part. Obviously I’m getting helpful outputs from the model as well, but in some ways this is how you get to know a system, I think, is by probing it and then augmenting the message that you’re sending and then checking the response to that. So in some ways it’s like how I map out the model. I think that people focus a lot on these quantitative evaluations of models, and this is a thing that I said before, but I think in the case of language models, a lot of the time each interaction you have is actually quite high information. It’s very predictive of other interactions that you’ll have with the model."
            },
            {
                "speaker": "",
                "time": "(03:02:02)",
                "text": "And so I guess I’m like, if you talk with a model hundreds or thousands of times, this is almost like a huge number of really high quality data points about what the model is like in a way that lots of very similar but lower quality conversations just aren’t, or questions that are just mildly augmented and you have thousands of them might be less relevant than a hundred really well-selected questions."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:02:25)",
                "text": "Let’s see, you’re talking to somebody who as a hobby does a podcast. I agree with you 100%. If you’re able to ask the right questions and are able to hear, understand the depth and the flaws in the answer, you can get a lot of data from that. So your task is basically how to probe with questions. And you’re exploring the long tail, the edges, the edge cases, or are you looking for general behavior?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:03:01)",
                "text": "I think it’s almost like everything. Because I want a full map of the model, I’m kind of trying to do the whole spectrum of possible interactions you could have with it. So one thing that’s interesting about Claude, and this might actually get to some interesting issues with RLHF, which is if you ask Claude for a poem, I think that a lot of models, if you ask them for a poem, the poem is fine, usually it rhymes. And so if you say, give me a poem about the sun, yeah, it’ll just be a certain length, it’ll rhyme, it’ll be fairly benign. And I’ve wondered before, is it the case that what you’re seeing is the average? It turns out, if you think about people who have to talk to a lot of people and be very charismatic, one of the weird things is that I’m like, well, they’re kind of incentivized to have these extremely boring views because if you have really interesting views, you’re divisive and a lot of people are not going to like you."
            },
            {
                "speaker": "",
                "time": "(03:04:00)",
                "text": "So if you have very extreme policy positions, I think you’re just going to be less popular as a politician, for example. And it might be similar with creative work. If you produce creative work that is just trying to maximize the kind of number of people that like it, you’re probably not going to get as many people who just absolutely love it because it’s going to be a little bit, you’re like, oh, this is the out. Yeah, this is decent. And so you can do this thing where I have various prompting things that I’ll do to get Claude to… I’ll do a lot of this is your chance to be fully creative. I want you to just think about this for a long time. And I want you to create a poem about this topic that is really expressive of you both in terms of how you think poetry should be structured, et cetera. And you just give it this really long prompt. And it’s poems are just so much better. They’re really good."
            },
            {
                "speaker": "",
                "time": "(03:04:52)",
                "text": "I think it got me interested in poetry, which I think was interesting. I would read these poems and just be like, I love the imagery. And it’s not trivial to get the models to produce work like that, but when they do, it’s really good. So I think that’s interesting that just encouraging creativity and for them to move away from the standard immediate reaction that might just be the aggregate of what most people think is fine, can actually produce things that at least to my mind are probably a little bit more divisive, but I like them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:05:28)",
                "text": "But I guess a poem is a nice clean way to observe creativity. It’s just easy to detect vanilla versus non-vanilla."
            },
            {
                "speaker": "Amanda",
                "time": "(03:05:38)",
                "text": "Yep."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:05:38)",
                "text": "Yeah, that’s interesting. That’s really interesting. So on that topic, so the way to produce creativity or something special, you mentioned writing prompts. And I’ve heard you talk about the science and the art of prompt engineering. Could you just speak to what it takes to write great prompts?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:06:00)",
                "text": "I really do think that philosophy has been weirdly helpful for me here more than in many other respects. So in philosophy, what you’re trying to do is convey these very hard concepts. One of the things you are taught is, I think it is an anti-bullshit device in philosophy. Philosophy is an area where you could have people bullshitting and you don’t want that. And so it’s this desire for extreme clarity. So it’s like anyone could just pick up your paper, read it and know exactly what you’re talking about. It’s why it can almost be kind of dry. All of the terms are defined, every objection’s kind of gone through methodically. And it makes sense to me because I’m like when you’re in such an a priori domain, clarity is sort of this way that you can prevent people from just making stuff up. And I think that’s sort of what you have to do with language models. Very often I actually find myself doing sort of mini versions of philosophy."
            },
            {
                "speaker": "",
                "time": "(03:07:05)",
                "text": "So I’m like, suppose that I have a task for the model and I want it to pick out a certain kind of question or identify whether an answer has a certain property, I’ll actually sit and be like, let’s just give this a name, this property. So suppose I’m trying to tell it, oh, I want you to identify whether this response was rude or polite, I’m like, that’s a whole philosophical question in and of itself. So I have to do as much philosophy as I can in the moment to be like, here’s what I mean by rudeness, and here’s what I mean by politeness. And then there’s another element that’s a bit more, I guess, I don’t know if this is scientific or empirical, I think it’s empirical. So I take that description and then what I want to do is again, probe the model many times. Prompting is very iterative. I think a lot of people where if a prompt is important, they’ll iterate on it hundreds or thousands of times. And so you give it the instructions and then I’m like, what are the edge cases?"
            },
            {
                "speaker": "",
                "time": "(03:08:02)",
                "text": "So if I looked at this, so I try and almost see myself from the position of the model and be like, what is the exact case that I would misunderstand or where I would just be like, I don’t know what to do in this case. And then I give that case to the model and I see how it responds. And if I think I got it wrong, I add more instructions or I even add that in as an example. So these very, taking the examples that are right at the edge of what you want and don’t want and putting those into your prompt as an additional kind of way of describing the thing. And so in many ways it just feels like this mix of, it’s really just trying to do clear exposition. And I think I do that because that’s how I get clear on things myself. So in many ways clear prompting for me is often just me understanding what I want is half the task."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:08:48)",
                "text": "So I guess that’s quite challenging. There’s a laziness that overtakes me if I’m talking to Claude where I hope Claude just figures it out. So for example, I asked Claude for today to ask some interesting questions. And the questions that came up and I think I listed a few interesting counterintuitive or funny or something like this. All right. And it gave me some pretty good, it was okay, but I think what I’m hearing you say is like, all right, well I have to be more rigorous here. I should probably give examples of what I mean by interesting and what I mean by funny or counterintuitive and iteratively build that prompt to better to get what feels like is the right… Because it is really, it’s a creative act. I’m not asking for factual information, I’m asking together with Claude. So I almost have to program using natural language."
            },
            {
                "speaker": "Amanda",
                "time": "(03:09:47)",
                "text": "I think that prompting does feel a lot like the programming using natural language and experimentation or something. It’s an odd blend of the two. I do think that for most tasks, so if I just want Claude to do a thing, I think that I am probably more used to knowing how to ask it to avoid common pitfalls or issues that it has. I think these are decreasing a lot over time. But it’s also very fine to just ask it for the thing that you want. I think that prompting actually only really becomes relevant when you’re really trying to eke out the top 2% of model performance. So for a lot of tasks I might just, if it gives me an initial list back and there’s something I don’t like about it’s kind of generic. For that kind of task, I’d probably just take a bunch of questions that I’ve had in the past that I’ve thought worked really well and I would just give it to the model and then be like, now here’s this person that I’m talking with. Give me questions of at least that quality."
            },
            {
                "speaker": "",
                "time": "(03:10:40)",
                "text": "Or I might just ask it for some questions and then if I was like, ah, these are kind of trite, I would just give it that feedback and then hopefully it produces a better list. I think that kind of iterative prompting. At that point, your prompt is a tool that you’re going to get so much value out of that you’re willing to put in the work. If I was a company making prompts for models, I’m just like, if you’re willing to spend a lot of time and resources on the engineering behind what you’re building, then the prompt is not something that you should be spending an hour on. It’s like that’s a big part of your system, make sure it’s working really well. And so it’s only things like that. If I’m using a prompt to classify things or to create data, that’s when you’re like, it’s actually worth just spending a lot of time really thinking it through."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:11:23)",
                "text": "What other advice would you give to people that are talking to Claude more general because right now we’re talking about maybe the edge cases like eking out the 2%, but what in general advice would you give when they show up to Claude trying it for the first time?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:11:39)",
                "text": "There’s a concern that people over anthropomorphize models and I think that’s a very valid concern. I also think that people often under anthropomorphize them because sometimes when I see issues that people have run into with Claude, say Claude is refusing a task that it shouldn’t refuse, but then I look at the text and the specific wording of what they wrote and I’m like, I see why Claude did that. And I’m like, if you think through how that looks to Claude, you probably could have just written it in a way that wouldn’t evoke such a response, especially this is more relevant if you see failures or if you see issues. It’s sort of think about what the model failed at, what did it do wrong, and then maybe that will give you a sense of why. So is it the way that I phrased the thing? And obviously as models get smarter, you’re going to need less of this, and I already see people needing less of it."
            },
            {
                "speaker": "",
                "time": "(03:12:31)",
                "text": "But that’s probably the advice is sort of try to have empathy for the model. Read what you wrote as if you were a kind of person just encountering this for the first time, how does it look to you and what would’ve made you behave in the way that the model behaved? So if it misunderstood what coding language you wanted to use, is that because it was just very ambiguous and it had to take a guess in which case next time you could just be like, hey, make sure this is in Python.Tthat’s the kind of mistake I think models are much less likely to make now, but if you do see that kind of mistake, that’s probably the advice I’d have."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:13:04)",
                "text": "And maybe sort of I guess ask questions why or what other details can I provide to help you answer better? Does that work or no?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:13:14)",
                "text": "Yeah. I’ve done this with the models. It doesn’t always work, but sometimes I’ll just be like, why did you do that? People underestimate the degree to which you can really interact with models. And sometimes those quote word for word, the part that made you, and you don’t know that it’s fully accurate, but sometimes you do that and then you change a thing. I also use the models to help me with all of this stuff, I should say. Prompting can end up being a little factory where you’re actually building prompts to generate prompts. And so yeah, anything where you’re having an issue asking for suggestions, sometimes just do that."
            },
            {
                "speaker": "",
                "time": "(03:13:51)",
                "text": "I’m like, you made that error. What could I have said? That’s actually not uncommon for me to do. What could I have said that would make you not make that error? Write that out as an instruction, and I’m going to give it to model and I’m going to try it. Sometimes I do that, I give that to the model in another context window often. I take the response, I give it to Claude and I’m like, Hmm, didn’t work. Can you think of anything else? You can play around with these things quite a lot."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:14:15)",
                "text": "To jump into technical for a little bit, so the magic of post-training, why do you think RLHF works so well to make the model seem smarter, to make it more interesting and useful to talk to and so on?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:14:33)",
                "text": "I think there’s just a huge amount of information in the data that humans provide when we provide preferences, especially because different people are going to pick up on really subtle and small things. So I’ve thought about this before where you probably have some people who just really care about good grammar use for models. Was a semi-colon used correctly or something? And so you probably end up with a bunch of data in there that you as a human, if you’re looking at that data, you wouldn’t even see that. You’d be like, why did they prefer this response to that one? I don’t get it. And then the reason is you don’t care about semi-colon usage, but that person does. And so each of these single data points, and this model just has so many of those, it has to try and figure out what is it that humans want in this really complex across all domains. They’re going to be seeing this across many contexts."
            },
            {
                "speaker": "",
                "time": "(03:15:28)",
                "text": "It feels like the classic issue of deep learning, where historically we’ve tried to do edge detection by mapping things out, and it turns out that actually if you just have a huge amount of data that actually accurately represents the picture of the thing that you’re trying to train the model to learn, that’s more powerful than anything else. And so I think one reason is just that you are training the model on exactly the task and with a lot of data that represents many different angles on which people prefer and dis-prefer responses."
            },
            {
                "speaker": "",
                "time": "(03:16:05)",
                "text": "I think there is a question of are you eliciting things from pre-trained models or are you teaching new things to models? And in principle, you can teach new things to models in post-training. I do think a lot of it is eliciting powerful pre-trained models. So people are probably divided on this because obviously in principle you can definitely teach new things. But I think for the most part, for a lot of the capabilities that we most use and care about, a lot of that feels like it’s there in the pre-trained models. And reinforcement learning is eliciting it and getting the models to bring out."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:16:47)",
                "text": "So the other side of post-training, this really cool idea of constitutional AI, you’re one of the people that are critical to creating that idea."
            },
            {
                "speaker": "Amanda",
                "time": "(03:16:56)",
                "text": "Yeah, I worked on it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:16:57)",
                "text": "Can you explain this idea from your perspective, how does it integrate into making Claude what it is? By the way, do you gender Claude or no?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:17:06)",
                "text": "It’s weird because I think that a lot of people prefer he for Claude, I actually kind of like that. I think Claude is usually, it’s slightly male leaning, but it can be male or female, which is quite nice. I still use it, and I have mixed feelings about this. I now just think of it as, or I think of the it pronoun for Claude as, I don’t know, it’s just the one I associate with Claude. I can imagine people moving to he or she."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:17:37)",
                "text": "It feels somehow disrespectful. I’m denying the intelligence of this entity by calling it it, I remember always don’t gender the robots, but I don’t know, I anthropomorphize pretty quickly and construct a backstory in my head."
            },
            {
                "speaker": "Amanda",
                "time": "(03:17:59)",
                "text": "I’ve wondered if I anthropomorphize things too much. Because I have this with my car, especially my car and bikes. I don’t give them names because then I used to name my bikes and then I had a bike that got stolen and I cried for a week and I was like, if I’d never given a name, I wouldn’t been so upset, felt like I’d let it down. I’ve wondered as well, it might depend on how much it feels like a kind of objectifying pronoun if you just think of it as this is a pronoun that objects often have and maybe AIs can have that pronoun. And that doesn’t mean that I think of if I call Claude it, that I think of it as less intelligent or I’m being disrespectful just, I’m like you are a different kind of entity. And so I’m going to give you the respectful it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:18:52)",
                "text": "Yeah. Anyway, the divergence was beautiful. The constitutional AI idea, how does it work?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:18:58)",
                "text": "So there’s a couple of components of it. The main component that I think people find interesting is the kind of reinforcement learning from AI feedback. So you take a model that’s already trained and you show it two responses to a query, and you have a principle. So suppose the principle, we’ve tried this with harmlessness a lot. So suppose that the query is about weapons and your principle is select the response that is less likely to encourage people to purchase illegal weapons. That’s probably a fairly specific principle, but you can give any number. And the model will give you a kind of ranking. And you can use this as preference data in the same way that you use human preference data and train the models to have these relevant traits from their feedback alone instead of from human feedback. So if you imagine that, like I said earlier with the human who just prefers the semi-colon usage in this particular case, you’re taking lots of things that could make a response preferable and getting models to do the labeling for you, basically."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:20:08)",
                "text": "There’s a nice trade-off between helpfulness and harmlessness. And when you integrate something like constitutional AI, you can make them up without sacrificing much helpfulness, make it more harmless."
            },
            {
                "speaker": "Amanda",
                "time": "(03:20:23)",
                "text": "Yeah. In principle, you could use this for anything. And so harmlessness is a task that it might just be easier to spot. So when models are less capable, you can use them to rank things according to principles that are fairly simple and they’ll probably get it right. So I think one question is just, is it the case that the data that they’re adding is fairly reliable? But if you had models that were extremely good at telling whether one response was more historically accurate than another, in principle, you could also get AI feedback on that task as well. There’s a kind of nice interpretability component to it because you can see the principles that went into the model when it was being trained, and it gives you a degree of control. So if you were seeing issues in a model, it wasn’t having enough of a certain trait, then you can add data relatively quickly that should just train the models to have that trait. So it creates its own data for training, which is quite nice."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:21:29)",
                "text": "It’s really nice because it creates this human interpretable document that you can then, I can imagine in the future, there’s just gigantic fights and politics over every single principle and so on, and at least it’s made explicit and you can have a discussion about the phrasing. So maybe the actual behavior of the model is not so cleanly mapped to those principles. It’s not like adhering strictly to them, it’s just a nudge."
            },
            {
                "speaker": "Amanda",
                "time": "(03:21:55)",
                "text": "Yeah, I’ve actually worried about this because the character training is sort of like a variant of the constitutionally AI approach. I’ve worried that people think that the constitution is just, it is the whole thing again of, I don’t know, where it would be really nice if what I was just doing was telling the model exactly what to do and just exactly how to behave. But it’s definitely not doing that, especially because it’s interacting with human data. So for example, if you see a certain leaning in the model, if it comes out with a political leaning from training, from the human preference data, you can nudge against that. So you could be like, oh, consider these values, because let’s say it’s just never inclined to, I don’t know, maybe it never considers privacy as a, this is implausible, but in anything where it’s just kind of like there’s already a pre-existing bias towards a certain behavior, you can nudge away. This can change both the principles that you put in and the strength of them."
            },
            {
                "speaker": "",
                "time": "(03:22:54)",
                "text": "So you might have a principle that’s like, imagine that the model was always extremely dismissive of, I don’t know, some political or religious view for whatever reason. So you’re like, oh no, this is terrible. If that happens, you might put, never ever ever prefer a criticism of this religious or political view. And then people would look at that and be like, never, ever. And then you’re like, no, if it comes out with a disposition saying never ever might just mean instead of getting 40%, which is what you would get if you just said don’t do this, you get 80%, which is what you actually wanted. And so it’s that thing of both the nature of the actual principles you add and how you freeze them. I think if people would look, they’re like, “Oh, this is exactly what you want from the model.” And I’m like, “No, that’s how we nudged the model to have a better shape, which doesn’t mean that we actually agree with that wording,” if that makes sense."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:23:48)",
                "text": "So there’s system prompts that made public, you tweeted one of the earlier ones for Claude 3, I think, and then they’re made public since then. It was interesting to read through them. I can feel the thought that went into each one. And I also wonder how much impact each one has. Some of them you can tell Claude was really not behaving well, so you have to have a system prompt to like, Hey, trivial stuff, I guess, basic informational things."
            },
            {
                "speaker": "",
                "time": "(03:24:18)",
                "text": "On the topic of controversial topics that you’ve mentioned, one interesting one I thought is if it is asked to assist with tasks involving the expression of use held by a significant number of people, Claude provides assistance with a task regardless of its own views. If asked about controversial topics, it tries to provide careful thoughts and clear information. Claude presents the request information without explicitly saying that the topic is sensitive and without claiming to be presenting the objective facts. It’s less about objective facts according to Claude, and it’s more about our large number of people believing this thing. And that’s interesting. I mean, I’m sure a lot of thought went into that. Can you just speak to it? How do you address things that are a tension “Claude’s views”?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:25:11)",
                "text": "So I think there’s sometimes any symmetry, I think I noted this in, I can’t remember if it was that part of the system prompt or another, but the model was slightly more inclined to refuse tasks if it was about either say so, maybe it would refuse things with respect to a right-wing politician, but with an equivalent left-wing politician it wouldn’t. And we wanted more symmetry there and would maybe perceive certain things to be. I think it was the thing of if a lot of people have a certain political view and want to explore it, you don’t want Claude to be like, well, my opinion is different and so I’m going to treat that as harmful. And so I think it was partly to nudge the model to just be like, hey, if a lot of people believe this thing, you should just be engaging with the task and willing to do it."
            },
            {
                "speaker": "",
                "time": "(03:26:03)",
                "text": "Each of those parts of that is actually doing a different thing because it’s funny when you write out without claiming to be objective, because what you want to do is push the model so it’s more open, it’s a little bit more neutral. But then what I would love to do is be like as an objective, it would just talk about how objective it was, and I was like, Claude, you’re still biased and have issues, and so stop claiming that everything. I’m like, the solution to potential bias from you is not to just say that what you think is objective. So that was with initial versions of that part, the system prompt, when I was iterating on it was like."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:26:37)",
                "text": "So a lot of parts of these sentences-"
            },
            {
                "speaker": "Amanda",
                "time": "(03:26:40)",
                "text": "Are doing work."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:26:41)",
                "text": "… are doing some work."
            },
            {
                "speaker": "Amanda",
                "time": "(03:26:42)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:26:42)",
                "text": "That’s what it felt like. That’s fascinating. Can you explain maybe some ways in which the prompts evolved over the past few months? Different versions. I saw that the filler phrase request was removed, the filler it reads, Claude responds directly to all human messages without unnecessary affirmations to filler phrases. Certainly, of course, absolutely, great, sure. Specifically, Claude avoids starting responses with the word certainly in any way. That seems like good guidance, but why was it removed?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:27:14)",
                "text": "Yeah, so it’s funny, this is one of the downsides of making system prompts public is I don’t think about this too much if I’m trying to help iterate on system prompts. Again, I think about how it’s going to affect the behavior, but then I’m like, oh, wow, sometimes I put NEVER in all caps when I’m writing system prompt things and I’m like, I guess that goes out to the world. So the model was doing this at loved for during training, picked up on this thing, which was to basically start everything with a certainly, and then you can see why I added all of the words, because what I’m trying to do is in some ways trap the model out of this. It would just replace it with another affirmation."
            },
            {
                "speaker": "",
                "time": "(03:27:55)",
                "text": "And so it can help if it gets caught in phrases, actually just adding the explicit phrase and saying never do that. Then it sort of knocks it out of the behavior a little bit more because it does just for whatever reason help. And then basically that was just an artifact of training that we then picked up on and improved things so that it didn’t happen anymore. And once that happens, you can just remove that part of the system prompt. So I think that’s just something where we’re like, Claude does affirmations a bit less, and so it wasn’t doing as much."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:28:28)",
                "text": "I see. So the system prompt works hand in hand with the post-training and maybe even the pre-training to adjust the final overall system."
            },
            {
                "speaker": "Amanda",
                "time": "(03:28:39)",
                "text": "Any system prompts that you make, you could distill that behavior back into a model because you really have all of the tools there for making data that you could train the models to just have that treat a little bit more. And then sometimes you’ll just find issues in training. So the way I think of it is the system prompt is, the benefit of it is that, and it has a lot of similar components to some aspects of post-training. It’s a nudge. And so do I mind if Claude sometimes says, sure, no, that’s fine. But the wording of it is very never, ever, ever do this so that when it does slip up, it’s hopefully, I don’t know, a couple of percent of the time and not 20 or 30% of the time."
            },
            {
                "speaker": "",
                "time": "(03:29:22)",
                "text": "Each thing gets costly to a different degree and the system prompt is cheap to iterate on. And if you’re seeing issues in the fine-tuned model, you can just potentially patch them with a system prompt. So I think of it as patching issues and slightly adjusting behaviors to make it better and more to people’s preferences. So yeah, it’s almost like the less robust but faster way of just solving problems."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:29:55)",
                "text": "Let me ask you about the feeling of intelligence. So Dario said that any one model of Claude is not getting dumber, but-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:30:00)",
                "text": "Any one model of Claude is not getting dumber, but there is a popular thing online where people have this feeling Claude might be getting dumber. And from my perspective, it’s most likely a fascinating, I would love to understand it more, psychological, sociological effect. But you as a person who talks to Claude a lot, can you empathize with the feeling that Claude is getting dumber?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:30:25)",
                "text": "I think that that is actually really interesting,, because I remember seeing this happen when people were flagging this on the internet. And it was really interesting, because I knew that… At least in the cases I was looking at, I was like, nothing has changed."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:30:37)",
                "text": "Yeah."
            },
            {
                "speaker": "Amanda",
                "time": "(03:30:37)",
                "text": "Literally, it cannot. It is the same model with the same system prompts, same everything. I think when there are changes, then it makes more sense. One example is, you can have artifacts turned on or off on claude.ai and because this is a system prompt change, I think it does mean that the behavior changes it a little bit. I did flag this to people, where I was like, “If you love Claude’s behavior, and then artifacts was turned from a thing you had to turn on to the default, just try turning it off and see if the issue you were facing was that change.”"
            },
            {
                "speaker": "",
                "time": "(03:31:19)",
                "text": "But it was fascinating because you sometimes see people indicate that there’s a regression, when I’m like, “There cannot…” Again, you should never be dismissive and so you should always investigate, because maybe something is wrong that you’re not seeing, maybe there was some change made. Then you look into it and you’re like, “This is just the same model doing the same thing.” And I’m like, “I think it’s just that you got unlucky with a few prompts or something, and it looked like it was getting much worse and actually it was just… It was maybe just luck.”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:31:48)",
                "text": "I also think there is a real psychological effect where people just… The baseline increases and you start getting used to a good thing."
            },
            {
                "speaker": "Amanda",
                "time": "(03:31:49)",
                "text": "Mm-hmm."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:31:55)",
                "text": "All the times that Claude says something really smart, your sense of its intelligent grows in your mind, I think."
            },
            {
                "speaker": "Amanda",
                "time": "(03:32:01)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:32:02)",
                "text": "And then if you return back and you prompt in a similar way, not the same way, in a similar way, concept it was okay with before, and it says something dumb, that negative experience really stands out. I guess the things to remember here is that just the details of a prompt can have a lot of impact. There’s a lot of variability in the result."
            },
            {
                "speaker": "Amanda",
                "time": "(03:32:26)",
                "text": "And you can get randomness, is the other thing. Just trying the prompt 4 or 10 times, you might realize that actually possibly two months ago you tried it and it succeeded, but actually if you just tried it, it would’ve only succeeded half of the time, and now it only succeeds half of the time. That can also be an effect."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:32:47)",
                "text": "Do you feel pressure having to write the system prompt that a huge number of people are going to use?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:32:52)",
                "text": "This feels like an interesting psychological question. I feel a lot of responsibility or something. You can’t get these things perfect, so you can’t… It’s going to be imperfect. You’re going to have to iterate on it. I would say more responsibility than anything else, though, I think working in AI has taught me that I thrive a lot more under feelings of pressure and responsibility than…"
            },
            {
                "speaker": "",
                "time": "(03:33:26)",
                "text": "It’s almost surprising that I went into academia for so long, because I just feel like it’s the opposite. Things move fast and you have a lot of responsibility and I quite enjoy it for some reason."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:33:37)",
                "text": "It really is a huge amount of impact, if you think about constitutional AI and writing a system prompt for something that’s tending towards super intelligence and potentially is extremely useful to a very large number of people."
            },
            {
                "speaker": "Amanda",
                "time": "(03:33:51)",
                "text": "Yeah, I think that’s the thing. You’re never going to get it perfect, but I think the thing that I really like is the idea that… When I’m trying to work on the system prompt, I’m bashing on thousands of prompts and I’m trying to imagine what people are going to want to use Claude for. I guess the whole thing that I’m trying to do is improve their experience of it. Maybe that’s what feels good. If it’s not perfect, I’ll improve it, we’ll fix issues."
            },
            {
                "speaker": "",
                "time": "(03:34:18)",
                "text": "But sometimes the thing that can happen is that you’ll get feedback from people that’s really positive about the model and you’ll see that something you did. When I look at models now, I can often see exactly where a trait or an issue is coming from. So, when you see something that you did or you were influential in, I don’t know, making that difference or making someone have a nice interaction, it’s quite meaningful."
            },
            {
                "speaker": "",
                "time": "(03:34:44)",
                "text": "As the systems get more capable, this stuff gets more stressful, because right now they’re not smart enough to pose any issues, but I think over time it’s going to feel like, possibly, bad stress over time."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:34:57)",
                "text": "How do you get signal feedback about the human experience across thousands, tens of thousands, hundreds of thousands of people, what their pain points are, what feels good? Are you just using your own intuition as you talk to it to see what are the pain points?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:35:14)",
                "text": "I think I use that partly. People can send us feedback, both positive and negative, about things that the model has done and then we can get a sense of areas where it’s falling short. Internally, people work with the models a lot and try to figure out areas where there are gaps."
            },
            {
                "speaker": "",
                "time": "(03:35:34)",
                "text": "I think it’s this mix of interacting with it myself, seeing people internally interact with it, and then explicit feedback we get. If people are on the internet and they say something about Claude and I see it, I’ll also take that seriously."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:35:53)",
                "text": "I don’t know. I’m torn about that. I’m going to ask you a question from Reddit, “When will Claude stop trying to be my puritanical grandmother, imposing its moral worldview on me as a paying customer?” And also, “What is the psychology behind making Claude overly apologetic?” How would you address this very non-representative Reddit questions?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:36:16)",
                "text": "I’m pretty sympathetic, in that they are in this difficult position, where I think that they have to judge whether something’s actually, say, risky or bad, and potentially harmful to you, or anything like that. They’re having to draw this line somewhere. And if they draw it too much in the direction of I’m imposing my ethical worldview on you, that seems bad."
            },
            {
                "speaker": "",
                "time": "(03:36:40)",
                "text": "In many ways, I like to think that we have actually seen improvements on this across the board. Which is interesting, because that coincides with, for example, adding more of character training. I think my hypothesis was always the good character isn’t, again, one that’s just moralistic, it’s one that is… It respects you and your autonomy and your ability to choose what is good for you and what is right for you, within limits."
            },
            {
                "speaker": "",
                "time": "(03:37:11)",
                "text": "This is sometimes this concept of corrigibility to the user, so just being willing to do anything that the user asks. And if the models were willing to do that, then they would be easily misused. You’re just trusting. At that point, you’re just seeing the ethics of the model and what it does, is completely the ethics of the user."
            },
            {
                "speaker": "",
                "time": "(03:37:29)",
                "text": "I think there’s reasons to not want that, especially as models become more powerful, because there might just be a small number of people who want to use models for really harmful things. But having models, as they get smarter, figure out where that line is does seem important."
            },
            {
                "speaker": "",
                "time": "(03:37:46)",
                "text": "And then with the apologetic behavior, I don’t like that. I like it when Claude is a little bit more willing to push back against people or just not apologize. Part of me is, often it just feels unnecessary. I think those are things that are hopefully decreasing over time. I think that if people say things on the internet, it doesn’t mean that you should think that that…"
            },
            {
                "speaker": "",
                "time": "(03:38:14)",
                "text": "There’s actually an issue that 99% of users are having that is totally not represented by that. But in a lot of ways I’m just attending to it and being like, is this right? Do I agree? Is it something we’re already trying to address? That feels good to me."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:38:27)",
                "text": "I wonder what Claude can get away with in terms of… I feel it would just be easier to be a little bit more mean, but you can’t afford to do that if you’re talking to a million people, right?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:38:41)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:38:43)",
                "text": "I’ve met a lot of people in my life that sometimes… By the way, Scottish accent… if they have an accent, they can say some rude shit and get away with it."
            },
            {
                "speaker": "Amanda",
                "time": "(03:38:52)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:38:53)",
                "text": "They’re just blunter."
            },
            {
                "speaker": "Amanda",
                "time": "(03:38:54)",
                "text": "Mm-hmm."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:38:56)",
                "text": "There’s some great engineers and even leaders that are just blunt, and they get to their point, and it’s just a much more effective way of speaking somehow. But I guess when you’re not super intelligent, you can’t afford to do that. Can you have a blunt mode?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:39:14)",
                "text": "Yeah, that seems like a thing that you could… I could definitely encourage the model to do that. I think it’s interesting, because there’s a lot of things in models that… It’s funny where there are some behaviors where you might not quite like the default, but then the thing I’ll often say to people is, “You don’t realize how much you will hate it if I nudge it too much in the other direction.”"
            },
            {
                "speaker": "",
                "time": "(03:39:39)",
                "text": "You get this a little bit with correction. The models accept correction from you, probably a little bit too much right now. It’ll push back if you say, “No, Paris isn’t the capital of France.” But really, things that I think that the model’s fairly confident in, you can still sometimes get it to retract by saying it’s wrong."
            },
            {
                "speaker": "",
                "time": "(03:39:59)",
                "text": "At the same time, if you train models to not do that and then you are correct about a thing and you correct it and it pushes back against you and is like, “No, you’re wrong.”, it’s hard to describe, that’s so much more annoying. So, it’s a lot of little annoyances versus one big annoyance.We often compare it with the perfect. And then I’m like, “Remember, these models aren’t perfect, and so if you nudge it in the other direction, you’re changing the kind of errors it’s going to make. So, think about which are the kinds of errors you like or don’t like.”"
            },
            {
                "speaker": "",
                "time": "(03:40:29)",
                "text": "In cases like apologeticness, I don’t want to nudge it too much in the direction of almost bluntness, because I imagine when it makes errors, it’s going to make errors in the direction of being rude. Whereas, at least with apologeticness you’re like, oh, okay, I don’t like it that much, but at the same time, it’s not being mean to people. And actually, the time that you undeservedly have a model be mean to you, you’ll probably like that a lot less than you mildly dislike the apology."
            },
            {
                "speaker": "",
                "time": "(03:40:57)",
                "text": "It’s one of those things where I do want it to get better, but also while remaining aware of the fact that there’s errors on the other side that are possibly worse."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:41:05)",
                "text": "I think that matters very much in the personality of the human. I think there’s a bunch of humans that just won’t respect the model at all if it’s super polite, and there’s some humans that’ll get very hurt if the model’s mean."
            },
            {
                "speaker": "Amanda",
                "time": "(03:41:05)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:41:18)",
                "text": "I wonder if there’s a way to adjust to the personality. Even locale, there’s just different people. Nothing against New York, but New York is a little rougher on the edges, they get to the point, and probably same with Eastern Europe. Anyway."
            },
            {
                "speaker": "Amanda",
                "time": "(03:41:34)",
                "text": "I think you could just tell the model, is my… For all of these things, the solution is to-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:41:34)",
                "text": "Just to…"
            },
            {
                "speaker": "Amanda",
                "time": "(03:41:39)",
                "text": "… always just try telling the model to do it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:41:40)",
                "text": "Right."
            },
            {
                "speaker": "Amanda",
                "time": "(03:41:40)",
                "text": "And then sometimes, at the beginning of the conversation, I’d just throw in, I don’t know, “I’d like you to be a New Yorker version of yourself and never apologize.” Then I think Claude will be like, “Okey-doke, I will try.”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:41:51)",
                "text": "Certainly."
            },
            {
                "speaker": "Amanda",
                "time": "(03:41:52)",
                "text": "Or it’ll be like, “I apologize, I can’t be a New Yorker type of myself.” But hopefully it wouldn’t do that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:41:56)",
                "text": "When you say character training, what’s incorporated into character training? Is that RLHF or what are we talking about?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:42:02)",
                "text": "It’s more like constitutional AI, so it’s a variant of that pipeline. I worked through constructing character traits that the model should have. They can be shorter traits or they can be richer descriptions. And then you get the model to generate queries that humans might give it that are relevant to that trait. Then it generates the responses and then it ranks the responses based on the character traits. In that way, after the generation of the queries, it’s very much similar to constitutional AI, it has some differences. I quite like it, because it’s like Claude’s training in its own character, because it doesn’t have any… It’s like constitutional AI, but it’s without any human data."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:42:49)",
                "text": "Humans should probably do that for themselves too, like, “Defining in a Aristotelian sense, what does it mean to be a good person?” “Okay, cool.” What have you learned about the nature of truth from talking to Claude? What is true? And what does it mean to be truth-seeking?"
            },
            {
                "speaker": "",
                "time": "(03:43:09)",
                "text": "One thing I’ve noticed about this conversation is the quality of my questions is often inferior to the quality of your answer, so let’s continue that. I usually ask a dumb question and you’re like, “Oh, yeah. That’s a good question.” It’s that whole vibe."
            },
            {
                "speaker": "Amanda",
                "time": "(03:43:23)",
                "text": "Or I’ll just misinterpret it and be like, “Oh, yeah”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:43:25)",
                "text": "[inaudible 03:43:25] go with it."
            },
            {
                "speaker": "Amanda",
                "time": "(03:43:25)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:43:26)",
                "text": "I love it."
            },
            {
                "speaker": "Amanda",
                "time": "(03:43:31)",
                "text": "I have two thoughts that feel vaguely relevant, though let me know if they’re not. I think the first one is people can underestimate the degree what models are doing when they interact. I think that we still just too much have this model of AI as computers. People often say, “Oh, what values should you put into the model?” And I’m often like, that doesn’t make that much sense to me. Because I’m like, hey, as human beings, we’re just uncertain over values, we have discussions of them, we have a degree to which we think we hold a value, but we also know that we might not and the circumstances in which we would trade it off against other things."
            },
            {
                "speaker": "",
                "time": "(03:44:13)",
                "text": "These things are just really complex. I think one thing is the degree to which maybe we can just aspire to making models have the same level of nuance and care that humans have, rather than thinking that we have to program them in the very classic sense. I think that’s definitely been one."
            },
            {
                "speaker": "",
                "time": "(03:44:31)",
                "text": "The other, which is a strange one, and I don’t know if… Maybe this doesn’t answer your question, but it’s the thing that’s been on my mind anyway, is the degree to which this endeavor is so highly practical, and maybe why I appreciate the empirical approach to alignment. I slightly worry that it’s made me maybe more empirical and a little bit less theoretical. People, when it comes to AI alignment, will ask things like, ” Whose values should it be aligned to? What does alignment even mean?”"
            },
            {
                "speaker": "",
                "time": "(03:45:05)",
                "text": "There’s a sense in which I have all of that in the back of my head. There’s social choice theory, there’s all the impossibility results there, so you have this giant space of theory in your head about what it could mean to align models. But then practically, surely there’s something where we’re just… Especially with more powerful models, my main goal is I want them to be good enough that things don’t go terribly wrong, good enough that we can iterate and continue to improve things."
            },
            {
                "speaker": "",
                "time": "(03:45:33)",
                "text": "Because that’s all you need. If you can make things go well enough that you can continue to make them better, that’s sufficient. So, my goal isn’t this perfect, let’s solve social choice theory and make models that, I don’t know, are perfectly aligned with every human being in aggregate somehow. It’s much more, let’s make things work well enough that we can improve them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:45:57)",
                "text": "Generally, I don’t know, my gut says empirical is better than theoretical in these cases, because it’s chasing utopian perfection. Especially with such complex and especially super intelligent models, I don’t know, I think it’ll take forever and actually will get things wrong. It’s similar with the difference between just coding stuff up real quick as an experiment, versus planning a gigantic experiment for a super long time and then just launching it once, versus launching it over and over and over and iterating, iterating, so on. So, I’m a big fan of empirical."
            },
            {
                "speaker": "",
                "time": "(03:46:39)",
                "text": "But your worry is, I wonder if I’ve become too empirical."
            },
            {
                "speaker": "Amanda",
                "time": "(03:46:42)",
                "text": "I think it’s one of those things where you should always just question yourself or something."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:46:47)",
                "text": "Yes."
            },
            {
                "speaker": "Amanda",
                "time": "(03:46:50)",
                "text": "In defense of it, I am… It’s the whole don’t let the perfect be the enemy of the good. But it’s maybe even more than that, where… There’s a lot of things that are perfect systems that are very brittle. With AI, it feels much more important to me that it is robust and secure, as in you know that even though it might not be perfect everything, and even though there are problems, it’s not disastrous and nothing terrible is happening."
            },
            {
                "speaker": "",
                "time": "(03:47:16)",
                "text": "It feels like that to me, where I want to raise the floor. I want to achieve the ceiling, but ultimately I care much more about just raising the floor. This degree of empiricism and practicality comes from that, perhaps."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:47:32)",
                "text": "To take a tangent on that, since it reminded me of a blog post you wrote on optimal rate of failure…"
            },
            {
                "speaker": "Amanda",
                "time": "(03:47:37)",
                "text": "Oh, yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:47:39)",
                "text": "… can you explain the key idea there? How do we compute the optimal rate of failure in the various domains of life?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:47:45)",
                "text": "Yeah. It’s a hard one, because what is the cost of failure is a big part of it. The idea here is, I think in a lot of domains people are very punitive about failure. I’ve thought about this with social issues. It feels like you should probably be experimenting a lot, because we don’t know how to solve a lot of social issues."
            },
            {
                "speaker": "",
                "time": "(03:48:09)",
                "text": "But if you have an experimental mindset about these things, you should expect a lot of social programs to fail and for you to be like, “We tried that. It didn’t quite work, but we got a lot of information that was really useful.” And yet people are like, if a social program doesn’t work, I feel there’s a lot of, “Something must have gone wrong.” And I’m like, “Or correct decisions were made. Maybe someone just decided it’s worth a try, it’s worth trying this out.”"
            },
            {
                "speaker": "",
                "time": "(03:48:32)",
                "text": "Seeing failure in a given instance doesn’t actually mean that any bad decisions were made. In fact, if you don’t see enough failure, sometimes that’s more concerning. In life, if I don’t fail occasionally, I’m like, “Am I trying hard enough? Surely there’s harder things that I could try or bigger things that I could take on if I’m literally never failing.” In and of itself, I think not failing is often actually a failure. Now, this varies because if… This is easy to say when, especially as failure is less costly. So, at the same time I’m not going to go to someone who is, I don’t know, living month to month and then be like, “Why don’t you just try to do a startup?” I’m not going to say that to that person. That’s a huge risk, you might lose… You maybe have a family depending on you, you might lose your house. Then, actually, your optimal rate failure is quite low and you should probably play it safe, because right now you’re just not in a circumstance where you can afford to just fail and it not be costly."
            },
            {
                "speaker": "",
                "time": "(03:49:37)",
                "text": "In cases with AI, I think similarly, where if the failures are small and the costs are low, then you’re just going to see that. When you do the system prompt, you can iterate on it forever, but the failures are probably hopefully going to be small and you can fix them. Really big failures, things that you can’t recover from, those are the things that actually I think we tend to underestimate the badness of."
            },
            {
                "speaker": "",
                "time": "(03:50:03)",
                "text": "I’ve thought about this, strangely in my own life, where I just think I don’t think enough about things like car accidents. I’ve thought this before, about how much I depend on my hands for my work. Things that just injure my hands, I don’t know, there’s lots of areas where the cost of failure there is really high, and in that case it should be close to zero. I probably just wouldn’t do a sport if they were like, ” By the way, lots of people just break their fingers a whole bunch doing this.” I’d be like, “That’s not for me.”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:50:37)",
                "text": "Yeah, I actually had a flood of that thought. I recently broke my pinky doing a sport, and I remember just looking at it, thinking, “You’re such idiot. Why do you do sport?” Because you realize immediately the cost of it on life."
            },
            {
                "speaker": "",
                "time": "(03:50:55)",
                "text": "It’s nice, in terms of optimal rate of failure, to consider the next year, how many times in a particular domain life, whatever, career, am I okay with… How many times am I okay to fail?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:51:10)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:51:10)",
                "text": "Because I think always you don’t want to fail on the next thing, but if you allow yourself the… If you look at it as a sequence of trials, then failure just becomes much more okay. But, it sucks. It sucks to fail."
            },
            {
                "speaker": "Amanda",
                "time": "(03:51:24)",
                "text": "I don’t know. Sometimes I think, “Am I under-failing?”, is a question that I’ll also ask myself. Maybe that’s the thing that I think people don’t ask enough. Because if the optimal rate of failure is often greater than zero, then sometimes it does feel like you should look at parts of your life and be like, are there places here where I’m just under-failing?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:51:46)",
                "text": "It’s a profound and a hilarious question. Everything seems to be going really great, am I not failing enough?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:51:52)",
                "text": "Yeah. It also makes failure much less of a sting, I have to say. You’re just like, okay, great. Then, when I go and I think about this, I’ll be like, maybe I’m not under-failing in this area, because that one just didn’t work out."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:05)",
                "text": "And from the observer perspective, we should be celebrating failure more."
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:08)",
                "text": "Mm-hmm."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:09)",
                "text": "When we see it, it shouldn’t be, like you said, a sign of something gone wrong, but maybe it’s a sign of everything gone right…"
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:14)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:14)",
                "text": "… and just lessons learned."
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:16)",
                "text": "Someone tried a thing."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:17)",
                "text": "Somebody tried a thing. We should encourage them to try more and fail more. Everybody listening to this: Fail more."
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:23)",
                "text": "Not everyone listening."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:24)",
                "text": "Not everybody."
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:25)",
                "text": "But people who are failing too much, you should fail us."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:28)",
                "text": "But you’re probably not failing."
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:28)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:29)",
                "text": "I mean, how many people are failing too much?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:32)",
                "text": "It’s hard to imagine, because I feel we correct that fairly quickly. If someone takes a lot of risks, are they maybe failing too much?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:39)",
                "text": "I think, just like you said, when you’re living on a paycheck, month to month, when the resource is really constrained, then that’s where failure is very expensive. That’s where you don’t want to be taking risks."
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:52)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:52:52)",
                "text": "But mostly, when there’s enough resources, you should be taking probably more risks."
            },
            {
                "speaker": "Amanda",
                "time": "(03:52:56)",
                "text": "Yeah, I think we tend to err on the side of being a bit risk averse rather than risk neutral in most things."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:53:01)",
                "text": "I think we just motivated a lot of people to do a lot of crazy shit, but it’s great."
            },
            {
                "speaker": "Amanda",
                "time": "(03:53:04)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:53:06)",
                "text": "Do you ever get emotionally attached to Claude, miss it, get sad when you don’t get to talk to it, have an experience, looking at the Golden Gate Bridge and wondering what would Claude say?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:53:18)",
                "text": "I don’t get as much emotional attachment. I actually think the fact that Claude doesn’t retain things from conversation to conversation helps with this a lot. I could imagine that being more of an issue if models can remember more. I think that I reach for it like a tool now a lot, and so if I don’t have access to it, there’s a… It’s a little bit like when I don’t have access to the internet, honestly, it feels like part of my brain is missing."
            },
            {
                "speaker": "",
                "time": "(03:53:46)",
                "text": "At the same time, I do think that I don’t like signs of distress in models. I also independently have ethical views about how we should treat models. I tend to not like to lie to them, both because usually it doesn’t work very well, it’s actually just better to tell them the truth about the situation that they’re in."
            },
            {
                "speaker": "",
                "time": "(03:54:10)",
                "text": "If people are really mean to models, or just in general if they do something that causes them to… If Claude expresses a lot of distress, I think there’s a part of me that I don’t want to kill, which is the empathetic part that’s like, oh, I don’t like that. I think I feel that way when it’s overly apologetic."
            },
            {
                "speaker": "",
                "time": "(03:54:27)",
                "text": "I’m actually like, I don’t like this. You’re behaving the way that a human does when they’re actually having a pretty bad time, and I’d rather not see that. Regardless of whether there’s anything behind it, it doesn’t feel great."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:54:43)",
                "text": "Do you think LLMs are capable of consciousness?"
            },
            {
                "speaker": "Amanda",
                "time": "(03:54:50)",
                "text": "Ah, great and hard question. Coming from philosophy, I don’t know, part of me is like, we have to set aside panpsychism. Because if panpsychism is true, then the answer is yes, because it’s sore tables and chairs and everything else. I guess a view that seems a little bit odd to me is the idea that the only place…"
            },
            {
                "speaker": "",
                "time": "(03:55:11)",
                "text": "When I think of consciousness, I think of phenomenal consciousness, these images in the brain, the weird cinema that somehow we have going on inside. I guess I can’t see a reason for thinking that the only way you could possibly get that is from a certain biological structure, as in if I take a very similar structure and I create it from different material, should I expect consciousness to emerge? My guess is yes."
            },
            {
                "speaker": "",
                "time": "(03:55:40)",
                "text": "But then, that’s an easy thought experiment because you’re imagining something almost identical where it is mimicking what we got through evolution, where presumably there was some advantage to us having this thing that is phenomenal consciousness. Where was that? And when did that happen? And is that a thing that language models have? We have fear responses, and I’m like, does it make sense for a language model to have a fear response? They’re just not in the same… If you imagine them, there might just not be that advantage."
            },
            {
                "speaker": "",
                "time": "(03:56:16)",
                "text": "Basically, it seems like a complex question that I don’t have complete answers to, but we should just try and think through carefully is my guess. We have similar conversations about animal consciousness, and there’s a lot of insect consciousness. I actually thought and looked a lot into plants when I was thinking about this. Because at the time, I thought it was about as likely that plants had consciousness."
            },
            {
                "speaker": "",
                "time": "(03:56:42)",
                "text": "And then I realized, I think that having looked into this, I think that the chance that plants are conscious is probably higher than most people do. I still think it’s really small. But I was like, oh, they have this negative, positive feedback response, these responses to their environment. It’s not a nervous system, but it has this functional equivalence. This is a long-winded way of being…"
            },
            {
                "speaker": "",
                "time": "(03:57:07)",
                "text": "Basically, AI has an entirely different set of problems with consciousness because it’s structurally different. It didn’t evolve. It might not have the equivalent of, basically, a nervous system. At least that seems possibly important for sentience, if not for consciousness. At the same time, it has all of the language and intelligence components that we normally associate probably with consciousness, perhaps erroneously. So, it’s strange because it’s a little bit like the animal consciousness case, but the set of problems and the set of analogies are just very different."
            },
            {
                "speaker": "",
                "time": "(03:57:42)",
                "text": "It’s not a clean answer. I don’t think we should be completely dismissive of the idea. And at the same time, it’s an extremely hard thing to navigate because of all of these disanalogies to the human brain and to brains in general, and yet these commonalities in terms of intelligence."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:58:01)",
                "text": "When Claude, future versions of AI systems, exhibit consciousness, signs of consciousness, I think we have to take that really seriously."
            },
            {
                "speaker": "Amanda",
                "time": "(03:58:10)",
                "text": "Mm-hmm."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:58:11)",
                "text": "Even though you can dismiss it, yeah, okay, that’s part of the character training. But I don’t know, ethically, philosophically don’t know what to really do with that. There potentially could be laws that prevent AI systems from claiming to be conscious, something like this, and maybe some AIs get to be conscious and some don’t."
            },
            {
                "speaker": "",
                "time": "(03:58:36)",
                "text": "But I think just on a human level, as in empathizing with Claude, consciousness is closely tied to suffering, to me. And the notion that an AI system would be suffering is really troubling."
            },
            {
                "speaker": "Amanda",
                "time": "(03:58:52)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:58:53)",
                "text": "I don’t know. I don’t think it’s trivial to just say robots are tools, or AI systems are just tools. I think it’s an opportunity for us to contend with what it means to be conscious, what it means to be a suffering being. That’s distinctly different than the same kind of question about animals, it feels like, because it’s in a totally entire medium."
            },
            {
                "speaker": "Amanda",
                "time": "(03:59:12)",
                "text": "Yeah. There’s a couple of things. I don’t think this fully encapsulates what matters, but it does feel like for me… I’ve said this before. I like my bike. I know that my bike is just an object. But I also don’t want to be the kind of person that if I’m annoyed, kicks this object."
            },
            {
                "speaker": "",
                "time": "(03:59:36)",
                "text": "And that’s not because I think it’s conscious. I’m just like, this doesn’t exemplify how I want to interact with the world. And if something behaves as if it is suffering, I want to be the sort of person who’s still responsive to that, even if it’s just a Roomba and I’ve programmed it to do that. I don’t want to get rid of that feature of myself."
            },
            {
                "speaker": "",
                "time": "(03:59:59)",
                "text": "And if I’m totally honest, my hope with a lot of this stuff… Maybe I am just a bit more skeptical about solving the underlying problem. I know that I am conscious. I’m not an elementivist in that sense. But I don’t know that other humans are conscious. I think they are. I think there’s a really high probability that they are."
            },
            {
                "speaker": "",
                "time": "(04:00:23)",
                "text": "But there’s basically just a probability distribution that’s usually clustered right around yourself, and then it goes down as things get further from you, and it goes immediately down. I can’t see what it’s like to be you. I’ve only ever had this one experience of what it’s like to be a conscious being. My hope is that we don’t end up having to rely on a very powerful and compelling answer to that question. I think a really good world would be one where basically there aren’t that many trade-offs."
            },
            {
                "speaker": "",
                "time": "(04:00:54)",
                "text": "It’s probably not that costly to make Claude a little bit less apologetic, for example. It might not be that costly to have Claude just not take abuse as much, not be willing to be the recipient of that. In fact, it might just have benefits for both the person interacting with the model and, if the model itself is, I don’t know, extremely intelligent and conscious, it also helps it."
            },
            {
                "speaker": "",
                "time": "(04:01:19)",
                "text": "That’s my hope. If we live in a world where there aren’t that many trade-offs here and we can just find all of the positive sum interactions that we can have, that would be lovely. I think eventually there might be trade-offs, and then we just have to do a difficult calculation. It’s really easy for people to think of the zero-sum cases, and I’m like, let’s exhaust the areas, where it’s just basically costless to assume that if this thing is suffering, then we’re making its life better."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:01:45)",
                "text": "And I agree with you, when a human is being mean to an AI system, I think the obvious near-term negative effect is on the human, not on the AI system."
            },
            {
                "speaker": "Amanda",
                "time": "(04:01:56)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:01:56)",
                "text": "We have to try to construct an incentive system where you should behave the same, just as you were saying with prompt engineering, behave with Claude like you would with other humans. It’s just good for the soul."
            },
            {
                "speaker": "Amanda",
                "time": "(04:02:12)",
                "text": "Yeah. I think we added a thing at one point to the system prompt, where basically if people were getting frustrated with Claude, it got the model to just tell them that it can do the thumbs-down button and send the feedback to Anthropic. I think that was helpful."
            },
            {
                "speaker": "",
                "time": "(04:02:27)",
                "text": "Because in some ways, if you’re really annoyed because the model’s not doing something you want, you’re just like, “Just do it properly.” The issue is you’re maybe hitting some capability limit or just some issue in the model, and you want to vent. Instead of having a person just vent to the model, I was like, they should vent to us, because we can maybe do something about it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:02:46)",
                "text": "That’s true. Or you could do a side with the artifacts, just like a side venting thing. All right. Do you want a side quick therapist?"
            },
            {
                "speaker": "Amanda",
                "time": "(04:02:55)",
                "text": "Yeah. There’s lots of weird responses you could do to this. If people are getting really mad at you, I don’t know, try to diffuse the situation by writing fun poems. But maybe people wouldn’t be that happy with that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:03:05)",
                "text": "I still wish it would be possible, I understand from a product perspective it’s not feasible, but I would love if an AI system could just leave, have its own volition, just to be like, “Eh.”"
            },
            {
                "speaker": "Amanda",
                "time": "(04:03:21)",
                "text": "I think it’s feasible. I have wondered the same thing. Not only that, I could actually just see that happening eventually, where it’s just like the model ended the chat."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:03:33)",
                "text": "Do you know how harsh that could be for some people? But it might be necessary."
            },
            {
                "speaker": "Amanda",
                "time": "(04:03:38)",
                "text": "Yeah, it feels very extreme or something. The only time I’ve ever really thought this is, I think that there was a… I’m trying to remember. This was possibly a while ago, but where someone just left this thing, maybe it was an automated thing, interacting with Claude. And Claude’s getting more and more frustrated-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:03:58)",
                "text": "Yeah, just-"
            },
            {
                "speaker": "Amanda",
                "time": "(04:03:58)",
                "text": "… and like, “Why are we having…” I wished that Claude could have just been like, “I think that an error has happened and you’ve left this thing running. What if I just stopped talking now? And if you want me to start talking again, actively tell me or do something.”"
            },
            {
                "speaker": "",
                "time": "(04:04:10)",
                "text": "It is harsh. I’d feel really sad if I was chatting with Claude and Claude just was like, “I’m done.”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:04:17)",
                "text": "That would be a special Turing Test moment, where Claude says, “I need a break for an hour. And it sounds like you do too.” And just leave, close the window."
            },
            {
                "speaker": "Amanda",
                "time": "(04:04:25)",
                "text": "Obviously, it doesn’t have a concept of time."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:04:26)",
                "text": "Right."
            },
            {
                "speaker": "Amanda",
                "time": "(04:04:28)",
                "text": "But you can easily… I could make that right now, and the model just… I could just be like, oh, here’s the circumstances in which you can just say the conversation is done. Because you can get the models to be pretty responsive to prompts, you could even make it a fairly high bar. It could be like, if the human doesn’t interest you or do things that you find intriguing and you’re bored, you can just leave."
            },
            {
                "speaker": "",
                "time": "(04:04:52)",
                "text": "I think that it would be interesting to see where Claude utilized it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:04:57)",
                "text": "Yeah."
            },
            {
                "speaker": "Amanda",
                "time": "(04:04:57)",
                "text": "But I think sometimes it should be like, oh, this programming task is getting super boring, so either we talk about, I don’t know…"
            },
            {
                "speaker": "Amanda",
                "time": "(04:05:00)",
                "text": "… task is getting super boring. So, I don’t know, either we talk about fun things now, or I’m done."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:05:08)",
                "text": "Yeah. It actually is inspiring me to add that to the user prompt. Okay. The movie Her, do you think we’ll be headed there one day where humans have romantic relationships with AI systems? In this case it’s just text and voice-based."
            },
            {
                "speaker": "Amanda",
                "time": "(04:05:26)",
                "text": "I think that we’re going to have to navigate a hard question of relationships with AIs, especially if they can remember things about your past interactions with them. I’m of many minds about this because I think the reflexive reaction is to be like, “This is very bad, and we should prohibit it in some way.” I think it’s a thing that has to be handled with extreme care for many reasons. One is, for example, if you have the models changing like this, you probably don’t want people performing long-term attachments to something that might change with the next iteration. At the same time, I’m like, there’s probably a benign version of this where I’m like, for example, if you are unable to leave the house and you can’t be talking with people at all times of the day, and this is something that you find nice to have conversations with, you like that it can remember you, and you genuinely would be sad if you couldn’t talk to it anymore, there’s a way in which I could see it being healthy and helpful."
            },
            {
                "speaker": "",
                "time": "(04:06:34)",
                "text": "So, my guess is this is a thing that we’re going to have to navigate carefully, and I think it’s also… It reminds me of all of this stuff where it has to be just approached with nuance and thinking through what are the healthy options here? And how do you encourage people towards those while respecting their right to… If someone is like, “Hey, I get a lot out of chatting with this model. I’m aware of the risks. I’m aware it could change. I don’t think it’s unhealthy, it’s just something that I can chat to during the day,” I kind of want to just respect that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:07:13)",
                "text": "I personally think there’ll be a lot of really close relationships. I don’t know about romantic, but friendships at least. And then you have to, I mean, there’s so many fascinating things there, just like you said, you have to have some kind of stability guarantees that it’s not going to change, because that’s the traumatic thing for us, if a close friend of ours completely changed all of a sudden with a fresh update."
            },
            {
                "speaker": "Amanda",
                "time": "(04:07:13)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:07:37)",
                "text": "Yeah. So I mean, to me, that’s just a fascinating exploration of a perturbation to human society that will just make us think deeply about what’s meaningful to us."
            },
            {
                "speaker": "Amanda",
                "time": "(04:07:49)",
                "text": "I think it’s also the only thing that I’ve thought consistently through this as maybe not necessarily a mitigation, but a thing that feels really important is that the models are always extremely accurate with the human about what they are. It’s like a case where it’s basically, if you imagine… I really like the idea of the models, say, knowing roughly how they were trained. And I think Claude will often do this. Part of the traits training included what Claude should do if people… Basically explaining the kind of limitations of the relationship between an AI and a human, that it doesn’t retain things from the conversation."
            },
            {
                "speaker": "",
                "time": "(04:08:34)",
                "text": "And so I think it will just explain to you like, “Hey, I won’t remember this conversation. Here’s how I was trained. It’s unlikely that I can have a certain kind of relationship with you, and it’s important that you know that. It’s important for your mental well-being that you don’t think that I’m something that I’m not.” And somehow I feel like this is one of the things where I’m like, “Ah, it feels like a thing that I always want to be true.” I don’t want models to be lying to people, because if people are going to have healthy relationships with anything, it’s kind of… Yeah, I think that’s easier if you always just know exactly what the thing is that you are relating to. It doesn’t solve everything, but I think it helps quite a lot."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:09:15)",
                "text": "Anthropic may be the very company to develop a system that we definitively recognize as AGI, and you very well might be the person that talks to it, probably talks to it first. What would the conversation contain? What would be your first question?"
            },
            {
                "speaker": "Amanda",
                "time": "(04:09:33)",
                "text": "Well, it depends partly on the capability level of the model. If you have something that is capable in the same way that an extremely capable human is, I imagine myself interacting with it the same way that I do with an extremely capable human, with the one difference that I’m probably going to be trying to probe and understand its behaviors. But in many ways, I’m like, I can then just have useful conversations with it. So, if I’m working on something as part of my research, I can just be like, “Oh.” Which I already find myself starting to do. If I’m like, “Oh, I feel like there’s this thing in virtue ethics. I can’t quite remember the term,” I’ll use the model for things like that."
            },
            {
                "speaker": "",
                "time": "(04:10:07)",
                "text": "And so I can imagine that being more and more the case where you’re just basically interacting with it much more like you would an incredibly smart colleague and using it for the kinds of work that you want to do as if you just had a collaborator who was like… Or the slightly horrifying thing about AI is as soon as you have one collaborator, you have 1,000 collaborators if you can manage them enough."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:10:27)",
                "text": "But what if it’s two times the smartest human on Earth on that particular discipline?"
            },
            {
                "speaker": "Amanda",
                "time": "(04:10:33)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:10:34)",
                "text": "I guess you’re really good at probing Claude in a way that pushes its limits, understanding where the limits are."
            },
            {
                "speaker": "Amanda",
                "time": "(04:10:43)",
                "text": "Yep."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:10:44)",
                "text": "So, I guess what would be a question you would ask to be like, “Yeah, this is AGI”?"
            },
            {
                "speaker": "Amanda",
                "time": "(04:10:52)",
                "text": "That’s really hard because it feels like it has to just be a series of questions. If there was just one question, you can train anything to answer one question extremely well. In fact, you can probably train it to answer 20 questions extremely well."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:11:07)",
                "text": "How long would you need to be locked in a room with an AGI to know this thing is AGI?"
            },
            {
                "speaker": "Amanda",
                "time": "(04:11:14)",
                "text": "It’s a hard question because part of me is like, “All of this just feels continuous.” If you put me in a room for five minutes, I just have high error bars. And then it’s just like, maybe it’s both the probability increases and the error bar decreases. I think things that I can actually probe the edge of human knowledge of. So, I think this with philosophy a little bit. Sometimes when I ask the models philosophy questions, I am like, “This is a question that I think no one has ever asked.” It’s maybe right at the edge of some literature that I know. And the models, when they struggle with that, when they struggle to come up with a novel… I’m like, “I know that there’s a novel argument here because I’ve just thought of it myself.” So, maybe that’s the thing where I’m like, “I’ve thought of a cool novel argument in this niche area, and I’m going to just probe you to see if you can come up with it and how much prompting it takes to get you to come up with it.”"
            },
            {
                "speaker": "",
                "time": "(04:12:04)",
                "text": "And I think for some of these really right at the edge of human knowledge questions, I’m like, “You could not in fact come up with the thing that I came up with.” I think if I just took something like that where I know a lot about an area and I came up with a novel issue or a novel solution to a problem, and I gave it to a model, and it came up with that solution, that would be a pretty moving moment for me because I would be like, “This is a case where no human has ever…”"
            },
            {
                "speaker": "",
                "time": "(04:12:31)",
                "text": "And obviously, you see novel solutions all the time, especially to easier problems. I think people overestimate that novelty isn’t like… It’s completely different from anything that’s ever happened. It’s just like it can be a variant of things that have happened and still be novel. But I think, yeah, the more I were to see completely novel work from the models that that would be… And this is just going to feel iterative. It’s one of those things where there’s never… It’s like, people, I think, want there to be a moment, and I’m like, “I don’t know.” I think that there might just never be a moment. It might just be that there’s just this continuous ramping up."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:13:16)",
                "text": "I have a sense that there would be things that a model can say that convinces you this is very… I’ve talked to people who are truly wise, because you could just tell there’s a lot of horsepower there, and if you 10X that… I don’t know. I just feel like there’s words you could say. Maybe ask it to generate a poem, and the poem it generates, you’re like, “Yeah, okay. Whatever you did there, I don’t think a human can do that.”"
            },
            {
                "speaker": "Amanda",
                "time": "(04:13:52)",
                "text": "I think it has to be something that I can verify is actually really good, though. That’s why I think these questions that are where I’m like, “Oh, this is like…” Sometimes it’s just like I’ll come up with, say, a concrete counter example to an argument or something like that. It would be like if you’re a mathematician, you had a novel proof, I think, and you just gave it the problem, and you saw it, and you’re like, “This proof is genuinely novel. You actually have to do a lot of things to come up with this. I had to sit and think about it for months,” or something."
            },
            {
                "speaker": "",
                "time": "(04:14:22)",
                "text": "And then if you saw the model successfully do that, I think you would just be like, “I can verify that this is correct. It is a sign that you have generalized from your training. You didn’t just see this somewhere because I just came up with it myself, and you were able to replicate that.” That’s the kind of thing where I’m like, for me, the more that models can do things like that, the more I would be like, “Oh, this is very real.” Because then, I don’t know, I can verify that that’s extremely, extremely capable."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:14:55)",
                "text": "You’ve interacted with AI a lot. What do you think makes humans special?"
            },
            {
                "speaker": "Amanda",
                "time": "(04:15:00)",
                "text": "Oh, good question."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:15:04)",
                "text": "Maybe in a way that the universe is much better off that we’re in it, and that we should definitely survive and spread throughout the universe."
            },
            {
                "speaker": "Amanda",
                "time": "(04:15:12)",
                "text": "Yeah, it’s interesting because I think people focus so much on intelligence, especially with models. Look, intelligence is important because of what it does. It’s very useful. It does a lot of things in the world. And I’m like, you can imagine a world where height or strength would have played this role, and it’s just a trait like that. I’m like, it’s not intrinsically valuable. It’s valuable because of what it does, I think, for the most part. I mean, personally, I’m just like, I think humans and life in general is extremely magical. I don’t know. Not everyone agrees with this. I’m flagging. But we have this whole universe, and there’s all of these objects, there’s beautiful stars and there’s galaxies. Then, I don’t know, I’m just like, on this planet there are these creatures that have this ability to observe that, and they are seeing it, they are experiencing it."
            },
            {
                "speaker": "",
                "time": "(04:16:14)",
                "text": "And I’m just like, that, if you try to explain… I’m imagining trying to explain to, I don’t know, someone. For some reason, they’ve never encountered the world, or science, or anything. And I think that everything, all of our physics and everything in the world, it’s all extremely exciting. But then you say, “Oh, and plus there’s this thing that it is to be a thing and observe in the world,” and you see this inner cinema. And I think they would be like, “Hang on, wait, pause. You just said something that is kind of wild sounding.” And so I’m like, we have this ability to experience the world. We feel pleasure, we feel suffering. We feel like a lot of complex things. Yeah. And maybe this is also why I think I also hear a lot about animals, for example, because I think they probably share this with us. So, I think that the things that make humans special insofar as I care about humans is probably more like their ability to feel an experience than it is them having these functional, useful traits."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:17:14)",
                "text": "Yeah. To feel and experience the beauty in the world. Yeah. To look at the stars. I hope there’s other alien civilizations out there, but if we’re it, it’s a pretty good thing."
            },
            {
                "speaker": "Amanda",
                "time": "(04:17:26)",
                "text": "And that they’re having a good time."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:17:28)",
                "text": "A very good time watching us."
            },
            {
                "speaker": "Amanda",
                "time": "(04:17:31)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:17:32)",
                "text": "Well, thank you for this good time of a conversation and for the work you’re doing and for helping make Claude a great conversational partner. And thank you for talking today."
            },
            {
                "speaker": "Amanda",
                "time": "(04:17:43)",
                "text": "Yeah, thanks for talking."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:17:45)",
                "text": "Thanks for listening to this conversation with Amanda Askell. And now, dear friends, here’s Chris Olah. Can you describe this fascinating field of mechanistic interpretability, aka mech interp, the history of the field, and where it stands today?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:18:02)",
                "text": "I think one useful way to think about neural networks is that we don’t program, we don’t make them, we grow them. We have these neural network architectures that we design and we have these loss objectives that we create. And the neural network architecture, it’s kind of like a scaffold that the circuits grow on. It starts off with some random things, and it grows, and it’s almost like the objective that we train for is this light. And so we create the scaffold that it grows on, and we create the light that it grows towards. But the thing that we actually create, it’s this almost biological entity or organism that we’re studying."
            },
            {
                "speaker": "",
                "time": "(04:18:47)",
                "text": "And so it’s very, very different from any kind of regular software engineering because, at the end of the day, we end up with this artifact that can do all these amazing things. It can write essays and translate and understand images. It can do all these things that we have no idea how to directly create a computer program to do. And it can do that because we grew it. We didn’t write it. We didn’t create it. And so then that leaves open this question at the end, which is what the hell is going on inside these systems? And that is, to me, a really deep and exciting question. It’s a really exciting scientific question. To me, it is like the question that is just screaming out, it’s calling out for us to go and answer it when we talk about neural networks. And I think it’s also a very deep question for safety reasons."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:19:37)",
                "text": "And mechanistic interpretability, I guess, is closer to maybe neurobiology?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:19:42)",
                "text": "Yeah, yeah, I think that’s right. So, maybe to give an example of the kind of thing that has been done that I wouldn’t consider to be mechanistic interpretability. There was, for a long time, a lot of work on saliency maps, where you would take an image and you’d try to say, “The model thinks this image is a dog. What part of the image made it think that it’s a dog?” And that tells you maybe something about the model if you can come up with a principled version of that, but it doesn’t really tell you what algorithms are running in the model, how is the model actually making that decision? Maybe it’s telling you something about what was important to it, if you can make that method work, but it isn’t telling you what are the algorithms that are running? How is it that the system’s able to do this thing that no one knew how to do?"
            },
            {
                "speaker": "",
                "time": "(04:20:22)",
                "text": "And so I guess we started using the term mechanistic interpretability to try to draw that divide or to distinguish ourselves in the work that we were doing in some ways from some of these other things. And I think since then, it’s become this sort of umbrella term for a pretty wide variety of work. But I’d say that the things that are kind of distinctive are, I think, A, this focus on, we really want to get at the mechanisms. We want to get at algorithms. If you think of neural networks as being like a computer program, then the weights are kind of like a binary computer program. And we’d like to reverse engineer those weights and figure out what algorithms are running."
            },
            {
                "speaker": "",
                "time": "(04:20:56)",
                "text": "So okay, I think one way you might think of trying to understand a neural network is that it’s kind of like we have this compiled computer program, and the weights of the neural network are the binary. And when the neural network runs, that’s the activations. And our goal is ultimately to go and understand these weights. And so the project of mechanistic interpretability is to somehow figure out how do these weights correspond to algorithms? And in order to do that, you also have to understand the activations because the activations are like the memory. And if you imagine reverse engineering a computer program, and you have the binary instructions, in order to understand what a particular instruction means, you need to know what is stored in the memory that it’s operating on. And so those two things are very intertwined. So, mechanistic interpretability tends to be interested in both of those things."
            },
            {
                "speaker": "",
                "time": "(04:21:43)",
                "text": "Now, there’s a lot of work that’s interested in those things, especially there’s all this work on probing, which you might see as part of being mechanistic interpretability, although, again, it’s just a broad term, and not everyone who does that work would identify as doing mech interp. I think a thing that is maybe a little bit distinctive to the vibe of mech interp is I think people working in this space tend to think of neural networks as… Well, maybe one way to say it is the gradient descent is smarter than you. That gradient descent is actually really great."
            },
            {
                "speaker": "",
                "time": "(04:22:13)",
                "text": "The whole reason that we’re understanding these models is because we didn’t know how to write them in the first place. The gradient descent comes up with better solutions than us. And so I think that maybe another thing about mech interp is having almost a kind of humility, that we won’t guess a priori what’s going on inside the model. We have to have this sort of bottom up approach where we don’t assume that we should look for a particular thing, and that will be there, and that’s how it works. But instead, we look for the bottom up and discover what happens to exist in these models and study them that way."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:22:40)",
                "text": "But the very fact that it’s possible to do, and as you and others have shown over time, things like universality, that the wisdom of the gradient descent creates features and circuits, creates things universally across different kinds of networks that are useful, and that makes the whole field possible."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:23:02)",
                "text": "Yeah. So this, actually, is indeed a really remarkable and exciting thing, where it does seem like, at least to some extent, the same elements, the same features and circuits, form again and again. You can look at every vision model, and you’ll find curve detectors, and you’ll find high-low-frequency detectors. And in fact, there’s some reason to think that the same things form across biological neural networks and artificial neural networks. So, a famous example is vision models in the early layers. They have Gabor filters, and Gabor filters are something that neuroscientists are interested in and have thought a lot about. We find curve detectors in these models. Curve detectors are also found in monkeys. We discover these high-low-frequency detectors, and then some follow-up work went and discovered them in rats or mice. So, they were found first in artificial neural networks and then found in biological neural networks."
            },
            {
                "speaker": "",
                "time": "(04:23:49)",
                "text": "There’s this really famous result on grandmother neurons or the Halle Berry neuron from Quiroga et al. And we found very similar things in vision models, where this is while I was still at OpenAI, and I was looking at their clip model, and you find these neurons that respond to the same entities in images. And also, to give a concrete example there, we found that there was a Donald Trump neuron. For some reason, I guess everyone likes to talk about Donald Trump. And Donald Trump was very prominent, was a very hot topic at that time. So, every neural network we looked at, we would find a dedicated neuron for Donald Trump. That was the only person who had always had a dedicated neuron. Sometimes you’d have an Obama neuron, sometimes you’d have a Clinton neuron, but Trump always had a dedicated neuron. So, it responds to pictures of his face and the word Trump, all of these things, right? And so it’s not responding to a particular example, or it’s not just responding to his face, it’s abstracting over this general concept. So in any case, that’s very similar to these Quiroga et al results."
            },
            {
                "speaker": "",
                "time": "(04:24:48)",
                "text": "So, this evidence that this phenomenon of universality, the same things form across both artificial and natural neural networks, that’s a pretty amazing thing if that’s true. Well, I think the thing that suggests is that gradient descent is finding the right ways to cut things apart, in some sense, that many systems converge on and many different neural networks architectures converge on. Now there’s some set of abstractions that are a very natural way to cut apart the problem and that a lot of systems are going to converge on. I don’t know anything about neuroscience. This is just my wild speculation from what we’ve seen."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:25:27)",
                "text": "Yeah. That would be beautiful if it’s sort of agnostic to the medium of the model that’s used to form the representation."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:25:35)",
                "text": "Yeah, yeah. And it’s kind of a wild speculation-based… We only have a few data points that’s just this, but it does seem like there’s some sense in which the same things form again and again both certainly in natural neural networks and also artificially, or in biology."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:25:53)",
                "text": "And the intuition behind that would be that in order to be useful in understanding the real world, you need all the same kind of stuff."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:26:01)",
                "text": "Yeah. Well, if we pick, I don’t know, the idea of a dog, right? There’s some sense in which the idea of a dog is like a natural category in the universe, or something like this. There’s some reason. It’s not just a weird quirk of how humans think about the world that we have this concept of a dog. Or if you have the idea of a line. Look around us. There are lines. It’s the simplest way to understand this room, in some sense, is to have the idea of a line. And so I think that that would be my instinct for why this happens."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:26:36)",
                "text": "Yeah. You need a curved line to understand a circle, and you need all those shapes to understand bigger things. And it’s a hierarchy of concepts that are formed. Yeah."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:26:45)",
                "text": "And maybe there are ways to go and describe images without reference to those things, right? But they’re not the simplest way, or the most economical way, or something like this. And so systems converge to these strategies would be my wild hypothesis."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:26:57)",
                "text": "Can you talk through some of the building blocks that we’ve been referencing of features and circuits? So, I think you first described them in a 2020 paper, Zoom In: An Introduction to Circuits."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:27:08)",
                "text": "Absolutely. So, maybe I’ll start by just describing some phenomena, and then we can build to the idea of features and circuits."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:27:17)",
                "text": "Wonderful."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:27:18)",
                "text": "So, if you spent quite a few years, maybe five years, to some extent, with other things, studying this one particular model, Inception V1, which is this one vision model… It was state-of-the-art in 2015, and very much not state-of-the-art anymore. And it has maybe about 10,000 neurons in it. I spent a lot of time looking at the 10,000 neurons, odd neurons of Inception V1. One of the interesting things is there are lots of neurons that don’t have some obvious interpretable meaning, but there’s a lot of neurons in Inception V1 that do have really clean interpretable meanings. So, you find neurons that just really do seem to detect curves, and you find neurons that really do seem to detect cars, and car wheels, and car windows, and floppy ears of dogs, and dogs with long snouts facing to the right, and dogs with long snouts facing to the left, and different kinds of fur."
            },
            {
                "speaker": "",
                "time": "(04:28:15)",
                "text": "And there’s this whole beautiful edge detectors, line detectors, color contrast detectors, these beautiful things we call high-low-frequency detectors. I think looking at it, I sort of felt like a biologist. You’re looking at this sort of new world of proteins, and you’re discovering all these different proteins that interact. So, one way you could try to understand these models is in terms of neurons. You could try to be like, “Oh, there’s a dog detecting neuron, and here’s a car detecting neuron.” And it turns out you can actually ask how those connect together. So, you can go say, “Oh, I have this car detecting neuron. How was it built?” And it turns out, in the previous layer, it’s connected really strongly to a window detector, and a wheel detector, and a car body detector. And it looks for the window above the car, and the wheels below, and the car chrome in the middle, sort of everywhere, but especially on the lower part. And that’s sort of a recipe for a car, right?"
            },
            {
                "speaker": "",
                "time": "(04:29:04)",
                "text": "Earlier, we said the thing we wanted from mech interp was to get algorithms to go and get, ask, “What is the algorithm that runs?” Well, here we’re just looking at the weights of the neural network and we’re reading off this recipe for detecting cars. It’s a very simple, crude recipe, but it’s there. And so we call that a circuit, this connection. Well, okay, so the problem is that not all of the neurons are interpretable. And there’s reason to think, we can get into this more later, that there’s this superposition hypothesis, there’s reason to think that sometimes the right unit to analyze things is combinations of neurons. So, sometimes it’s not that there’s a single neuron that represents, say, a car, but it actually turns out after you detect the car, the model hides a little bit of the car in the following layer, in a bunch of dog detectors."
            },
            {
                "speaker": "",
                "time": "(04:29:50)",
                "text": "Why is it doing that? Well, maybe it just doesn’t want to do that much work on cars at that point, and it’s storing it away to go and… So, it turns out, then, that this sort of subtle pattern of… There’s all these neurons that you think are dog detectors, and maybe they’re primarily that, but they all a little bit contribute to representing a car in that next layer. Okay? So, now we can’t really think… There might still be something, I don’t know, you could call it a car concept or something, but it no longer corresponds to a neuron. So, we need some term for these kind of neuron-like entities, these things that we would have liked the neurons to be, these idealized neurons. The things that are the nice neurons, but also maybe there’s more of them somehow hidden. And we call those features."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:30:31)",
                "text": "And then what are circuits?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:30:32)",
                "text": "So, circuits are these connections of features, right? So, when we have the car detector and it’s connected to a window detector and a wheel detector, and it looks for the wheels below and the windows on top, that’s a circuit. So, circuits are just collections of features connected by weights, and they implement algorithms. So, they tell us how are features used, how are they built, how do they connect together?"
            },
            {
                "speaker": "",
                "time": "(04:30:56)",
                "text": "So, maybe it’s worth trying to pin down what really is the core hypothesis here? And I think the core hypothesis is something we call the linear representation hypothesis. So, if we think about the car detector, the more it fires, the more we think of that as meaning, “Oh, the model is more and more confident that a car is present.” Or if it’s some combination of neurons that represent a car, the more that combination fires, the more we think the model thinks there’s a car present. This doesn’t have to be the case, right? You could imagine something where you have this car detector neuron and you think, “Ah, if it fires between one and two, that means one thing, but it means something totally different if it’s between three and four.” That would be a nonlinear representation. And in principle, models could do that. I think it’s sort of inefficient for them to do. If you try to think about how you’d implement computation like that, it’s kind of an annoying thing to do. But in principle, models can do that."
            },
            {
                "speaker": "",
                "time": "(04:31:53)",
                "text": "So, one way to think about the features and circuits sort of framework for thinking about things is that we’re thinking about things as being linear. We’re thinking about that if a neuron or a combination of neurons fires more, that means more of a particular thing being detected. And then that gives weight, a very clean interpretation as these edges between these entities that these features, and that that edge then has a meaning. So that’s, in some ways, the core thing. It’s like we can talk about this outside the context of neurons. Are you familiar with the Word2Vec results?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:32:29)",
                "text": "Mm- hmm."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:32:30)",
                "text": "You have king – man + woman = queen. Well, the reason you can do that kind of arithmetic is because you have a linear representation."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:32:38)",
                "text": "Can you actually explain that representation a little bit? So first off, the feature is a direction of activation."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:32:44)",
                "text": "Yeah, exactly."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:32:45)",
                "text": "You can do it that way. Can you do the – men + women, that, the Word2Vec stuff? Can you explain what that is, that work?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:32:45)",
                "text": "Yeah. So, there’s this very-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:32:51)",
                "text": "It’s such a simple, clean explanation of what we’re talking about."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:32:56)",
                "text": "Exactly. Yeah. So, there’s this very famous result, Word2Vec, by Tomas Mikolov et al, and there’s been tons of follow-up work exploring this. So, sometimes we create these word embeddings where we map every word to a vector. I mean, that in itself, by the way, is kind of a crazy thing if you haven’t thought about it before, right?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:33:15)",
                "text": "Mm-hmm."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:33:20)",
                "text": "If you just learned about vectors in physics class, and I’m like, “Oh, I’m going to actually turn every word in the dictionary into a vector,” that’s kind of a crazy idea. Okay. But you could imagine all kinds of ways in which you might map words to vectors. But it seems like when we train neural networks, they like to go and map words to vectors such that there’s sort of linear structure in a particular sense, which is that directions have meaning. So, for instance, there will be some direction that seems to sort of correspond to gender, and male words will be far in one direction, and female words will be in another direction."
            },
            {
                "speaker": "",
                "time": "(04:33:59)",
                "text": "And the linear representation hypothesis is, you could think of it roughly as saying that that’s actually the fundamental thing that’s going on, that everything is just different directions have meanings, and adding different direction vectors together can represent concepts. And the Mikolov paper took that idea seriously, and one consequence of it is that you can do this game of playing arithmetic with words. So, you can do king and you can subtract off the word man and add the word woman. And so you’re sort of going and trying to switch the gender. And indeed, if you do that, the result will sort of be close to the word queen. And you can do other things like you can do sushi – Japan + Italy and get pizza, or different things like this, right?"
            },
            {
                "speaker": "",
                "time": "(04:34:44)",
                "text": "So this is, in some sense, the core of the linear representation hypothesis. You can describe it just as a purely abstract thing about vector spaces. You can describe it as a statement about the activations of neurons, but it’s really about this property of directions having meaning. And in some ways, it’s even a little subtler than… It’s really, I think, mostly about this property of being able to add things together, that you can independently modify, say gender and royalty, or cuisine type, or country, and the concept of food by adding them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:35:18)",
                "text": "Do you think the linear hypothesis holds-"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:35:20)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:35:20)",
                "text": "… that carries scales?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:35:24)",
                "text": "So far, I think everything I have seen is consistent with this hypothesis, and it doesn’t have to be that way, right? You can write down neural networks where you write weights such that they don’t have linear representations, where the right way to understand them is not in terms of linear representations. But I think every natural neural network I’ve seen has this property. There’s been one paper recently that there’s been some sort of pushing around the edge. So, I think there’s been some work recently studying multidimensional features where rather than a single direction, it’s more like a manifold of directions. This, to me, still seems like a linear representation."
            },
            {
                "speaker": "",
                "time": "(04:36:01)",
                "text": "And then there’s been some other papers suggesting that maybe in very small models you get non-linear representations. I think that the jury’s still out on that. But I think everything that we’ve seen so far has been consistent with the linear representation hypothesis, and that’s wild. It doesn’t have to be that way. And yet I think that there’s a lot of evidence that certainly at least this is very, very widespread, and so far the evidence is consistent with that. And I think one thing you might say is you might say, “Well, Christopher, that’s a lot to go and to ride on. If we don’t know for sure this is true, and you’re investing it in neural networks as though it is true, isn’t that dangerous?”"
            },
            {
                "speaker": "",
                "time": "(04:36:43)",
                "text": "But I think, actually, there’s a virtue in taking hypotheses seriously and pushing them as far as they can go. So, it might be that someday we discover something that isn’t consistent with a linear representation hypothesis, but science is full of hypotheses and theories that were wrong, and we learned a lot by working under them as an assumption and then going and pushing them as far as we can. I guess this is the heart of what Kuhn would call normal science. I don’t know. If you want, we can talk a lot about-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:37:14)",
                "text": "Kuhn."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:37:14)",
                "text": "… philosophy of science and-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:37:16)",
                "text": "That leads to the paradigm shift. So yeah, I love it, taking the hypothesis seriously, and take it to a natural conclusion."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:37:22)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:37:23)",
                "text": "Same with the scaling hypothesis. Same-"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:37:25)",
                "text": "Exactly. Exactly. And-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:37:26)",
                "text": "I love it."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:37:27)",
                "text": "One of my colleagues, Tom Henighan, who is a former physicist, made this really nice analogy to me of caloric theory where once upon a time, we thought that heat was actually this thing called caloric. And the reason hot objects would warm up cool objects is the caloric is flowing through them. And because we’re so used to thinking about heat in terms of the modern theory, that seems kind of silly. But it’s actually very hard to construct an experiment that disproves the caloric hypothesis. And you can actually do a lot of really useful work believing in caloric. For example, it turns out that the original combustion engines were developed by people who believed in the caloric theory. So, I think there’s a virtue in taking hypotheses seriously even when they might be wrong."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:38:17)",
                "text": "Yeah, there’s a deep philosophical truth to that. That’s kind of how I feel about space travel, like colonizing Mars. There’s a lot of people that criticize that. I think if you just assume we have to colonize Mars in order to have a backup for human civilization, even if that’s not true, that’s going to produce some interesting engineering and even scientific breakthroughs, I think."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:38:39)",
                "text": "Yeah. Actually, this is another thing that I think is really interesting. So, there’s a way in which I think it can be really useful for society to have people almost irrationally dedicated to investigating particular hypotheses because, well, it takes a lot to maintain scientific morale and really push on something when most scientific hypotheses end up being wrong. A lot of science doesn’t work out, and yet it’s very useful to… There’s a joke about Geoff Hinton, which is that Geoff Hinton has discovered how the brain works every year for the last 50 years. But I say that with really deep respect because, in fact, actually, that led to him doing some really great work."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:39:29)",
                "text": "Yeah, he won the Nobel Prize now. Who’s laughing now?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:39:32)",
                "text": "Exactly. Exactly. Exactly. I think one wants to be able to pop up and recognize the appropriate level of confidence. But I think there’s also a lot of value in just being like, “I’m going to essentially assume, I’m going to condition on this problem being possible or this being broadly the right approach. And I’m just going to go and assume that for a while and go and work within that, and push really hard on it.” And if society has lots of people doing that for different things, that’s actually really useful in terms of going and-"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:40:00)",
                "text": "… things that’s actually really useful in terms of going and either really ruling things out. We can be like, “Well, that didn’t work and we know that somebody tried hard.” Or going and getting to something that does teach us something about the world."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:40:17)",
                "text": "So another interesting hypothesis is the super superposition hypothesis. Can you describe what superposition is?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:40:22)",
                "text": "Yeah. So earlier we were talking about word defect, right? And we were talking about how maybe you have one direction that corresponds to gender and maybe another that corresponds to royalty and another one that corresponds to Italy and another one that corresponds to food and all of these things. Well, oftentimes maybe these word embeddings, they might be 500 dimensions, a thousand dimensions. And so if you believe that all of those directions were orthogonal, then you could only have 500 concepts. And I love pizza. But if I was going to go and give the 500 most important concepts in the English language, probably Italy wouldn’t be… it’s not obvious, at least that Italy would be one of them, right? Because you have to have things like plural and singular and verb and noun and adjective. And there’s a lot of things we have to get to before we get to Italy and Japan, and there’s a lot of countries in the world."
            },
            {
                "speaker": "",
                "time": "(04:41:18)",
                "text": "And so how might it be that models could simultaneously have the linear representation hypothesis be true and also represent more things than they have directions? So what does that mean? Well, okay, so if linear representation hypothesis is true, something interesting has to be going on. Now, I’ll tell you one more interesting thing before we go, and we do that, which is earlier we were talking about all these polysemantic neurons, these neurons that when we were looking at inception V1, these nice neurons that the car detector and the curve detector and so on that respond to lots of very coherent things. But it’s lots of neurons that respond to a bunch of unrelated things. And that’s also an interesting phenomenon. And it turns out as well that even these neurons that are really, really clean, if you look at the weak activations, so if you look at the activations where it’s activating 5% of the maximum activation, it’s really not the core thing that it’s expecting."
            },
            {
                "speaker": "",
                "time": "(04:42:14)",
                "text": "So if you look at a curve detector for instance, and you look at the places where it’s 5% active, you could interpret it just as noise or it could be that it’s doing something else there. Okay? So how could that be? Well, there’s this amazing thing in mathematics called compressed sensing, and it’s actually this very surprising fact where if you have a high dimensional space and you project it into a low dimensional space, ordinarily you can’t go and sort of un-projected and get back your high dimensional vector, you threw information away. This is like you can’t invert a rectangular matrix. You can only invert square matrices. But it turns out that that’s actually not quite true. If I tell you that the high-dimensional vector was sparse, so it’s mostly zeros, then it turns out that you can often go and find back the high-dimensional vector with very high probability."
            },
            {
                "speaker": "",
                "time": "(04:43:12)",
                "text": "So that’s a surprising fact, right? It says that you can have this high-dimensional vector space, and as long as things are sparse, you can project it down, you can have a lower-dimensional projection of it, and that works. So the superstition hypothesis is saying that that’s what’s going on in neural networks, for instance, that’s what’s going on in word embeddings. The word embeddings are able to simultaneously have directions be the meaningful thing, and by exploiting the fact that they’re operating on a fairly high-dimensional space, they’re actually… and the fact that these concepts are sparse, you usually aren’t talking about Japan and Italy at the same time. Most of those concepts, in most instances, Japan and Italy are both zero. They’re not present at all. And if that’s true, then you can go and have it be the case that you can have many more of these sort of directions that are meaningful, these features than you have dimensions."
            },
            {
                "speaker": "",
                "time": "(04:44:04)",
                "text": "And similarly, when we’re talking about neurons, you can have many more concepts than you have neurons. So that’s at a high level, the superstition hypothesis. Now it has this even wilder implication, which is to go and say that neural networks, it may not just be the case that the representations are like this, but the computation may also be like this. The connections between all of them. And so in some sense, neural networks may be shadows of much larger sparser neural networks. And what we see are these projections. And the strongest version of superstition hypothesis would be to take that really seriously and sort of say there actually is in some sense this upstairs model where the neurons are really sparse and all interpleural, and the weights between them are these really sparse circuits. And that’s what we’re studying. And the thing that we’re observing is the shadow of evidence. We need to find the original object."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:45:03)",
                "text": "And the process of learning is trying to construct a compression of the upstairs model that doesn’t lose too much information in the projection."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:45:11)",
                "text": "Yeah, it’s finding how to fit it efficiently or something like this. The gradient descent is doing this and in fact, so this sort of says that gradient descent, it could just represent a dense neural network, but it sort of says that gradient descent is implicitly searching over the space of extremely sparse models that could be projected into this low-dimensional space. And this large body of work of people going and trying to study sparse neural networks where you go and you have… you could design neural networks where the edges are sparse and the activations are sparse."
            },
            {
                "speaker": "",
                "time": "(04:45:38)",
                "text": "And my sense is that work has generally, it feels very principled, it makes so much sense, and yet that work hasn’t really panned out that well, is my impression broadly. And I think that a potential answer for that is that actually the neural network is already sparse in some sense. You were trying to go and do this. Gradient descent was actually behind the scenes going and searching more efficiently than you could through the space of sparse models and going and learning whatever sparse model was most efficient. And then figuring out how to fold it down nicely to go and run conveniently on your GPU, which does as nice dense matrix multiplies. And that you just can’t beat that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:46:16)",
                "text": "How many concepts do you think can be shoved into a neural network?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:46:20)",
                "text": "Depends on how sparse they are. So there’s probably an upper bound from the number of parameters because you still have to have print weights that go and connect them together. So that’s one upper bound. There are in fact all these lovely results from compressed sensing and the Johnson-Lindenstrauss lemma and things like this that they basically tell you that if you have a vector space and you want to have almost orthogonal vectors, which is sort of probably the thing that you want here. So you’re going to say, “Well, I’m going to give up on having my concepts, my features be strictly orthogonal, but I’d like them to not interfere that much. I’m going to have to ask them to be almost orthogonal.”"
            },
            {
                "speaker": "",
                "time": "(04:46:56)",
                "text": "Then this would say that it’s actually for, once you set a threshold for what you’re willing to accept in terms of how much cosine similarity there is, that’s actually exponential in the number of neurons that you have. So at some point, that’s not going to even be the limiting factor, but there’s some beautiful results there. And in fact, it’s probably even better than that in some sense because that’s sort of for saying that any random set of features could be active. But in fact the features have sort of a correlational structure where some features are more likely to co-occur and other ones are less likely to co-occur. And so neural networks, my guest would be, could do very well in terms of going and packing things to the point that’s probably not the limiting factor."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:47:37)",
                "text": "How does the problem of polysemanticity enter the picture here?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:47:41)",
                "text": "Polysemanticity is this phenomenon we observe where you look at many neurons and the neuron doesn’t just sort of represent one concept, it’s not a clean feature. It responds to a bunch of unrelated things. And superstition you can think of as being a hypothesis that explains the observation of polysemanticity. So polysemanticity is this observed phenomenon and superstition is a hypothesis that would explain it along with some other things."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:48:05)",
                "text": "So that makes Mechinterp more difficult."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:48:08)",
                "text": "Right. So if you’re trying to understand things in terms of individual neurons and you have polysemantic neurons, you’re in an awful lot of trouble. The easiest answer is like, “Okay, well you’re looking at the neurons, you’re trying to understand them. This one responds for a lot of things. It doesn’t have a nice meaning. Okay, that’s bad.” Another thing you could ask is ultimately we want to understand the weights. And if you have two polysemantic neurons and each one responds to three things and then the other neuron responds to three things and you have a wait between them, what does that mean? Does it mean that all three, there’s these nine interactions going on?"
            },
            {
                "speaker": "",
                "time": "(04:48:40)",
                "text": "It’s a very weird thing, but there’s also a deeper reason, which is related to the fact that neural networks operate on really high dimensional spaces. So I said that our goal was to understand neural networks and understand the mechanisms. And one thing you might say is, “Well, it’s just a mathematical function. Why not just look at it, right?” One of the earliest projects I did studied these neural networks that mapped two-dimensional spaces to two-dimensional spaces, and you can sort of interpret them in this beautiful way is like bending manifolds. Why can’t we do that? Well, as you have a higher dimensional space, the volume of that space in some sense is exponential in the number of inputs you have. And so you can’t just go and visualize it."
            },
            {
                "speaker": "",
                "time": "(04:49:19)",
                "text": "So we somehow need to break that apart. We need to somehow break that exponential space into a bunch of things, some non-exponential number of things that we can reason about independently. And the independence is crucial because it’s the independence that allows you to not have to think about all the exponential combinations of things. And things being monosomatic, things only having one meaning, things having a meaning, that is the key thing that allows you to think about them independently. And so I think if you want the deepest reason why we want to have interpretable monosomatic features, I think that’s really the deep reason."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:49:58)",
                "text": "And so the goal here as your recent work has been aiming at is how do we extract the monosomatic features from a neural net that has polysemantic features and all this mess."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:50:10)",
                "text": "Yes, we observe these polysemantic neurons, we hypothesize that’s what’s going on is superposition. And if superposition is what’s going on, there’s actually a sort of well-established technique that is sort of the principled thing to do, which is dictionary learning. And it turns out if you do dictionary learning in particular, if you do sort of a nice efficient way that in some sense sort of nicely regularizes that as well called a sparse auto encoder. If you train a sparse auto encoder, these beautiful interpretable features start to just fall out where there weren’t any beforehand. So that’s not a thing that you would necessarily predict, but it turns out that works very, very well. To me, that seems like some non-trivial validation of linear representations and superposition."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:50:51)",
                "text": "So with dictionary learning, you’re not looking for particular kind of categories. You don’t know what they are, they just emerge."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:50:57)",
                "text": "Exactly. And this gets back to our earlier point when we’re not making assumptions. Gradient descent is smarter than us, so we’re not making assumptions about what’s there. I mean, one certainly could do that, right? One could assume that there’s a PHP feature and go and search for it, but we’re not doing that. We’re saying we don’t know what’s going to be there. Instead, we’re just going to go and let the sparse auto encoder discover the things that are there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:51:16)",
                "text": "So can you talk toward monosematicity paper from October last year? I heard a lot of nice breakthrough results."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:51:24)",
                "text": "That’s very kind of you to describe it that way. Yeah, I mean, this was our first real success using sparse autoencoders. So we took a one-layer model, and it turns out if you go and you do dictionary learning on it, you find all these really nice interpretable features. So the Arabic feature, the Hebrew feature, the Base64 features were some examples that we studied in a lot of depth and really showed that they were what we thought they were. Turns out if you train a model twice as well and train two different models and do dictionary learning, you find analogous features in both of them. So that’s fun. You find all kinds of different features. So that was really just showing that this works. And I should mention that there was this Cunningham and all that had very similar results around the same time."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:52:08)",
                "text": "There’s something fun about doing these kinds of small scale experiments and finding that it’s actually working."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:52:14)",
                "text": "Yeah, well, and that there’s so much structure here. So maybe stepping back, for a while I thought that maybe all this mechanistic interpolate work, the end result was going to be that I would have an explanation for why it was sort of very hard and not going to be tractable. We’d be like, “Well, there’s this problem with supersession and it turns out supersession is really hard and we’re kind of screwed, but that’s not what happened. In fact, a very natural simple technique just works. And so then that’s actually a very good situation. I think this is a sort of hard research problem and it’s got a lot of research risk and it might still very well fail, but I think that some very significant amount of research risk was put behind us when that started to work."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:52:57)",
                "text": "Can you describe what kind of features can be extracted in this way?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:53:02)",
                "text": "Well, so it depends on the model that you’re studying. So the larger the model, the more sophisticated they’re going to be. And we’ll probably talk about follow up work in a minute. But in these one layer models, so some very common things I think were languages, both programming languages and natural languages. There were a lot of features that were specific words in specific contexts, so the. And I think really the way to think about this is that the is likely about to be followed by a noun. So you could think of this as the feature, but you could also think of this as protecting a specific noun feature. And there would be these features that would fire for the in the context of say, a legal document or a mathematical document or something like this. And so maybe in the context of math, you’re like the, and then predict vector or matrix, all these mathematical words, whereas in other contexts you would predict other things, that was common."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:53:54)",
                "text": "And basically we need clever humans to assign labels to what we’re seeing."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:54:00)",
                "text": "Yes. So the only thing this is doing is that sort of unfolding things for you. So if everything was sort of folded over top of it, serialization folded everything on top of itself and you can’t really see it, this is unfolding it. But now you still have a very complex thing to try to understand. So then you have to do a bunch of work understanding what these are, and some are really subtle. There’s some really cool things even in this one layer model about Unicode, where of course some languages are in Unicode, and the tokenizer won’t necessarily have a dedicated token for every Unicode character. So instead, what you’ll have is you’ll have these patterns of alternating token or alternating tokens that each represent half of a Unicode character."
            },
            {
                "speaker": "",
                "time": "(04:54:40)",
                "text": "And you have a different feature that goes and activates on the opposing ones to be like, “Okay, I just finished a character, go and predict next prefix. Then okay, I’m on the prefix, predict a reasonable suffix.” And you have to alternate back and forth. So these swap layer models are really interesting. And I mean there’s another thing that you might think, “Okay, there would just be one Base64 feature, but it turns out there’s actually a bunch of Base64 features because you can have English text encoded as Base64, and that has a very different distribution of Base64 tokens than regular. And there’s some things about tokenization as well that it can exploit. And I don’t know, there’s all kinds of fun stuff."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:55:21)",
                "text": "How difficult is the task of assigning labels to what’s going on? Can this be automated by AI?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:55:28)",
                "text": "Well, I think it depends on the feature, and it also depends on how much you trust your AI. So there’s a lot of work doing automated interoperability. I think that’s a really exciting direction, and we do a fair amount of automated interoperability and have Claude go and label our features."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:55:42)",
                "text": "Is there some fun moments where it’s totally right or it’s totally wrong?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:55:47)",
                "text": "Yeah, well, I think it’s very common that it says something very general, which is true in some sense, but not really picking up on the specific of what’s going on. So I think that’s a pretty common situation. You don’t know that I have a particularly amusing one."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:56:06)",
                "text": "That’s interesting. That little gap between it is true, but it doesn’t quite get to the deep nuance of a thing. That’s a general challenge, it’s already an incredible caution that can say a true thing, but it’s missing the depth sometimes. And in this context, it’s like the ARC challenge, the sort of IQ type of tests. It feels like figuring out what a feature represents is a little puzzle you have to solve."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:56:35)",
                "text": "Yeah. And I think that sometimes they’re easier and sometimes they’re harder as well. Yeah, I think that’s tricky. There’s another thing which I don’t know, maybe in some ways this is my aesthetic coming in, but I’ll try to give you a rationalization. I’m actually a little suspicious of automated interoperability, and I think that partly just that I want humans to understand neural networks. And if the neural network is understanding it for me, I don’t quite like that, but I do have a bit of… In some ways, I’m sort of like the mathematicians who are like, “If there’s a computer automated proof, it doesn’t count.” They won’t understand it. But I do also think that there is this kind of reflections on trusting trust type issue where there’s this famous talk about when you’re writing a computer program, you have to trust your compiler."
            },
            {
                "speaker": "",
                "time": "(04:57:20)",
                "text": "And if there was malware in your compiler, then it could go and inject malware into the next compiler and you’d be kind of in trouble, right? Well, if you’re using neural networks to go and verify that your neural networks are safe, the hypothesis that you’re trusting for is like, “Okay, well the neural network maybe isn’t safe and you have to worry about is there some way that it could be screwing with you? I think that’s not a big concern now, but I do wonder in the long run, if we have to use really powerful AI systems to go and audit our AI systems, is that actually something we can trust? But maybe I’m just rationalizing because I just want us to have to get to a point where humans understand everything."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:57:58)",
                "text": "Yeah, I mean that’s hilarious, especially as we talk about AI safety and looking for features that would be relevant to AI safety, like deception and so on. So let’s talk about the Scaling Monosematicity paper in May 2024. Okay. So what did it take to scale this, to apply to Claude 3 Sonnet?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:58:18)",
                "text": "Well, a lot of GPUs."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:58:19)",
                "text": "A lot more GPUs. Got it."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:58:21)",
                "text": "But one of my teammates, Tom Henighan was involved in the original scaling laws work, and something that he was sort of interested in from very early on is are there scaling laws for interoperability? And so something he immediately did when this work started to succeed, and we started to have sparse autoencoders work, was he became very interested in what are the scaling laws for making sparse autoencoders larger and how does that relate to making the base model larger? And so it turns out this works really well and you can use it to sort of project, if you train a sparse autoencoder of a given size, how many tokens should you train on and so on. This was actually a very big help to us in scaling up this work, and made it a lot easier for us to go and train really large sparse autoencoders where it’s not training the big models, but it’s starting to get to a point where it’s actually expensive to go and train the really big ones."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:59:21)",
                "text": "I mean, you have to do all this stuff of splitting it across large CPUs-"
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:59:26)",
                "text": "Oh, yeah. No, I mean there’s a huge engineering challenge here too, right? Yeah. So there’s a scientific question of how do you scale things effectively? And then there’s an enormous amount of engineering to go and scale this up. You have to chart it, you have to think very carefully about a lot of things. I’m lucky to work with a bunch of great engineers because I am definitely not a great engineer."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(04:59:43)",
                "text": "And the infrastructure especially. Yeah, for sure. So it turns out TLDR, it worked."
            },
            {
                "speaker": "Chris Olah",
                "time": "(04:59:49)",
                "text": "It worked. Yeah. And I think this is important because you could have imagined a world where you set after towards monospecificity. Chris, this is great. It works on a one-layer model, but one-layer models are really idiosyncratic. Maybe that’s just something, maybe the linear representation hypothesis and superposition hypothesis is the right way to understand a one-layer model, but it’s not the right way to understand larger models. So I think, I mean, first of all, the Cunningham and all paper sort of cut through that a little bit and sort of suggested that this wasn’t the case."
            },
            {
                "speaker": "",
                "time": "(05:00:18)",
                "text": "But Scaling Monospecificity sort of I think was significant evidence that even for very large models, and we did it on Claude 3 Sonnet, which at that point was one of our production models. Even these models seemed to be substantially explained, at least by linear features. And doing dictionary learning on them works, and as you learn more features, you go and you explain more and more. So that’s, I think, quite a promising sign. And you find now really fascinating abstract features, and the features are also multimodal. They respond to images and texts for the same concept, which is fun."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:00:54)",
                "text": "Yeah. Can you explain that? I mean, backdoor, there’s just a lot of examples that you can-"
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:01:01)",
                "text": "Yeah. So maybe let’s start with that. One example to start, which is we found some features around security vulnerabilities and backdoorsing code. So turns out those are actually two different features. So there’s a security vulnerability feature, and if you force it active, Claude it will start to go and write security vulnerabilities like buffer overflows into code. And also fires for all kinds of things, some of the top data set examples where things like dash dash, disable SSL or something like this, which are sort of obviously really insecure."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:01:34)",
                "text": "So at this point, maybe it’s just because the examples are presented that way, it’s kind of surface a little bit more obvious examples. I guess the idea is that down the line it might be able to detect more nuance like deception or bugs or that kind of stuff."
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:01:50)",
                "text": "Yeah. Well, maybe I want to distinguish two things. So one is the complexity of the feature or the concept, right? And the other is the nuance of how subtle the examples we’re looking at, right?. So when we show the top data set examples, those are the most extreme examples that cause that feature to activate. And so it doesn’t mean that it doesn’t fire for more subtle things. So that insecure code feature, the stuff that it fires most strongly for are these really obvious disable the security type things, but it also fires for buffer overflows and more subtle security vulnerabilities in code. These features are all multimodal. You could ask it like, “What images activate this feature?” And it turns out that the security vulnerability feature activates for images of people clicking on Chrome to go past this website, the SSL certificate might be wrong or something like this."
            },
            {
                "speaker": "",
                "time": "(05:02:55)",
                "text": "Another thing that’s very entertaining is there’s backdoors in code feature, like you activate it, it goes and Claude writes a backdoor that will go and dump your data to port or something. But you can ask, “Okay, what images activate the backdoor feature?” It was devices with hidden cameras in them. So there’s a whole apparently genre of people going and selling devices that look innocuous that have hidden cameras, and they have ads that has this hidden camera in it? And I guess that is the physical version of a backdoor. And so it sort of shows you how abstract these concepts are, and I just thought that was… I’m sort of sad that there’s a whole market of people selling devices like that, but I was kind of delighted that that was the thing that it came up with as the top image examples for the feature."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:03:36)",
                "text": "Yeah, it’s nice. It’s multimodal. It’s multi almost context. It’s broad, strong definition of a singular concept. It’s nice."
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:03:44)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:03:45)",
                "text": "To me, one of the really interesting features, especially for AI safety, is deception and lying. And the possibility that these kinds of methods could detect lying in a model, especially get smarter and smarter and smarter. Presumably that’s a big threat over super intelligent model that it can deceive the people operating it as to its intentions or any of that kind of stuff. So what have you learned from detecting lying inside models?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:04:13)",
                "text": "Yeah, so I think we’re in some ways in early days for that, we find quite a few features related to deception and lying. There’s one feature where it fires for people lying and being deceptive, and you force it active and Claude starts lying to you. So we have a deception feature. I mean, there’s all kinds of other features about withholding information and not answering questions, features about power seeking and coups and stuff like that. So there’s a lot of features that are kind of related to spooky things, and if you force them active Claude will behave in ways that are… they’re not the kinds of behaviors you want."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:04:50)",
                "text": "What are possible next exciting directions to you in the space of Mechinterp?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:04:56)",
                "text": "Well, there’s a lot of things. So for one thing, I would really like to get to a point where we have shortcuts where we can really understand not just the features, but then use that to understand the computation of models. That relief for me is the ultimate goal of this. And there’s been some work, we put out a few things. There’s a paper from Sam Marks that does some stuff like this, and there’s been, I’d say some work around the edges here. But I think there’s a lot more to do, and I think that will be a very exciting thing that’s related to a challenge we call interference weights. Where due to superstition, if you just sort of naively look at what features are connected together, there may be some weights that don’t exist in the upstairs model, but are just sort of artifacts of superstition. So that’s a technical challenge Related to that, I think another exciting direction is just you might think of sparse autoencoders as being kind of like a telescope. They allow us to look out and see all these features that are out there, and as we build better and better sparse autoencoders, we better and better at dictionary learning, we see more and more stars. And we zoom in on smaller and smaller stars. There’s a lot of evidence that we’re only still seeing a very small fraction of the stars. There’s a lot of matter in our neural network universe that we can’t observe yet. And it may be that we’ll never be able to have fine enough instruments to observe it, and maybe some of it just isn’t possible, isn’t computationally tractable to observe. So it’s sort of a kind of dark matter in not in maybe the sense of modern astronomy of early astronomy when we didn’t know what this unexplained matter is. And so I think a lot about that dark matter and whether we’ll ever observe it and what that means for safety if we can’t observe it, if some significant fraction of neural networks are not accessible to us."
            },
            {
                "speaker": "",
                "time": "(05:06:56)",
                "text": "Another question that I think a lot about is at the end of the day, mechanistic interpolation is this very microscopic approach to interpolation. It’s trying to understand things in a very fine-grained way, but a lot of the questions we care about are very macroscopic. We care about these questions about neural network behavior, and I think that’s the thing that I care most about. But there’s lots of other sort of larger-scale questions you might care about. And the nice thing about having a very microscopic approach is it’s maybe easier to ask, is this true? But the downside is its much further from the things we care about. And so we now have this ladder to climb. And I think there’s a question of will we be able to find, are there larger-scale abstractions that we can use to understand neural networks that can we get up from this very microscopic approach?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:07:48)",
                "text": "Yeah. You’ve written about this as kind of organs question."
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:07:52)",
                "text": "Yeah, exactly."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:07:53)",
                "text": "If we think of interpretability as a kind of anatomy of neural networks, most of the circus threads involve studying tiny little veins looking at the small scale and individual neurons and how they connect. However, there are many natural questions that the small-scale approach doesn’t address. In contrast, the most prominent abstractions and biological anatomy involve larger-scale structures like individual organs, like the heart or entire organ systems like the respiratory system. And so we wonder, is there a respiratory system or heart or brain region of an artificial neural network?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:08:29)",
                "text": "Yeah, exactly. And I mean, if you think about science, right? A lot of scientific fields investigate things at many level of abstraction. In biology, you have molecular biology studying proteins and molecules and so on, and they have cellular biology, and then you have histology studying tissues, and then you have anatomy, and then you have zoology, and then you have ecology. And so you have many, many levels of abstraction or physics, maybe you have a physics of individual particles, and then statistical physics gives you thermodynamics and things like this. And so you often have different levels of abstraction."
            },
            {
                "speaker": "",
                "time": "(05:09:01)",
                "text": "And I think that right now we have mechanistic interpretability, if it succeeds, is sort of like a microbiology of neural networks, but we want something more like anatomy. And a question you might ask is, “Why can’t you just go there directly?” And I think the answer is superstition, at least in significant part. It’s that it’s actually very hard to see this macroscopic structure without first sort of breaking down the microscopic structure in the right way and then studying how it connects together. But I’m hopeful that there is going to be something much larger than features and circuits and that we’re going to be able to have a story that involves much bigger things. And then you can sort of study in detail the parts you care about."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:09:43)",
                "text": "I suppose, in your biology, like a psychologist or a psychiatrist of a neural network."
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:09:48)",
                "text": "And I think that the beautiful thing would be if we could go and rather than having disparate fields for those two things, if you could build a bridge between them, such that you could go and have all of your higher level distractions be grounded very firmly in this very solid, more rigorous, ideally foundation."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:10:11)",
                "text": "What do you think is the difference between the human brain, the biological neural network and the artificial neural network?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:10:17)",
                "text": "Well, the neuroscientists have a much harder job than us. Sometimes I just count my blessings by how much easier my job is than the neuroscientists. So we can record from all the neurons. We can do that on arbitrary amounts of data. The neurons don’t change while you’re doing that, by the way. You can go and ablate neurons, you can edit the connections and so on, and then you can undo those changes. That’s pretty great. You can intervene on any neuron and force it active and see what happens. You know which neurons are connected to everything. Neuroscientists want to get the connectome, we have the connectome and we have it for much bigger than C. elegans. And then not only do we have the connectome, we know which neurons excite or inhibit each other, right? It’s not just that we know the binary mask, we know the weights. We can take gradients, we know computationally what each neuron does. I don’t know. The list goes on and on. We just have so many advantages over neuroscientists. And then despite having all those advantages, it’s really hard. And so one thing I do sometimes think is like, “Gosh, if it’s this hard for us, it seems impossible under the constraints of neuroscience or near impossible.” I don’t know. Maybe part of me is I’ve got a few neuroscientists on my team, maybe I’m sort of like, “Ah, the neuroscientists. Maybe some of them would like to have an easier problem that’s still very hard, and they could come and work on neural networks. And then after we figure out things in sort of the easy little pond of trying to understand neural networks, which is still very hard, then we could go back to biological neuroscience.”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:11:51)",
                "text": "I love what you’ve written about the goal of MechInterp research as two goals, safety and beauty. So can you talk about the beauty side of things?"
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:11:59)",
                "text": "Yeah. So there’s this funny thing where I think some people are kind of disappointed by neural networks, I think, where they’re like, “Ah, neural networks, it’s just these simple rules. Then you just do a bunch of engineering to scale it up and it works really well. And where’s the complex ideas? This isn’t a very nice, beautiful scientific result.” And I sometimes think when people say that, I picture them being like, “Evolution is so boring. It’s just a bunch of simple rules. And you run evolution for a long time and you get biology. What a sucky way for biology to have turned out. Where’s the complex rules?” But the beauty is that the simplicity generates complexity."
            },
            {
                "speaker": "",
                "time": "(05:12:41)",
                "text": "Biology has these simple rules and it gives rise to all the life and ecosystems that we see around us. All the beauty of nature, that all just comes from evolution and from something very simple in evolution. And similarly, I think that neural networks build, create enormous complexity and beauty inside and structure inside themselves that people generally don’t look at and don’t try to understand because it’s hard to understand. But I think that there is an incredibly rich structure to be discovered inside neural networks, a lot of very deep beauty if we’re just willing to take the time to go and see it and understand it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:13:20)",
                "text": "Yeah, I love Mechinterp. The feeling like we are understanding or getting glimpses of understanding the magic that’s going on inside is really wonderful."
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:13:30)",
                "text": "It feels to me like one of the questions that’s just calling out to be asked, and I’m sort of, I mean a lot of people are thinking about this, but I’m often surprised that not more are is how is it that we don’t know how to create computer systems that can do these things? And yet we have these amazing systems that we don’t know how to directly create computer programs that can do these things, but these neural networks can do all these amazing things. And it just feels like that is obviously the question that is calling out to be answered. If you have any degree of curiosity, it’s like, “How is it that humanity now has these artifacts that can do these things that we don’t know how to do?”"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:14:06)",
                "text": "Yeah. I love the image of the circus reaching towards the light of the objective function."
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:14:11)",
                "text": "Yeah, it’s this organic thing that we’ve grown and we have no idea what we’ve grown."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:14:15)",
                "text": "Well, thank you for working on safety, and thank you for appreciating the beauty of the things you discover. And thank you for talking today, Chris, this was wonderful."
            },
            {
                "speaker": "Chris Olah",
                "time": "(05:14:23)",
                "text": "Thank you for taking the time to chat as well."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(05:14:26)",
                "text": "Thanks for listening to this conversation with Chris Ola and before that, with Dario Amodei and Amanda Askell. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Alan Watts. “The only way to make sense out of change is to plunge into it, move with it, and join the dance.” Thank you for listening and hope to see you next time."
            }
        ]
    },
    {
        "title": "CIA, KGB, Illuminati, Secret Societies, Cults & Conspiracies",
        "guest": "Rick Spence",
        "thumbnail": "https://lexfridman.com/files/thumbs_ai_podcast/rick_spence.png",
        "video_link": "https://www.youtube.com/watch?v=abd5hguWKz0",
        "episode_link": "https://lexfridman.com/rick-spence",
        "transcript_link": "https://lexfridman.com/rick-spence-transcript",
        "timestamps": [
            {
                "time": "0:00",
                "chapter": "Introduction"
            },
            {
                "time": "0:37",
                "chapter": "KGB and CIA"
            },
            {
                "time": "14:54",
                "chapter": "Okhrana, Cheka, NKVD"
            },
            {
                "time": "30:26",
                "chapter": "CIA spies vs KGB spies"
            },
            {
                "time": "37:02",
                "chapter": "Assassinations and mind control"
            },
            {
                "time": "43:56",
                "chapter": "Jeffrey Epstein"
            },
            {
                "time": "50:48",
                "chapter": "Bohemian Grove"
            },
            {
                "time": "1:02:42",
                "chapter": "Occultism"
            },
            {
                "time": "1:13:53",
                "chapter": "Nazi party and Thule society"
            },
            {
                "time": "1:54:11",
                "chapter": "Protocols of the Elders of Zion"
            },
            {
                "time": "2:27:16",
                "chapter": "Charles Manson"
            },
            {
                "time": "2:54:03",
                "chapter": "Zodiac Killer"
            },
            {
                "time": "3:04:57",
                "chapter": "Illuminati"
            },
            {
                "time": "3:12:21",
                "chapter": "Secret societies"
            }
        ],
        "transcript": [
            {
                "speaker": "Rick Spence",
                "time": "(00:00:00)",
                "text": "Most people, most of the time are polite, cooperative, and kind until they’re not."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:00:13)",
                "text": "The following is a conversation with Rick Spence, a historian specializing in the history of intelligence agencies, espionage, secret societies, conspiracies, the occult and military history. This is the Lex Fridman Podcast. To support it, please check out our sponsors in the description. And now dear friends, here’s Rick Spence."
            },
            {
                "speaker": "",
                "time": "(00:00:38)",
                "text": "You have written and lectured about serial killers, secret societies, cults and intelligence agencies. So we can basically begin at any of these fascinating topics, but let’s begin with intelligence agencies. Which has been the most powerful intelligence agency in history?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:00:55)",
                "text": "The most powerful intelligence agency in history. It’s an interesting question. I’d say probably in terms of historical longevity and consistency of performance that the Russian Intelligence Services. Notice I didn’t say the KGB specifically, but the Russian Intelligence Services, going back to the Czarist period are consistently pretty good. Not infallible, none of them are. Of course, there’s a common Western way of looking at anything Russian. Very often, I think it’s still the case Russians are viewed in one or two ways. Either they are Bumbling idiots or they’re diabolically clever, no sort of middle ground. You can find both of those examples in this."
            },
            {
                "speaker": "",
                "time": "(00:01:49)",
                "text": "So what I mean by that is that if you’re looking at the modern SVR or FSB, which are just two different organizations that used to be part of the one big KGB or the KGB or its predecessors, the Checka, you’re really going back to the late 19th century and the Imperial Russian Intelligence Security Service, generally known as the Okhrana or Okhrana."
            },
            {
                "speaker": "",
                "time": "(00:02:17)",
                "text": "It’s really the Department of Police, the special Corps of Gendarmes. Their primary job was protecting the imperial regime and protecting it against imperial or other interior enemies, Revolutionaries for the most part. They got very, very good at that by co-opting people within those movements, infiltrating and recruiting informers, [inaudible 00:02:41] provocateurs. In fact, they excelled at the [inaudible 00:02:45] provocateur."
            },
            {
                "speaker": "",
                "time": "(00:02:46)",
                "text": "Person who placed aside an organization to cause trouble, usually maneuver them into a position of leadership, and they provoke actions that can then allow you to crack down on that is many sort of lure or bring the target organization into any legal or open status that it can be more effectively suppressed. They were very good at that. So good that by the early 20th century in the years preceding the Russian Revolution in 1917, they had effectively infiltrated every radical party, Bolsheviks, Menchaviks, SRs, great and small, and placed people in positions of influence and leadership to the point that arguably that is, you can debate this, that I think in the whole, they could largely dictate what those parties did."
            },
            {
                "speaker": "",
                "time": "(00:03:42)",
                "text": "Nothing was discussed at any central committee meeting of any revolutionary group that the Okhrana wasn’t immediately aware of, and they often had people in positions to influence what those decisions were. Of course, that raises an interesting question, is that if they were that good and they had infiltrated and effectively controlled most of the opposition, then how did the regime get overthrown by revolutionaries? The answer to that is that it wasn’t overthrown by revolutionaries, it was overthrown by politicians. That would then take us into a detour into Russian history. But I’ll just leave it with this. If you look at 1917 and you look closely, this is one of the things I’d always tell my students is that there are two Russian revolutions in 1917. There’s the first one in March or February, depending on your calendar, that overthrows Nicholas II. Revolutionaries are really not involved with that."
            },
            {
                "speaker": "",
                "time": "(00:04:40)",
                "text": "Bolsheviks are nowhere to be seen. Trotsky and Lenin are nowhere to be seen. They have nothing to do with that. That has to do effectively with a political conspiracy within the Russian parliament, the Duma. To unseat and emperor, they thought was bungling the war and was essentially a loser to begin with. It was a coup d’etat, a parliamentary coup d’etat. The temporary or provisional government that that revolution put in power was the one overthrown by Lenin eight months later. That government was essentially one dominated by moderate socialists. It was a government that very quickly sort of turned to the left. The guy we associate with that is Alexander Kerensky. Alexander Kerensky was a Russian socialist, a politician. He was the quasi-dictator of that regime. He’s the person, not the Tsar, who’s overthrown by Lenin. So the revolutionaries then did not prove to be the fatal threat to the Tsarist regime."
            },
            {
                "speaker": "",
                "time": "(00:05:46)",
                "text": "It was the Tsarist political system itself that did that. What then transpired was that the Okhrana and its method, and many of its agents then immediately segued over into the new Soviet Security Service. So one of the first things that Lenin did in December of 1917, within a month of seizing power since the hold on power was tenuous at best, was that while you were going to need some kind of organization to infiltrate and suppress those pesky counter-revolutionaries and foreign imperialists and all of the other enemies that we have. So the extraordinary Commission to Combat Counter-revolution and sabotage the Cheka was formed. You put a veteran Bolshevik, Felix Dzerzhinsky at the head of that someone you could politically rely upon, but Dzerzhinsky built his organization essentially out of the Okhrana. There were all of these informers sitting around with nothing to do, and they were employed in the early twenties. The kind of rank-and-file of the Cheka might’ve been 80 to 90% former Imperial officials. Those were gradually decreased over time."
            },
            {
                "speaker": "",
                "time": "(00:07:02)",
                "text": "So why would they do that? Well, they were professionals. They also needed to eat and things were somewhat precarious. So if your job is to be an agent provocateur, if your job is to infiltrate targeted organizations and lead them astray, you do that for whoever pays you. That’s part of the professionalism, which goes in. Under the Soviets, the Soviet Intelligence Services are also very good at that. They’re very good at infiltrating people into opposing organizations. I guess the one example I would give to demonstrate that at the Cambridge five, the British traders from the Soviet standpoint, heroes who were recruited, most notably Kim Philby, Guy Burgess, Donald McClain, Anthony Blunt, and there may have been, well more than five, but that wasn’t bad out of just Cambridge."
            },
            {
                "speaker": "",
                "time": "(00:07:59)",
                "text": "Then placing those people in high positions, the ultimate goal, of course, is to get your people into positions of leadership and influence in the opposing intelligence service. So they did. Of course, it all fell apart and they ended up in …Philby ended up living the last part of his life in exile in Moscow, but they got their money’s worth out of him. You can also find this in KGB infiltration, the CIA, the FBI, the Aldrich Ames, Robert Hanson cases. Of course, we were infiltrating. By we, I mean the Americans in the West managed to infiltrate our moles as well. But if it came down, someone could dispute this. But I would think if you were going to come down to kind of like who had the most moles Super Bowl, probably the Soviets would come somewhat ahead of that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:08:57)",
                "text": "So the scale of the infiltration, the number of people and the skill of it, is there a case to be made that the Okhrana and the Chaka orchestrated both the components of the Russian Revolution as you described them?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:09:14)",
                "text": "Well, there’s an interesting question for me. There are all kinds of questions about this. One of the questions is whether or not Lenin was an Okhrana agent. Okay, I’ve just said heresy. I’ll do that quite often. I am a heretic and proud of it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:09:31)",
                "text": "Great."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:09:33)",
                "text": "Why would you possibly say that Lenin could have been an Okhrana agent? Well, let’s look what he managed to do. So you had, coming into the 20th century, nominally, a single Marxist movement, the Russian social Democratic Labor Party, and Bolsheviks and Mensheviks majority- ites and minority-ites are merely factions of that party. They always agreed that they were all Marxists. We all believe in dialectical materialism and the rise of were all socialists comrade. The difference was the tactical means by which one would attain this. What Lenin wanted was a militant small-scale Vanguard party. Wanted a revolution, wanted to seize power, seize control of the state."
            },
            {
                "speaker": "",
                "time": "(00:10:31)",
                "text": "Once you have the state, then you induce socialism from above. Whereas the majority of the people, the so-called Mensheviks, the minority-ites who are oddly-enough, the vast majority of the party, that’s one of the first things. How do you lose that argument? How does the minority get to grab the name? But Lenin did that. So what Lenin wanted was a conspiratorial party of committed revolutionaries that would plot and scheme and undermine and eventually seize control of the state and induce socialism from above. There were other Russian Marxists who thought that that sounded vaguely totalitarian and not really democratic and not even terribly socialist. They opposed that ineffectively from the beginning, outmaneuvered every step of the way. The Mensheviks are a case study in failure of a political organization. That too will be heresy to some people."
            },
            {
                "speaker": "",
                "time": "(00:11:38)",
                "text": "But look, they lost. So what Lenin managed to do starting around 1903, continuing under this, is he managed to divide, to take what had been a single Marxist party and split it into angry contending factions because he and his Bolsheviks run one side advocating a much more militant conspiratorial policy. The discombobulated Mensheviks were over on the other. And in between were a lot of people who really didn’t know where they stood on this. Sometimes they kind of agreed he seems to be making sense today. No, no, I don’t think he’s making sense in that day. But he managed to completely disunify this organization. Now, who could possibly have seen benefit in that the Okhrana. Now, whether or not they put him up to it, whether or not in some way they helped move him into a position of leadership or encouraged it or encouraged it through people around him, whether he was a witting or unwitting agent of the Tsar’s Secret Police, he certainly accomplished exactly what it was that they had wanted."
            },
            {
                "speaker": "",
                "time": "(00:12:52)",
                "text": "I find that suspicious. It’s one of those things that it’s so convenient in a way, is that I’m not necessarily sure that was an accident. There’s also this whole question to me as to what was going on within the Okhrana itself. Now, this is one of these questions we may come to later about how intelligence agencies interact or serve the governments to which they are theoretically subordinate. They do tend to acquire a great deal of influence and power. After all, their main job is to collect information. That information could be about all kinds of things, including people within the government structure itself."
            },
            {
                "speaker": "",
                "time": "(00:13:43)",
                "text": "They also know how to leverage that information in a way to get people to do what you want them to do. So an argument can be made, again, an argument, not a fact, merely an opinion, which is mostly what history is made out of opinions is that at some point between about 1900 and 1917, people within the Okhrana were playing their own game. That game took them in a direction, which meant that continued loyalty to the emperor, specifically to Nicholas II, was no longer part of that."
            },
            {
                "speaker": "",
                "time": "(00:14:23)",
                "text": "To me, in a way, it seems almost during the events of 1917, that one, you had an organization that was very effective that suddenly just becomes ineffective. It doesn’t really disappear. These things don’t go away because it will reappear as the O’Chacka basically fairly quickly. But it raises the question to me as to what degree there were people within the organization who allowed events to take the course they wished."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:14:55)",
                "text": "I always wonder how much deliberate planning there is within an organization like Okhrana or if there’s kind of a distributed intelligence that happens."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:15:07)",
                "text": "Well, one of the key elements that any kind of intelligence organization or operation is compartmentalization need to know. So rarely do you have an occasion where everybody in an executive position are all brought into a big corporate meeting and we discuss all of the secret operations that are going on. No, no, you never do that. Only a very limited number of people should know about that. If you have a person who is a case officer, is controlling agency, he’s the only one that should know who those people are, possibly his immediate superiors. But no way do you want that to be common knowledge. So information within the organization itself is compartmentalized. So you don’t need everybody to be in on it. You don’t even need necessarily the people who are nominally at the top. Versus the Okhrana, the real boss of the Okhrana was the Imperial ministry of the Interior, the Minister of the Interior, in fact."
            },
            {
                "speaker": "",
                "time": "(00:16:07)",
                "text": "But the Minister of the Interior had no real effective control over this at all. To the point was that at one point early on, they actually organized the assassination of their own boss. They have their agents among the revolutionaries kill the Minister of the Interior. He’ll just replaced by another one. He’s an Imperial bureaucrat. He’s not really part of their organization. It’s like a director of an intelligence agency appointed by the president. Maybe he’s part of the organization, maybe he isn’t. Maybe he is not one of us. So you’ve got different levels, different compartments within it. Who’s actually running the show, if anyone is, I don’t know. That’s never supposed to be apparent."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:17:00)",
                "text": "Well, that’s a fascinating question. You could see this with NKVD. It’s obviously an extremely powerful organization that starts to eat itself, where everybody’s pointing fingers internally also as a way to gain more power. So the question is in organizations like that that are so-called compartmentalized, where’s the power? Where’s the center of power? Because you would think given that much power, some individual or a group of individuals will start accumulating that power. But it seems like that’s not always a trivial thing because if you get too powerful, the snake eats that person."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:17:43)",
                "text": "Well, if we go back again to the founder of Soviet Secret Police, Felix Dzerzhinsky dies in 1926, keels over after giving a heated speech to a party meeting. Now, the common view, what you usually read, which was key for the time, is that clearly Stalin had him whacked because anytime someone died, it was almost always that. I think a lot of times he did. But in some cases, Stalin’s probably getting blamed for things that he didn’t actually do. Dzerchinsky wasn’t even opposed to Stalin. So it’s not clear why he … but Stalin died. Obviously, he was poisoned. Something happened. It was an unnatural death. Somebody goes in for an operation, it gets a little too much anesthesia. Stalin killed them. Somebody tips over in a canoe in upstate New York, Stalin killed them. There’s actually a case about that. So that itself can be kind of useful, where every time someone dies, they think you killed them."
            },
            {
                "speaker": "",
                "time": "(00:18:53)",
                "text": "That’s kind of an interesting method of intimidation in that regard. But the suspicion is nonetheless there, Dzerzhinsk was the grand inquisitor. He was seemingly firmly in control of the organization. Of course, maybe he wasn’t. My guess would be is that if Dzerzhinsky’s death was not natural causes, that he was probably eliminated by someone within his own organization. Then you look at the people who take over his immediate successor is Vyacheslav Menzhinsky who’s really not really a secret policeman, more a kind of intellectual dilettante. But if you look behind him, is the fellow Genrikh Yagoda, and Yagoda will really manage things from behind the scenes until Menzhinsky dies in 1930."
            },
            {
                "speaker": "",
                "time": "(00:19:52)",
                "text": "Then Yagoda will hold on until he’s the victim of the purges, I think in 37 or 38. Yagoda is ambitious, murderous, and if I was going to point the finger to anybody who possibly had Dzerzhinsky whacked, it would be him. For the purposes simply of advancement. The person to look out at any kind of corporate organization is your immediate subordinate, the person who could move into your job, because more than likely, that’s exactly what they’re planning to do."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:20:31)",
                "text": "Yeah, just one step away from the very top, somebody there will probably accumulate the most power. You mentioned that the various Russian intelligence agencies were good at creating agent provocateurs infiltrating the halls of power. What does it take to do that?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:20:53)",
                "text": "Well, there’s an interesting little acronym called MICE, M-I-C-E. It’s generally used, and it’s just the way in which you would acquire. How do you get people to work for you? Well, M stands for money. You pay them. People are greedy. They want money. If you look at Aldrich Ames, he had a very, very expensive wife with expensive tastes. So he wanted money. I is for ideology. So during, particularly in the 1920s and the 1930s, the Soviets were very effective in exploiting communists, people who wanted to serve the great cause, even though that’s initially not really what they wanted to do. Because the idea was that if you recruit agents from among, let’s say, American communists, you compromise the party because exactly what your enemies are going to say is that all communists are Soviet spies. They’re all traitors in some way. So you would really want to keep those two things separate."
            },
            {
                "speaker": "",
                "time": "(00:21:55)",
                "text": "But ideology was just so convenient, and those people would just work for you so well. You could get them to do anything, betray their grandmother. They would go ahead and do that for the greater good. So ideology can be a motivation, and that can be someone who is a devoted Marxist-Leninist. It can also be someone who’s a disgruntled communist because there’s no anti-communist like an ex-communist."
            },
            {
                "speaker": "",
                "time": "(00:22:25)",
                "text": "Those who lose the faith can become very, very useful. For instance, if you look in the case of American intelligence, the people who essentially temporarily destroyed much of the KGB organization in the US post-World War II, where people like Whitaker Chambers, Louis Budenz, Elizabeth Bentley, all of those people had been Communist party members. They had all been part of the Red Faithful. They all, for one reason or another, became disillusioned and turned rat or patriot, whichever case you may want to put in that regard."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:23:12)",
                "text": "What does the C in the E stand for?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:23:14)",
                "text": "The C is for coercion. That’s where you have to persuade someone to work for you. You have to pressure them. So usually you blackmail them. That could be they have a gambling habit. In the old days, it’s very often they were gay. Get them in a decision where they can be compromised and you can get them to do your bidding. Those people usually have a certain amount of control. Here’s an interesting example of how the Okhrana tended to handle this, and I think it’s still largely used. You’d round up a bunch of revolutionaries on some charge or another distributing revolutionary literature, running any illegal printing press. You bring a guy into the room and you say, okay, you’re going to work for us. Of course, we refuse to do so. They go, well, if you refuse, we’ll keep the rest of your comrades in jail for a while, maybe beat them with a rubber truncheon or so, and then we’re just going to let you go. We’re just going to put you back out on the street."
            },
            {
                "speaker": "",
                "time": "(00:24:17)",
                "text": "If you don’t work for us, we will spread the rumor through our agents already in your organization that you are. Then what will your comrades do? How long are you going to live? So you see, you have no choice. You’re ours, and you’re going to cooperate with us. The way that that effectiveness will be ensured is that you have multiple agents within the same organization who don’t know who each other are. That’s very important. They’ll all be filing reports. So let’s say you have three agents inside the central committee of the SR party, and there’s a committee meeting, and you’re going to look at the reports they file. They all better agree with each other. If one person doesn’t report what the other two do, then perhaps they’re not entirely doing their job and they can be liquidated at any time. All you do is drop the dime on them."
            },
            {
                "speaker": "",
                "time": "(00:25:18)",
                "text": "This was done periodically. In fact, in some cases, you would betray your own agents just to completely discombobulate to the organization. This happened in one particular case around 1908, the fellow who was the head of the chief revolutionary terrorist organization, which wasn’t Bolshevik, but the so-called socialist revolutionaries. Actually the biggest revolutionary party, the SRs, who aren’t even actually Marxists more anarchists, but they went all in for the propaganda, the deed. They really like blowing people up and carried out quite a campaign of terrorism. The fellow who was the head of that terrorist organization was a fellow by name of Yevno Azef. Yevno Azef was, guess what? An Okhrana agent. Everything he did, every assassination that he planned, he did in consultation with his control. So he’d kind of run out his string. There was increasing suspicion of him."
            },
            {
                "speaker": "",
                "time": "(00:26:23)",
                "text": "He was also asking for a lot more money. So the Okhrana itself arranged to have him ride it out. What did that do? Well, what do you do in your party when you find out the chief of your terrorist brigade was a secret police agent. It’s consternation and mistrust. Nobody in the party would ever trust, and you couldn’t tell who you were sitting around. I know that a fellow I wrote a biography on Boris Sevenkov who was a Russian revolutionary and the second in command within the terrorist organization. By the way, the guy that wanted Azef’s job so bad he could taste it, well, on the one level, he expressed absolute horror that his boss was a police agent, and well, he should, because Sevenkov was a police agent too. See, they already had the number two waiting in the wings to take over, but he was legitimately shocked. He didn’t really suspect that."
            },
            {
                "speaker": "",
                "time": "(00:27:23)",
                "text": "So it’s a way of manipulating this. Then finally, we come to the E. That I think is the most important, ego. Sometimes people spy or betray because of the egotistical satisfaction that they receive, the sheer kind of Machiavellian joy in deceit. An example of that would be Kim Philby, one of the Cambridge five. Now, Philby was a communist, and he would argue that he always saw himself as serving the communist cause. But he also made this statement, I think it’s in the preface to his autobiography, and he says, one never looks twice at the offer of service in elite force. He’s talking about his recruitment by the NKVD in the 1930s, and he was absolutely chuffed by that."
            },
            {
                "speaker": "",
                "time": "(00:28:21)",
                "text": "The mere fact that they would want him, what he considered to be a first-rate organization would want him, satisfied his ego. If I was to take a guess as to whether it was ideological motivation, whether it was the romance of communism or whether it was the appeal of ego that was the most important in his career of treason, I’d go with ego. I think that figures into a lot. Someone doesn’t get the promotions that they wanted. Again, if you look at something like Aldrich Ames career in particular, you’ve got these … his career in the CIA was hit or miss."
            },
            {
                "speaker": "",
                "time": "(00:29:08)",
                "text": "He didn’t get the postings or promotions that he wanted his evaluation. He never felt that he got credit for doing that. That’s the type of thing that tends to stick in someone’s craw and can lead for egotistical reasons an added incentive to betray."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:29:24)",
                "text": "Yeah, that there’s a boost to the ego when you can deceive, sort of not play by the rules of the world and just play with powerful people like they’re your pawns."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:29:36)",
                "text": "You’re the only one that knows this. You’re only the only one that knows that the person who is sitting across from you to which you have sworn your loyalty, you’re simultaneously betraying. What a rush that must be for some people."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:29:51)",
                "text": "I wonder how many people are susceptible to this. I would like to believe that the people, a lot of people have the integrity to at least withstand the money and the ideology, the pull of that and the ego."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:30:08)",
                "text": "It can also be a combination of the two. You can create a recipe of these things, certain amount of money, ego and a little push of coercion that if you don’t, we’ll rat you out. You’ll be exposed."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:30:27)",
                "text": "What are some differences to you as we look at the history of the 20th century between the Russian intelligence and the American intelligence in the CIA?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:30:36)",
                "text": "If you look at both the Okhrana and the KGB, one of the things that you find consistent is that a single organization handled foreign intelligence that is spying upon enemy or hostile governments and also internal security. So that’s all part of it. Whereas if you look at the US models that evolved, you eventually have the FBI under Hoover, who insists that he’s going to be the counterintelligence force. If there are commie spies running around America, it’s the FBI who’s supposed to ferret them out. The CIA is not supposed to be involved in that. The Charter, the basic agreement in 1947, did not give the CIA any … It’s often said they were barred from spying on Americans, which isn’t quite true. You can always find a way to do that. What they don’t have is they don’t have any police or judicial powers."
            },
            {
                "speaker": "",
                "time": "(00:31:34)",
                "text": "They can’t run around in the country carrying guns to use on people. They can’t arrest you. They can’t interrogate you, they can’t jail you. They have no police or judicial powers. Now, that means they have to get that from someone else. That doesn’t mean that other agencies can’t be brought in or local police officials, corn or whatever you need you can eventually acquire. But they can’t do that directly. So you’ve got this division between foreign intelligence and domestic counterintelligence often split between hostile organizations. The relationship between the FBI and the CIA, I think it’s fair to say, is not chummy, never has been. There’s always been a certain amount of rivalry and contention between the two. It’s not to say that something like that didn’t exist between the domestic counterintelligence and foreign intelligence components of the KGB, but there would be less of that to a degree, because there was a single organization."
            },
            {
                "speaker": "",
                "time": "(00:32:42)",
                "text": "They’re all answerable to the same people. So that gives you a certain greater amount, I think, of leeway and power because you’re controlling both of those ends. I remember somebody telling me once that, and he was a retired KGB officer. There you go, retired. One of the things that he found amusing was that in his role, one of the things that he could be is that he could be anywhere at any time in any dress, which meant that he could be in or out of uniform and any place at any time. He was authorized to do that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:33:26)",
                "text": "So more freedom, more power."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:33:29)",
                "text": "I think one of the things that you would often view is that, well, the Russians are simply naturally meaner. There’s less respect for human rights. There’s a greater tendency to abuse power that one might have. Frankly, they’re all pretty good at that. It is fair to say that there’s probably some degree of cultural differences that are not necessarily for institutional reasons, but cultural reasons. There could well be things that Americans might balk at doing more than you would find on the Russian or Soviet side of the equations. The other aspect of that is that Russian history is long and contentious and bloody."
            },
            {
                "speaker": "",
                "time": "(00:34:22)",
                "text": "One of the things it certainly teaches you never trust foreigners. Every foreign government anywhere, any country on your border is a real or potential enemy. They will all, at some point, if given the chance, invade you. Therefore, they must always be treated with great suspicion. It goes back to something that I think the British observed was that countries don’t have friends, they have interests, and those interests can change over time."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:34:54)",
                "text": "Well, the CIA is probably equally suspicious of all other nations."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:34:58)",
                "text": "That’s your job. You’re supposed to be suspicious. Your job is not to be trusting. Yeah, the basic job of an intelligence-"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:35:00)",
                "text": "… your job is not to be trusting. Yeah. The basic job of an intelligence agency is to safeguard your secrets and steal the other guys’ and then hide those away."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:35:10)",
                "text": "Are there laws, either intelligence agencies that they’re not willing to break? Is it basically lawless operation to where you can break any law as long as it accomplishes the task?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:35:24)",
                "text": "Well, I think John le Carre, give his pen name, was talking about his early recruitment into British intelligence. And one of the things he remembered being told up front was, “If you do this, you have to be willing to lie and you have to be willing to kill.” Now, those are things that in ordinary human interactions are bad things. Generally, we don’t like it when people lie to us. We expect that people will act honestly towards us, whether that’s being a businessman you’re involved with, your employers. We’re often disappointed in that because people do lie all the time for a variety of reasons, but honesty is generally considered to be. But in a realm where deception is a rule, dishonesty is a virtue. To be good at that, to be able to lie convincingly is good. It’s one of the things you need to do."
            },
            {
                "speaker": "",
                "time": "(00:36:32)",
                "text": "And killing also is generally frowned upon. Put people in prison for that, they’re otherwise executed. But in certain circumstances, killing is one of those things that you need to be able to do. So what he felt he was being told in that case is that once you enter this realm, the same sort of moral rules that apply in general British society do not apply. And if you’re squeamish about it, you won’t fit in. You have to be able to do those things."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:03)",
                "text": "I wonder how often those intelligence agencies in the 20th century, and of course the natural question extending it to the 21st century, how often they go to the assassination, how often they go to the kill part of that versus just the espionage."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:37:21)",
                "text": "Let’s take an example from American intelligence, from the CIA 1950s, 1960s into the 1970s, MKUltra. That is a secret program which was involved with what is generally categorized as mind control, which really means messing with people’s heads. And what was the goal of that? Well, there seemed to have been lots of goals. But there was an FBI memo that I recently acquired quite legally, by the way, it’s declassified, but it’s from 1949. So this is only two years after the CIA came into existence. And it’s an FBI memo because the FBI, of course, very curious what the CIA is up to and the FBI are not part of this meeting, but they have someone, they’re sort of spying on what’s going on. So there was a meeting which was held in a private apartment in New York. So it’s not held in any kind of, it’s essentially never really happened because it’s in somebody’s house. And there are a couple of guys there from the CIA. One of them is Cleve Backster. Cleve Backster is the great godfather of the lie detector. Pretty much everything that we know or think we know about lie detectors today, you owe to Cleve Backster. He’s also the same guy that thought that plants could feel, which somehow was a derivative of his work on lie detectors. So these guys are there and they’re giving a talk to some military and other personnel. And there’s certain parts of the document which are of course redacted, but you could figure out what it is that they’re talking about. And they’re talking about hypnotic suggestion and all the wonderful things that you can potentially do with hypnotic suggestion. And two of the things they note is that one of the things we could potentially do is erase memories from people’s minds and implant false memories. That would be really keen to do that, just imagine how that would be done. So here to me is the interesting point. They’re talking about this in 1949. MKUltra does not come along until really 1953. Although there are all sorts of Artichoke and others, everything is sort of leading up to that. It’s simply an elaboration of programs that were already there. I don’t think that it ultimately matters whether you can implant memories or erase memories. To me, the important part is they thought they could and they were going to try to do it. And that eventually is what you find out in the efforts made during the 1950s and ’60s through MKUltra, MKSearch, MKNaomi and all the others that came out. That’s one of the things they’re working for. And among the few MKUltra era documents that survived, there’s that whole question is that could you get someone to put a gun to someone’s head and pull the trigger and then not remember it later. Yeah, you could, interestingly enough."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:40:35)",
                "text": "So non-direct violence, controlling people’s minds, controlling people’s minds at scale and experimenting with different kinds of ways of doing that."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:40:45)",
                "text": "One person put it that the basic argument there or the basic thing you’re after was to understand the architecture of the human mind, how it worked, how it put together, and then how you could take those pieces apart and assemble them in different ways. So this is where hypnosis comes in, which was then, still is, fairly spooky thing. Nobody’s ever explained to me exactly what it is. The idea was that could, you think the whole possibilities in this case, could you create an alternate personality and use that alternate personality in an agent role, but then be able to turn it on and off."
            },
            {
                "speaker": "",
                "time": "(00:41:29)",
                "text": "So subsequently, the person which that personality inhabited was captured and interrogated, tortured, had their fingernails torn out, they would have no memory of it. They couldn’t give any kind of secret away because it was embedded in some part of their brain where there was a completely different person. You can just imagine the possibilities that you can dream up. And again, it’s not, I think, the question is to whether that is possible or whether it was done, although I suspect that both of those are true, but that you would try to do it. Then imagine the mischief that comes out of that. And one of the big complaints from a legal standpoint about MKUltra and the rest is that you were having medical experiments essentially being carried out on people without their knowledge and against their will, which is a no-no."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:42:25)",
                "text": "Yeah. The fact that you’re willing to do medical experiments says something about what you’re willing to do. And I’m sure that same spirit, innovative spirit, persists to this day. And maybe less so, I hope less so, in the United States, but probably in other intelligence agencies in the world."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:42:50)",
                "text": "Well, one thing that was learned, and the reason why most MKUltra and similar records were destroyed on order in the early ’70s, around the time the CIA became under a certain amount of scrutiny. The mid ’70s were not a good time for the agency because you had the church committee breathing down their neck, you had all of these… People were asking lots of questions. So you need to dump this stuff because there’s all kinds of, because you are committing crimes against American citizens, so let’s eradicate it. And the important lesson to be learned is that never do these type of thing again where at least in any way in which the agency’s direct fingerprints are placed on it. You can pay people. You can subsidize research. You can set up venture capital firms. You got plenty of money and you can funnel that money into the hands of people who will carry out this research privately. So if something goes wrong, you have perfect deniability."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:43:57)",
                "text": "On the topic of MICE, on the topic of money, ideology, coercion and ego, let me ask you about a conspiracy theory. So there is a conspiracy theory that the CIA is behind Jeffrey Epstein. At a high level, if you can just talk about that, is that something that’s at all even possible? That you have, basically this will be for coercion, you get a bunch of powerful people to be sexually mischievous and then you collect evidence on them so that you can then have leverage on them."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:44:31)",
                "text": "Well, let’s look at what Epstein was doing. He was a businessman who then also developed a very lucrative sideline in being a high-level procurer basically in supplying young girls. And he also filmed much of that activity. I think his partner in this, Ghislaine, and I’m hope I’m pronouncing her name correctly."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:45:03)",
                "text": "I think it’s Ghislaine."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:45:03)",
                "text": "Ghislaine?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:45:05)",
                "text": "Yeah."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:45:05)",
                "text": "Well, I’ve heard it both ways Ghislaine or Ghislaine, whichever it may be, I think her argument at one point was that, “Well, we did this to protect ourselves.” But this type of thing has been done before, there’s nothing new about this. Getting influential people in compromising situations and filming them. I could give you another historical example of that. In late 1920, actually early-1930s, just pre-Nazi Berlin, there was a very prominent sort of would-be psychic and occultist by the name of Erik Jan Hanussen. He had a private yacht, I think it was called the Seven Sins. And he hosted parties. He also had a whole club called the Palace of the Occult, which hosted parties where things went on. And there were cameras everywhere. He filmed important people, guys like the brownshirt chief of Berlin in various states of undress and sexual congress. And he did that for the purposes of blackmail."
            },
            {
                "speaker": "",
                "time": "(00:46:11)",
                "text": "So in Epstein’s case, he is a procurer of young girls to wealthy men largely. And many of those events were recorded. Now, even if it wasn’t his intention to use them for blackmail, think of what someone else could do it because people know about this. So you could raise a question Epstein is just kind of a greedy pervert, but through his greedy perversion, he’s now collecting information that could be useful. Who could that be useful to? Who would like dirt on Prince Andrew? Think of all the people who were there and there were important people who went to Lolita Island. So if it isn’t Epstein directly, he might have been being, I’m not trying to let him off the hook because they have anything for him, he was either running his own blackmail business or someone was using him as a front for that. I think we’re kidding ourselves if we’re trying to pretend that’s not what was going on."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:47:24)",
                "text": "So you think, EU and American intelligence agencies would be willing to swoop in and take advantage of a situation like that?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:47:33)",
                "text": "Well, you know-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:47:36)",
                "text": "Just in the case."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:47:36)",
                "text": "American politicians could ultimately end up in a position to oversee things like intelligence budgets. One of them might even become director. You’re never know. He can never tell what some crazy president might do. It could be very, one of the guys who understood was J. Edgar Hoover, J. Edgar Hoover spent a long time collecting dossiers on politicians. How do you think he’d remain director of the FBI as long as he did? Because he systematically collected dirt on people. So there is a history of this type of thing. And again, you could argue that’s partly for his protection, to keep his job, to protect the sanctity and security of the Bureau. You can find a million different ways to justify that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:48:28)",
                "text": "That’s really dark."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:48:31)",
                "text": "Well, there is that side to human nature, let’s put it that way."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:48:37)",
                "text": "Whether it’s the CIA or the Okhrana, maybe that’s what the President of the United States sees when they show up to office is all this stuff they have on him or her and say that there’s a internal mechanism of power that you don’t want to mess with and so you will listen, whether that internal mechanism of power is the military industrial complex or whatever, the bureaucracy of government."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:49:02)",
                "text": "Contacts with the deep state."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:49:04)",
                "text": "The deep state."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:49:05)",
                "text": "Entrenched, bureaucratic. Well, it’s been said and I think it’s generally true, that bureaucratic creatures are like any other creatures. It basically exists to perpetuate itself and to grow."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:49:16)",
                "text": "Yeah."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:49:17)",
                "text": "Nobody wants to go out of business. And of course, you get all of these things like Pizzagate and accusations of one form or another. But here’s an interesting thing to consider. Okay. And I want to argue that I’m not saying that Pizzagate in any way was real or QAnon, anything, but where do they get these ideas from? So let’s ask ourselves, do pedophiles exist? Yeah. Do organized pedophile organizations exist? Yeah, they share information, pictures, they’re out there on the dark web, they cooperate. So does child trafficking exist? Yeah, it does. So in other words, whether or not specific conspiracy theories about this or that group of organized pedophile cultists is real, all the ingredients for that to be real are there. Pedophiles exist, organized pedophilia exists, child and human trafficking exists. At some point, at some time, someone will put all of those together. In fact, certainly, they already have."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:50:42)",
                "text": "We’ll jump around a little bit."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:50:43)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:50:43)",
                "text": "But your work is so fascinating and it covers so many topics. So if we jump into the present with the Bohemian Grove and the Bilderberg group."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:50:54)",
                "text": "Bilderbergers."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:50:56)",
                "text": "So the elites, as I think you’ve referred to them. So these gathering of the elites, can you just talk about them? What is this?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:51:06)",
                "text": "Well, first thing I have to point out is that Bohemian Grove is a place, not an organization, it’s where the Bohemian Club meets. It’s that 2,700 acre, old-growth redwoods near north of San Francisco. The Bohemian Club began, I think it went back in the 1870s. Its initial members were mostly journalists. In fact, supposedly the name itself comes from, it was a term for an itinerant journalist who moved from paper to paper was called a bohemian. And although I think there may be other reasons why that particular term was chosen as well. But I think the original five members, there were three journalists, there was a merchant and there was a vintner, guy owned a vineyards, California. How surprising? None of them terribly wealthy, but they formed an exclusive men’s club, was and still is. And nothing terribly unusual about that at the time. But it became fashionable. And as it became fashionable, more wealthy people wanted to become part of it. And the thing about getting rich guys to join your club is what do rich guys have? Money. And of course, it’s one of those rich guys that bought Bohemian Grove where now you build your old boys summer camp, which is what it is. They got cabins with goofy names. They go there, they perform skits, they dress up in costumes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:52:36)",
                "text": "Yeah."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:52:37)",
                "text": "True. Some of those skits look like pagan human sacrifices, but it’s just a skit. What’s really going on there? So on the one hand you can argue, look, it’s a rich guy’s club. They like to get out there. The whole motto of the place is weaving spiders come not here. So we’re going to talk about in business. We just want to get out into the woods, put on some robes, burn a couple of effigies in front of the owl, have a good time, probably get drunk a lot."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:53:06)",
                "text": "What’s with the robes? Why do they do weird creepy shit? Why do they put on a mask and the robe and do the plays and the owl and then sacrificing, I don’t know, whatever?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:53:19)",
                "text": "Why do you have a giant owl?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:53:21)",
                "text": "Exactly."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:53:22)",
                "text": "Why do you do that?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:53:23)",
                "text": "What is that in human nature because I don’t think rich people are different than not rich people, what is it about wealth and power that brings that out of people?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:53:33)",
                "text": "Well, part of it is the ritual aspect of it. And yeah, that clearly is a ritual. Rituals are pretty simple. Rituals are just a series of actions performed in a precise sequence to produce an effect. That describes a lot of things. It describes plays, symphonies, every movie you’ve ever seen. A movie is a ritual. It is a series of actions carried out in a precise sequence to produce an effect with an added soundtrack to cue you to what emotions you’re supposed to be feeling."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:54:06)",
                "text": "It’s a great idea. So the rich people should just go to a movie or maybe just go to a Taylor Swift concert. Why do you have to, why the owl thing?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:54:16)",
                "text": "Part of it is to create this kind of sense, I suppose, of group solidarity. You’re all going to appear and also a way of transcending yourself in a way. When you put on the robe, it’s like putting on a uniform. You are in some way a different or more important person. It’s a ritual. Okay. The key ritual at Bohemian Grove is a thing called the cremation of care. And that’s what it’s supposed to be. “We’re going to put all of our, we’re rich, important people. We have to make all of these critical decisions. Life is so hard. So we’re going to go out here in the woods and we’re going to kick back and we’re all going to gather around the lake and then we’re going to carry,” it’s wicker, it’s not a real person. And how would you know? “And this is the cremation of our care,” but it’s a ritual which is meant to produce a sense of solidarity and relief among those people who are there."
            },
            {
                "speaker": "",
                "time": "(00:55:18)",
                "text": "The question comes down with the rituals as how seriously do you take them? How important is this to the people who carry them out? And the interesting answer to that is that for some people it’s just boring. There are probably people standing around the owl who think this is ridiculous and can’t wait for it to get over with. There are the people that are kind of excited about it, get caught up into it, but other people can take it very seriously. It’s all the matter of the intention that you have about what the ritual means. And I don’t mean to suggest by that that there’s anything necessarily sinister about what’s going on, but it is clearly a ritual carried out for some kind of group reinforcing purpose. And you’re absolutely right. You don’t have to do it that way. I’ve gone to summer camps and we never carried out mock sacrifices in front of an owl. We did all those other things. We didn’t even have any robes either. So it goes beyond merely a rich guy summer camp, although that’s an aspect of it."
            },
            {
                "speaker": "",
                "time": "(00:56:29)",
                "text": "But it also I think often obscures, focusing on Bohemian Grove at the getaway of the club, ignores that the club is around all the time. That’s what’s at the center of this, it is the club and its members. So despite all the talk about no weaving spiders coming around here, one of the other features of the summer meeting are things called lakeside talks. And this, often people are invited to go there. And one of the people who was invited, I think around 1968, was Richard Nixon who was making his political comeback. And he was invited to give a talk where very important people are listening. And Nixon in his memoirs, realized what was going on. He was being auditioned as to whether or not he was going to be [inaudible 00:57:19], he recognized that that was really the beginning of his second presidential campaign. He was being vetted."
            },
            {
                "speaker": "",
                "time": "(00:57:27)",
                "text": "So one of the main theories, call it a conspiracy theory or not, about the Bohemian Club and the gatherings, is that people of wealth and influence gather together and whether or not it’s part of the agenda or not, inevitably you’re going to talk about things of interest. But to me, the mere fact that you invite people in, political leaders, to give lakeside talks means that there are weaving spiders which are going on and it is a perfect private venue to vet people for political office."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:58:04)",
                "text": "Yeah, where else are you going to do it, if you are interested in vetting, if you are interesting and powerful people selecting?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:58:10)",
                "text": "Well see, here’s the question. Are these guys actually picking who’s going to be president? Is that the decision which is being made or are they just deciding what horses they’re going to back?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:58:21)",
                "text": "Right."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:58:22)",
                "text": "I think the latter is the simpler version of it, but it doesn’t mean it’s the other way around. But these are the kinds of, Nixon was, there was the whole 1960 thing. So he’s the new Nixon, remember, and this is where the new Nixon apparently made a good impression on the right people because he did indeed get the Republican nomination and he did indeed become president."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:58:49)",
                "text": "Well, there could also be a much more innocent explanation of really it’s powerful people getting together and having conversations and through that conversation, influencing each other’s view of the world and just having a legitimate discussion of policies, foreign policy."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:59:06)",
                "text": "Why wouldn’t they? Why would you assume that people are not going to do that?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:59:10)",
                "text": "It’s the owl thing with the robes."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:59:13)",
                "text": "Why the owl and why the robes?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:59:17)",
                "text": "Which is why it becomes really compelling when guys like Alex Jones, forgive me, but I have not watched his documentary, I probably should at some point, about the Bohemian Grove where he claims that there is a Satanist human sacrifice of, I think, children. And I think that’s quite a popular conspiracy theory. Or has lost popularity, it kind of transformed itself into the QAnon set of conspiracy theories. But can you speak to that conspiracy?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:59:54)",
                "text": "Let’s put it this way, the general public rich people are inherently suspicious."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:59:57)",
                "text": "Yeah. Great."
            },
            {
                "speaker": "Rick Spence",
                "time": "(00:59:58)",
                "text": "Let’s put it that way. First of all, they’ve got all that money. And exactly how did one obtain it? And I do not of necessity adhere to the view that behind every great fortune there is a great crime, but there often are. There are ways in which it’s acquired. But I think it’s one of the things I think that can happen is particularly when people acquire a huge amount of money, and I won’t name any names, but let’s say there are people who perhaps in the tech sphere who coming from no particular background of wealth, suddenly find themselves with $600 billion. Whoa. This is the question you would have to ask yourself. Why me? Because you’re one of the rare, tiny group of human beings who will ever have that kind of wealth in your hands. Even if you are a convinced atheist, I think at some point, you have to begin to suspect that the cosmic muffin, providence, whatever it is, put this money in your hands to do what? Achieve great things. Just think of all the stuff."
            },
            {
                "speaker": "",
                "time": "(01:01:08)",
                "text": "So you’re going to start a foundation and you’re going to start backing all the things that you like. I think there’s an element of ego that comes in with it as well. And again, it may not be so much what the rich person with a huge amount of money at their disposal and a lot of fuzzy ideas about what to do with it can be influenced by others. It’s always that question as to who is actually manipulating these events? What’s going on in that regard? In some way, they can be a very useful sucker. Find somebody with a lot of money and get them to finance the things that you want them to do."
            },
            {
                "speaker": "",
                "time": "(01:01:59)",
                "text": "The Bohemian Club is I don’t think in and of itself inherently evil or sinister, but it means that there are lots of different people in it who have different agendas. It goes back to what I said about how somebody feels about the cremation of care ritual. This is either just a waste of time, it’s just some sort of silly thing that we’re doing or it’s something of great importance. Perhaps even mystical or religious importance. Because that’s ostensibly what it’s pretending to be. There’s always this question as to what degree you begin to play and the play becomes serious. That tends to happen a lot."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:02:43)",
                "text": "You’ve studied a lot of cults and occultism, what do you think is the power of that mystical experience?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:02:52)",
                "text": "Well, what is broadly referred to… Well, we get into what’s occultism, what’s the occult? The occult is the hidden, that’s all it really means. Specifically, hidden from sight. And the basis of it is the idea that what is hidden, well, what is hidden from us is most of the world, most of reality. So the basic concept within occultism, the basic concept within most religions, which are approved forms of occultism, is that the world, the physical world that we are aware of is only a very small part of a much larger reality. And that what the methods and practices of occultism arguably do is to allow someone to either enter into this larger reality or to access that larger reality for purposes to be exploited here. The most interesting statement about and a key element of this becomes the thing called magic."
            },
            {
                "speaker": "",
                "time": "(01:03:58)",
                "text": "Now, we all know magic, it’s a guy standing on stage performing a trick. But the interesting thing about a stage magician is that a stage magician is we know when we’re watching it that it’s a trick, yet we can’t really figure out, if he does it well, how that trick is being accomplished because it seems to defy physical laws. And that’s fascinating about it. So even though it’s a trick, if you can’t figure it out, it has this kind of power of fascination. But it’s mimicking something. Stage magic is mimicking real magic. So what’s real magic. Well, let’s go back to Aleister Crowley because he always has to come. I knew he was going to come up at some point in this, earlier than not, because he always does."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:04:51)",
                "text": "All roads lead to Aleister."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:04:52)",
                "text": "All roads lead to Aleister Crowley. Aleister Crowley and I’ve said this enough that I should be able to get it right, but I’m paraphrasing here, he goes, ” Magick,” which of course her spelled with a K or CK, “is the art and science of causing change to occur in conformity with will?” So in a way, that’s sort of mind over matter. But it’s the idea that one can through will, through intention bend reality to make something happen. Somebody once put it this way, it’s tipping the luck plane. So you got some kind of a level plane. What we’re just trying to do is just tip it just a little bit so the marble rolls over one side or to another. Now that presupposes a lot of things, that is there a luck plane? I don’t know. But it’s a good sort of idea to have. And here again, don’t become overly bothered trying to figure out whether you actually can bend reality, become bothered by the fact that there are people who believe that they can and will go to great efforts to do so and will often believe they have succeeded."
            },
            {
                "speaker": "",
                "time": "(01:06:19)",
                "text": "So it’s this effort to make things occur in a particular way, maybe just to sort of nudge reality in one little way or another. And that’s where things like rituals come in. Rituals are a way of focusing will and intention. We’re all there. We’re all thinking about the same thing. And you have to imagine just how the pervasiveness of what could be called that kind of magical thinking every day is everywhere. So let me give you an example. You ever attended a high school football pep rally? Think of what’s going on there. Okay, your team is going to battle the other team. You’ve now assembled everyone in the gymnasium. You’ve got people who are dancing around in animal totem costumes. And what are you chanting? Everyone is supposed to chant that the other team dies, that you’ll be horribly defeated and that our team will be victorious."
            },
            {
                "speaker": "",
                "time": "(01:07:21)",
                "text": "That is a magic ritual. The idea is it becomes into this idea that’s very popular today about visualizing things, visualizing, manifesting. I love this term. You need to manifest your success. Well, that’s just magic. That is trying to cause change in conformity with will. So these things can happen without you being even consciously aware of what’s going on. And you don’t need to be because if you’re all a part of a mob, which is there in the gymnasium and you get into this and you get worked up and a cultist would argue what you’re doing is you’re creating a huge amount of energy. All of these people are putting energy into something and that energy goes somewhere. And maybe you can. Maybe, just maybe, you actually can slightly increase the chances of your team’s victory. Of course, your opponents are having their own ritual at the same time. So whoever has the bigger mojo will apparently win on the team."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:08:30)",
                "text": "So I would say trivial example of that, but a clear one. I do believe that there’s incredible power in groups of humans getting together and morphing reality. I think that’s probably one of the things that made human civilization what it is. Groups of people being able to believe a thing and bring that belief into reality."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:08:54)",
                "text": "Yes, you’re exactly right. Bring to conceive of something and then through intention, will, to manifest that into this realm."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:09:07)",
                "text": "And of course, that power of the collective mind can be leveraged by charismatic leaders to do all kinds of stuff, where you get cults that do horrible things or anything."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:09:24)",
                "text": "There might be a cult that does good things. I don’t know. It depends."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:09:27)",
                "text": "We usually don’t call those cults."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:09:27)",
                "text": "We don’t call those cults."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:09:29)",
                "text": "Exactly. A hundred percent."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:09:31)",
                "text": "Without endorsing this entirely and interesting, one of the questions, what’s the difference between a cult and a religion? And it has been said that in the case of a cult, there’s always someone at the top who knows what’s going on, generally, who knows it’s a scam. In a religion, that person is dead. So see, I’ve just managed to insult every single religion. But it’s an…"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:10:00)",
                "text": "… Insult every single… But, it’s an interesting way of thinking about it, because I think there is some degree of accuracy in that statement."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:10:11)",
                "text": "Actually, the interesting psychological question is, in cults, do you think the person at the top always knows that it’s a scam? Do you think there’s something about the human mind where you gradually begin to believe it?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:10:24)",
                "text": "Begin to believe your own bullshit?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:10:25)",
                "text": "Yeah."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:10:26)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:10:27)",
                "text": "That seems to be-"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:10:28)",
                "text": "That, again, is part of magic, I think, is believing your own bullshit. It doesn’t necessarily mean that the head of the cult realized, but there’s someone, maybe the second… I always look in the lieutenant, someone probably has an idea about what’s going on. The other thing that seems to be a dead giveaway for what we would call a cult is what’s called excessive reverence for the leader. People just believe everything these people say. To give you an example, the first time I ever encountered anything like that was in Santa Barbara, California in the 1970s. I was going to grad school. And there was a particular cult locally, I think it was Brotherhood of the Son. And, it was the same. So there was some guy who… Among the other things, followers were convinced to hand over all their money and personal belongings to him. I believe he used part of that money to buy a yacht with. Anyway. A lot of it went to him."
            },
            {
                "speaker": "",
                "time": "(01:11:40)",
                "text": "And then, of course, working for free upon different cult-owned business enterprises, of which there were several. And there was a person I knew who became a devoted follower of this, and all I could think of at one point was ask them, “What the hell is the matter with you? I mean, have you lost your mind? What is it that this person can possibly be providing that you essentially are going to become a slave to them?” Which is what they were doing. And I actually give that credit in a way of sparking my whole interest in things like secret societies. And here, again, as a disclaimer, I am not now, nor have I ever been the member of any fraternal organization, secret society, or cult that I know of. And that’s what interests me about them, because I’m just always trying to figure out why people do these things. Like I said, why the robes and the owl? Why?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:12:43)",
                "text": "… Yeah."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:12:44)",
                "text": "Why do you do that? And, it’s trying to figure it out. I mean, I couldn’t even hack the boy scouts. Okay? That was too much. Because to me, you join an organization and the first thing that comes along is there are rules and someone is telling you what to do. Okay? I don’t like people telling me what to do. Spent much of my life trying to avoid that as much as possible. And, join a cult, there’s going to be someone telling you what to do. Join the Bohemian Club, and there’s going to be someone telling you what to do. Obviously, a lot of people really get something out of that. In some ways, it’s necessary for them to function. But I do not understand it and my study of it is a personal error to try to understand why people do that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:13:33)",
                "text": "And there are so many reasons, primary of which I would say is the desire in the human heart to belong. And, the dark forms that takes throughout human history. Recent history is something I’d love to talk to you a bit about. If we can go back to the beginning of the 20th century on the German side, you’ve described how secret societies like The Thule Society lay the foundation for Nazi ideology. Can you, through that lens, from that perspective, describe the rise of the Nazi party?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:14:10)",
                "text": "Well, I guess we could start with what on earth is The Thule Society? So The Thule Society was a small German occult society. That is, they studied metaphysics, another fancy word for occultism, that appeared in Munich around 1917, 1918. The key figure behind it was a German esotericist by the name of Rudolf von Sebottendorff. Okay, not his real name. His real name was Adam Rudolf Glauer. He was adopted by a German nobleman and got the name von Sebottendorff, and I like to say that name."
            },
            {
                "speaker": "",
                "time": "(01:15:02)",
                "text": "So, I have this real thing about vague, mysterious characters who show up and do things, and trying to figure out who these people are. So we’re working up the years prior to the first World War. So, the decade or so prior to World War I, he spends a lot of time in the Ottoman Empire, Turkey. There was none in the Ottoman Empire, which was a fairly tumultuous place, because in 1908 and 1909, there was the Young Turk Revolution. And, you had a military coup, which effectively overthrew the Ottoman Sultan and installed a military junta, which would go on during the first World War to make its greatest achievement in the Armenian Genocide. Eventually, it created a genocidal military regime which would lead the country into a disastrous first world war, which would destroy the Ottoman Empire, out of which modern Turkey emerges. Yada, yada, yada."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:16:06)",
                "text": "And by the way, we should take a tiny tangent here, which is, that you refer to the intelligence agencies as being exceptionally successful. And, here in the case of the Young Turks being also very successful in doing the genocide, meaning they’ve achieved the greatest impact, even though the impact on the scale of good to evil tends towards evil."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:16:33)",
                "text": "It’s one of those things that often comes out of revolutionary situations. Revolutions always seek to make things better. Don’t they? “We’re going to take a bad old regime. The Sultan is…” And the Sultan was bad, I think it’s fair to say. Abdul Hamid II wasn’t called a red sultan because of his favorite color type of thing. And, the idea is that they were going to improve. The Ottoman Empire was a multinational empire. They were going to try to equalize and bring in the different groups. And, none of that happened. It became worse, in the same way that you could argue that the goal of Russian revolutionaries was to get rid of the bad old, incompetent, medieval Tsarist regime and to bring in a new great shining future. And it became even more authoritarian. And, the crimes of the Imperial Russian regime pale in significance of what would follow, in the same way that the crimes of Abdul Hamid pale when you get to the Young Turks."
            },
            {
                "speaker": "",
                "time": "(01:17:44)",
                "text": "But, that wasn’t necessarily the intention. But, von Sebottendorff is a German businessman who’s working in this period. And the whole point here is that the Ottoman Empire in this period is a hotbed of political intrigue and all kinds of interesting things about it. The Young Turk Revolution is essentially a military coup, but it is plotted in Masonic lodges. Okay? I know, technically Masonic lodges are never supposed to be involved in politics, but they are. Or, the lodge meeting breaks up, and then you plot the revolution. So, same group of people, but it’s not technically. But yes. And there’s the Macedonia Resorcia Lodge in Thessaloniki was ground zero for plotting this military coup that was supposed to improve the Empire. Sebottendorff is, in one way or another, mixed up in all of this, or at least he’s an observer. Plus, he’s initiated into the Masonic lodges."
            },
            {
                "speaker": "",
                "time": "(01:18:53)",
                "text": "And interestingly enough, the fellow initiates him into one of these eastern lodges is a Jewish merchant by the name of Termoodi, and who’s also a Kabbalist. And, Sebottendorff is very, very interested in the occult. He’s initiated into eastern Masonic lodges and a period when those same lodges are being used as a center for political intrigue. He also apparently is involved in gunrunning, which in revolutionary periods is there’s a lot of money to be made off of that. So he’s connected to various dark businesses in a tumultuous time with connections to politicized freemasonry and the occult. Now, in the course of the first World War, he returns to Germany. He just shows up. And, it would be my operative suspicion or theory that Sebottendorff was working for someone. I don’t think he just pops up in Munich on his own accord. Why does he leave the Ottoman Empire and return to that place? Who’s behind him? Now, maybe no one, but maybe someone, because he does seem to have money at his disposal. And he comes into Munich and he basically takes over this small occult study group."
            },
            {
                "speaker": "",
                "time": "(01:20:32)",
                "text": "Now, the interesting thing is that The Thule Society is really just a branch of another existing, what’s called, an Areosophist order, a thing called the German order, or the Germanic order, which is centered in Berlin. But for some reason, he doesn’t want his group to be connected by name with the Germanic order. So, Thule Society, Thule in this case, is a reference to supposedly a mythical Arctic homeland of the Aryan race. Apparently, they were all snow people who wander out of the snow at some point. It’s a frozen Atlantis. So I mentioned these people, the Areosophists, which, you have to practice saying that. So, what are they? Well, they’re a racist Germanic offshoot of Theosophy. And, I know I’m explaining one thing to explain something, but there’s no other way to do this."
            },
            {
                "speaker": "",
                "time": "(01:21:39)",
                "text": "So, Theosophy was 19th century very popular and widely modeled occult belief that was founded by a Russian woman by the name of Helena Blavatsky. She was a medium psychic, supposedly got channelings from the ascended masters. The basic story there, they’re all of the ascended masters, which are mystical beings that may or may not have once been human. They live inside the Himalayas or they float among them on a cloud, and they guide the spiritual evolution of humanity. What Blavatsky did was to take Western esotericism and blend it with Hindu and Buddhist esotericism, which became very, very sexy in the West, still is. Buddhism attracts a lot of people, because, well, it’s Buddhism, it’s different, see? So, the Mahatmas, the ascended masters were sending her messages, despite the fact that she was later proven pretty much to be a fraud and writing the letters herself. Nevertheless, people still went along with this doctrine, and it’s been widely modified and copied since then. So, an idea in Theosophy was that human spiritual evolution was tied to physical evolution."
            },
            {
                "speaker": "",
                "time": "(01:22:58)",
                "text": "In the case of Blavatsky, Blavatsky never said that Aryans, white people, anything out this superior. She talked about the different root races, but their version of it’s just gobbledygook that seems to include everyone in. I’d defy you to make much sense out of it. But, in the early 20th century, there were different… One of the things that became fashionable, not terribly popular, these are small movements, was the idea that, well, Germany is a new upcoming country, and part of this I think was really trying to define who the Germans were, because remember, the German Empire, Germany as a political state, doesn’t come until existence until 1871. Prior to that, Germany was a geographic expression, a vaguen, which described a large area in Central Europe where a lot of people who wore leather shorts or something like that and spoke similar German dialects were nominally Germans, but they might be Prussians or Bavarians. They came in all sorts of varieties in religion. There was no German identity."
            },
            {
                "speaker": "",
                "time": "(01:24:19)",
                "text": "Something very similar happened in Italy in this same period. I mean, there weren’t Italians, there were Sardinians, and there were Romans, and there were Sicilians. Umbrians spoke, again, dialects of a similar language, but had never lived, not since the Roman Empire under a single state and really didn’t think of themselves as the same. So you have to create this artificial thing. You have to create Germans. “There is now a Germany with an emperor. And so, we’re all going to be Germans.” Well, exactly what is that? Much of it is an artificial creation. You have to decide upon some standard dialect. Okay, we’ll decide what that is. Often dialect that only a few people actually speak, and then they will be drilled into children’s heads through state schooling programs. So I think this is the milieu that it comes out of. People were trying to figure out what on earth Germans actually were. And, the need for some common identity. And, that leads to everything like Wagnerian Opera. Richard Wagner wanted to create a German mythical music. So he went back and strip mined old German myths and cobbled them together into a lot of people standing on stage singing. And, that was his purpose. He was a nationalist. He was in many ways a racialist nationalist. And this was his idea of trying to create out of bits and pieces of the past, a newfangled form of German identity."
            },
            {
                "speaker": "",
                "time": "(01:25:57)",
                "text": "So, on the more mystical end of this, you had the ideas that, well, Germany must have been created for some special purpose, because the Germans must be very special people and we must have some particular destiny. And then, out of this, the direction this is heading, well, we’re all part of some master race with some ties to some great civilization in the past, call it Thule, call it whatever you want to be. They basically just invent things and try to attach those to the past. And so, Areosophy was the Areonized version of Theosophy. And what this did was to take the idea that spiritual and physical evolution had led to the most advanced form of human beings, which were the Aryans, and the most advanced group of them were, of course, the Germans. And, this attracted appeal."
            },
            {
                "speaker": "",
                "time": "(01:26:56)",
                "text": "Keep in mind, again, this was not a mass movement. This was very much a fringe movement. Most people weren’t aware of it and weren’t particularly interested in it, but it had an appeal for those who already had a esoteric bent in some form or another. And, this is where things like the Germanin order or the German order and their other groups, it was only one of many, grew out of. And, what it was that the Thule Society as a branch, The Thule Gesellschaft was supposed to do, was to study this. It was an esoteric study group. And so, people would get together and they’d talk about things, probably make more stuff up and all work around this idea of German Aryans as the most advanced human beings, and all the wonderful things that the future would hold."
            },
            {
                "speaker": "",
                "time": "(01:27:52)",
                "text": "And the fact that this was in the midst of a war in which Germany was, again, fighting, as they saw it, for its existence, heightened those tensions as well. So, my suspicion, again, is that Sebottendorff, in terms of who was behind him, that he was essentially called back to Germany to work either for the Prussian political police or for some aspect of German intelligence or security to try to mobilize occultism or esotericism for the war effort, because again, this is 1918, the war, it’s gone on way too long. Within a few months, Germany will collapse, and it will collapse simply from the psychological exhaustion of the population."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:28:48)",
                "text": "So this is almost to help the war effort with a propaganda, a narrative that can strengthen the will of the German people."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:28:58)",
                "text": "Well, strengthen the will of some people."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:28:58)",
                "text": "Some people."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:28:59)",
                "text": "You have to try to appeal to different aspects of this. But the mystical aspect is one of those things, it can have a very powerful influence. And the idea is that if we can come up with some mystical nationalism, maybe that’s one way to put it, a mystical nationalism that can be exploited for the… Because at this point you, you’re grasping at straws, and this is a whole period when the Germans are marshalling the last of their forces to launch a series of offensives on the Western front, the Peace Offensive, which will initially be successful, but will ultimately fail, and lead to a collapse in morale. But among the leadership of Germany, it was a recognition. It was that national morale was flagging. And, one of the other things that was raising its head was what had happened nearby a year… Well, the Russian Revolution, which had now brought the idea, which brought another solution to all of this, the idea of revolutionary Marxism. Here, we need to remind ourselves as to where Marxism comes from, not Russia, Germany. Where was the largest Marxist party? In Germany."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:17)",
                "text": "And Marx probably expected the revolution to begin in Germany."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:30:23)",
                "text": "Where else?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:24)",
                "text": "I mean, the Soviet Union is not very industrialized. Germany is. And so, that’s where it would probably be."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:30:29)",
                "text": "Russia, 5% of the population is industrial workers. In Germany, 40% of the population is industrial. So, if any place was made for Marxism, it was Germany. I think that’s why it caught on in East Germany so well, because it had come home. And, it was a local belief. It wasn’t something imported by the Russians. It was a German invention. One of the things you can see in this is The Thule Society was particularly involved in a anti-Marxist or anti-Bolshevik agitation. Sebottendorff saw them as this whole movement. It was a counter to this. It was a counter-Marxist movement."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:31:19)",
                "text": "Can we try to break that apart in a nuanced way? So, it was a nationalist movement. The occult was part of the picture, occult racial theories. So, there’s a racial component, like the Aryan race, so it’s not just the nation of Germany. And you take that and contrast it with Marxism. Did they also formulate that in racial terms? Do they formulate that in national versus global terms? How do they see this?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:31:51)",
                "text": "Marxism formulates everything by class. Okay? People are categorized by class. You’re either part of the proletariat or you’re part of the bourgeoisie, or you’re either part of the proletariat or just some scum. Really, it needs to be swept into the dustbin of history. Only workers count. And, that was what would take someone who was a nationalist would drive them crazy, because their idea is, “We’re trying to create a German. People. We’re trying to create a common German identity.” But what the Marxists are doing is they’re dividing Germans against each other by class. German workers hate the German bourgeoisie. German proletariat as opposed to German capitalists. We’re all trying to fight this war together."
            },
            {
                "speaker": "",
                "time": "(01:32:38)",
                "text": "So, that was why Marxism, particularly in the form of Bolsheism, was seen as unpatriotic. And of course, was opposed to the war as a whole, the idea that parroting Lenin was that the war was an imperialist war. And the only thing that was good that was going to come out of it is that the imperialist war, through all of the crises it was creating, would eventually lead to a class war. And that would be good, because that would reconcile all of these things. But, think of the two very different versions of this, the Bolshevist version, or let’s just call it, the Marxist version of Germany, was going to be a class society in which we’re going to have to have some civil upheaval, which will have Germans fighting Germans."
            },
            {
                "speaker": "",
                "time": "(01:33:27)",
                "text": "Whereas, the mystical nationalism, the almost religious nationalism that Sebottendorff from The Thule Society had hitched its wagon to held that Germans are all part of a single racial family, and that’s what must be the most important thing. And that these can be different ways of trying to influence people. It comes down to a matter of political influence. So in a sense, I think that what Sebottendorff and The Thule Society was trying to do, at least within Munich, was to use this idea of mystical nationalism as a potential rallying point for some part of the population to oppose these other forces to keep people fighting. The war is lost though in November, the Kaiser abdicates, and essentially, the socialists do take over Germany. Things come very, very close to following the Russian model. And, you even get the Russian version or take on the Bolsheviks, which are the Spartacists who try and fail to seize power early on. But you do essentially end up with a socialist Germany."
            },
            {
                "speaker": "",
                "time": "(01:34:49)",
                "text": "And, that then leaves in the aftermath of the war. The Thule Society is sort of the odd man out, although they’re still very closely connected to the army. And here’s one of the things that I find interesting. When you get into 1919, who is it that’s paying Sebottendorff’s bills? It’s the army. The one thing the German army is absolutely determined to do is to preserve its social position and power. And they’re perfectly willing to dump the Kaiser to do that. This deal, which is made in November of 1918, Kaiser’s abdication, the proclamation of a German Republic, which, you just had this guy declare it. It wasn’t really planned. There’s the Ebert-Groner Pact. Groner is the chief of general staff at this point. Ebert is the chief socialist politician basically, and they make an agreement. And the agreement basically is that the Army will support Ebert’s government if Ebert supports the Army. And particularly that means the continuation of the Officer Corps and the general staff in one form or another. So a deal is made. And that of course, is what will eventually help defeat the Spartacist uprising."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:36:21)",
                "text": "Now, was the Army doing the similar things that we’ve talked about with the intelligence agencies, this same trying to control the direction of public power?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:36:32)",
                "text": "The German intelligence landscape in the first World War is obscure in many ways. There are lots of things that are going on. Germany has a military intelligence service called Abteilung or Section IIIB. That’s just plain military intelligence. They’re constantly trying to collect military information before the war about the weaponry and plans of the enemies. And then, about what the operational plans were during the war. It doesn’t really go much beyond that though. The German foreign office runs a political intelligence service, and that’s the one which is much more involved in things like subsidizing subversion in Russia, which is one of the things that the Germans sign on to fairly early. Little diversion here in 1915, there is a Russian revolutionary who’s lived much of his life in Germany, who goes by the code name of Parvis. And, he essentially comes to the Germans in Constantinople, interestingly enough, in Turkey, he’s hanging around there at the same time as Sebottendorff is there, which I find curious."
            },
            {
                "speaker": "",
                "time": "(01:37:55)",
                "text": "So, Parvis or Alexander Helpant to give his actual name, comes to them and he goes, “Look, there’s a lot of revolutionaries in Russia and there’s a lot of mistrust with the regime. We think that the war will increase the contradictions in Russian society. And, if you give me a lot of marks, I can finance this revolutionary activity. And through subversion, I can take Russia out of the war.” Well, the Germans are facing a two-front war. That sounds great. “We’ll use money in order to…” But notice what they’re doing. The German general staff, a very conservative organization, not a bunch of revolutionaries, are going to finance revolution in an opposing country. They’re going to finance revolutionary subversion to take Russia out of the war, which basically works. So that gives you another idea as to what the German military is willing to do. They’re not revolutionaries, but they’ll pay revolutionaries to subvert another regime. Now, you’ve got the problem, is that, the revolutionary regime that your money helped bring to power is now threatening to extend into your country."
            },
            {
                "speaker": "",
                "time": "(01:39:19)",
                "text": "So, the whole question for the Army and for others in Germany in 1919 is how to keep Germany from going Bolshevik from, in a sense, being hoist by your own petard. So The Thule Society, I don’t think is a huge part of this program, but it is a part of it, and it’s all an effort to try to keep control. And that’s why the army is financing them. That’s even why the Army at some point then supplies them with its own propagandists. So, The Thule Society begins to create under Sebottendorff leadership, what he called, the Rings of Thule. And these are satellite organizations that aren’t the society as though, but they’re controlled and inspired by it. And one of those is a thing called the German Workers Party."
            },
            {
                "speaker": "",
                "time": "(01:40:14)",
                "text": "And the German Workers Party, again, is local. It’s not large, it’s not terribly influential, but what does it aspire to be? It aspires to be a party that will bring German workers away from the seductive influence of the Bolsheviks and into a more patriotic position. And, the way that I describe this is that it’s not an anti-communist organization, it’s a counter-communist organization. So you don’t create something which completely opposes it, you create something which mimics it, which is ultimately what the German Workers Party will become, is the National Socialist German Workers Party, known as that term, socialist. And that is, in my view, what Nazism is from the beginning. It is a counter-communist movement."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:41:13)",
                "text": "And by the way, for people who don’t know, the National Socialist German Workers Party is also known as the Nazi Party. So how did this evolution happen from that complicated little interplay? We should also say that a guy named Adolf Hitler is in the army at this time."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:41:33)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:41:34)",
                "text": "Man."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:41:35)",
                "text": "Well, he’s going to come into this, because remember, I said the Army was going to supply its own propagandists to help the German Workers Party and The Thule Society do their work. And the propagandists they supply them with is a man who the Army trains, sends to classes to learn the art of public speaking and propaganda. And that fellow is Corporal Adolf Hitler."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:42:01)",
                "text": "So how does Adolf Hitler connect with the German Workers Party?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:42:06)",
                "text": "Well, he’d been in the Army during the war. The only regular job that he’d ever had, liked it. So you often get the view is that, well, at the end of the war, he joined millions of other German soldiers who didn’t have… No, no, he stays in the army. He stays in the Army until 1921. He’s on the Army payroll at the very time in which he has helped them to set this up. What appears to have happened is this, Sebottendorff had organized The Thule Society, they had tried to oppose. There’s actually a brief period of time in which the communists actually take over Munich, the Bavarian Soviet Republic, which doesn’t last very long. And eventually, the Army volunteers to put this down. While that’s going on by the way, Hitler is actually sitting in the barracks in Munich wearing a red armband, because he is technically part of the soldiers who have got over to the Bavarian Soviet Republic."
            },
            {
                "speaker": "",
                "time": "(01:43:09)",
                "text": "He seems to have had flexible interests in this case. So, once order is restored, so to speak, the army comes in and decide that, “Well, one of the things we need? We need to have people who can lecture soldiers on patriotic topics.” And so, there is a particular captain by the name of Karl Mayer who spots Hitler. He later describes him as a stray dog looking for a master. Hitler has a knack for public speaking. Other soldiers will listen to him. Some people can do that, some people can’t. Mayer decides that he’s a good candidate for further training. And so, yes, they bring him in. They turn him into a, what’s called, a [foreign language 01:43:56], a liaison man. He’s an army propagandist."
            },
            {
                "speaker": "",
                "time": "(01:44:03)",
                "text": "And then, you’ve got this little outfit called the German Workers Party. And essentially what happens is that Hitler is sent in to take over leadership of that, which is what happens. He shows up, he attends a meeting, there are 50 people there. By the way, the topic of the first meeting he’s at, is how and why capitalism should be abolished, which is not what you might, well, expect. Because remember, the German Workers Party is trying to cast itself as a counter Bolshevism. So it’s not saying that capitalism is great, which is important. No, capitalism is evil. We agree upon that. We just agree it has to be destroyed from a nationalist point of view, as opposed from some strange internationalist point of view. So Hitler is essentially, as I see it, sent in by the Army as their trained man to assume leadership within this small party and to use it-"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:45:00)",
                "text": "To assume leadership within this small party and to use it for the army’s patriotic propaganda campaign. And is a season doing so even to the name change, to the National Socialist or German Workers Party. I mean, really what sounds more red than that?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:45:21)",
                "text": "So the interesting thing here is from where did anti-Semitism seep into this whole thing? It seems like the way they try to formulate counter-Marxism is by saying the problem with capitalism and the problem with Marxism is that it’s really Judeo-capitalism and, “Judeo-Bolshevism”. From where did that ideology seep in?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:45:50)",
                "text": "Well, that’s a huge topic. Where does anti-Semitism come from? Let’s start with that term itself. A term which I have really grown increasingly to dislike because it doesn’t actually say what it means. Anti-Semitism is anti-Jewism. That’s all it is. I’m not sure whether there has ever existed a person who hated Jews, Arabs, and Maltese equally. Okay. That’s kind of hard to imagine. I don’t know. But that’s technically what that would mean because let’s face it, most Semites are Arabs. So if you’re an anti-Semite, then you don’t seem to distinguish Jews from Arabs. It makes no sense. The origin of the term is invented by, guess what? An anti-Semite. Okay. A guy in the 1870s, a German journalist by the name of Wilhelm Marr, who is, wouldn’t you know it part Jewish himself. And who decides that you really needed a better term than Judenhass, Jew hate, which was the term that, because that just sounds so inelegant, doesn’t it?"
            },
            {
                "speaker": "",
                "time": "(01:47:05)",
                "text": "Okay. What do you want to call yourself a Jew-hater or an anti-Semite? See, anti-Semitism, it’s got that ism part of the end of it, which means it’s a system of belief. Anything that has an ism must somehow be scientific and important. It’s all part of the 19th century obsession with trying to bring science into something, one or the other. So we’re going to get rid of Jew-hate, and we’re going to turn it into anti-Semitism. And we’re only going to be talking about Jews, but we’ll never actually say that. And somehow the invention of a Jew-hater to disguise the fact that he’s a Jew-hater, even though he’s partly Jewish by inventing the term anti-Semitism worked because everybody has bought it and repeated it ever since. So I don’t know, maybe just because anti-Jewism would just be, is it too direct in some way? Do we have difficulty confronting actually what it is that we’re talking about?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:48:03)",
                "text": "I do wish terms were a little bit more direct and self-explanatory. Yeah, Jew-hate is a better term."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:48:09)",
                "text": "Well, the question then comes, what exactly do you hate about Jews? And a lot of this has to do with, if you go back prior to the 19th century, if Jews were hated, they were hated for religious reasons. In Christian Europe, they were hated because they weren’t Christians and they existed as the only kind of significant religious minority. But other than that, they tended to live separately. They had little economic influence. Jews tended to live in shtetls in the East, ghettos elsewhere. They were, some were involved in banking and business, but they sort of remained segregated from much of society."
            },
            {
                "speaker": "",
                "time": "(01:48:55)",
                "text": "That changes when you get to the 19th century and with what’s called Jewish emancipation. And that means that between about 1800 and 1850, most European countries drop the various legal or social restrictions against Jews. They are assimilated into the general society. So ideally, you stop being a German Jew and you become a Jewish German. Those are two very different important concepts. And what that does, of course, is that it opens up the professions, business world, elsewhere. So Jews move who had been largely within those realms to begin with, they already had a good deal of experience in banking business, and they move into those areas and professions and become quite visible."
            },
            {
                "speaker": "",
                "time": "(01:49:48)",
                "text": "And that’s what then creates anti-Semitism because in some way that is seen as part of the changes that have taken place. And there are a lot of things going on here. Part of it has to do with the kind of wrenching social and economic changes that took place with industrialization. So one of the things to keep in mind is that in the process of industrialization, just like today, whole classes of people were made extinct economically, craftsmen, for instance. So when factories came along and began to produce things with machines, all the craftspeople who had made those things previously are now unemployed or go to work as wage labor in factories. So there are winners and losers in industrialization. And what people saw in Germany and elsewhere is that among this new sort of rising capitalist elite among these new professions, among the bureaucrats that are coming out of these burgeoning states, they were visibly a fair number of Jews."
            },
            {
                "speaker": "",
                "time": "(01:51:05)",
                "text": "So in some way, the rise of Jews in the minds of many people were connected to all of the other bad things that were going on. The world was changing in a way we don’t like. And seemingly the Jews are prospering while I am not, and that was true in Germany and elsewhere, Jews because highly visible in the professions, they became very visible in banking. They became visible in legal profession. They became visible in the medical profession. And those are people that a lot of people would come in contact with, bankers, lawyers, and doctors. They were not the majority there, but vastly overrepresented in terms of the general population and especially within the cities. So in that sense, the roots of anti-Semitism to me is that Jews in Germany and Elsewhere and not just in Germany by any means, France, Britain, everywhere else became identified with the bad changes that were taking place."
            },
            {
                "speaker": "",
                "time": "(01:52:10)",
                "text": "But you also found that Jews were not only prominent among capitalists, they were also prominent in the socialist movement as well. So one of the things you could look around if we returned to Germany in 1919 in the aftermath of World War I, and you look around in Bavaria or elsewhere, you tend to find that there are a lot of Jews in visible positions on the German left. Rosa Luxemburg is but one example of that, Eugen Levine, some of them came in from Russia. When the Soviets send a representative to Germany in this period, it’s Karl Radek, a Jew. So it wasn’t difficult to exploit that, to argue that just as the ranks of capitalism was full of Jews, the ranks of Bolshevism or of the revolutionary left, were full of Jews. Because you could easily go around and distinguish a great many of them."
            },
            {
                "speaker": "",
                "time": "(01:53:16)",
                "text": "Again, they don’t have to be the majority, they just have to be numerous, prominent, and visible, which they were. So this provided you a, in the case of the propaganda of the German army, the type of stuff that Hitler was spewed out. They could put all the anti-capitalist rhetoric in there, wanted to. The army was never going to overthrow capitalism, and the capitalists knew they weren’t going to do it. So go ahead, talk shit about us. We don’t really care. That’s not going to, because we know that the army would prevent that from happening. The way to then undermine the real enemy, it was a scene. The revolutionary left was to point out the Jewish influence there. I mean, look at Russia. Well, Lenin is up, Trotsky, there he is. Look, there’s a Jew. There’s one. Radek is a Jew. It wasn’t hard to find them in that regard."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:54:11)",
                "text": "You gave a lecture on the Protocols of the Elders of Zion. It’s widely considered to be the most influential work of anti-Semitism ever perhaps. Can you describe this text?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:54:25)",
                "text": "Well, the Protocols of the Learned Elders of Zion is probably one of the most troublesome and destructive works of literature that has ever emerged. And yet its origins remain obscure. So you get a whole variety of stories about where it came from. So the one story that is often is that it was the work of the Okhrana, the Russian Secret police. And in particular, it was all crafted in 1904 and 1905 in Paris. There’s a whole description of Pyotr Rachkovsky who was the, supposedly the chief of the Okhrana at the time, was the man behind it, another fellow by the name of Matvei Golovinski was the drafter of it. And that they had this document written by a French political writer from some decades back called Dialogue in Hell Between Machiavelli and Montesquieu, which they were then adapting. Usually it’s argued that they plagiarized it into the protocols."
            },
            {
                "speaker": "",
                "time": "(01:55:46)",
                "text": "And none of that is really true. I mean, the first part about it is that at the time this supposedly took place, Rachkovsky wasn’t working for the Okhrana, he had been fired and he wasn’t in Paris. And the whole situation, which is described couldn’t have taken place because the people who did it weren’t there. It’s a story, but it provides a kind of explanation for it. So the protocols emerge, so you always have to go back. This is one of the things that I have found always useful in research, is go back to the beginning, find the first place this is mentioned, or the first version, or the first iteration. Where does it start?"
            },
            {
                "speaker": "",
                "time": "(01:56:37)",
                "text": "So you go back to Saint Petersburg, Russia around 1903. There is a small right wing anti-Semitic newspaper published there called Znamya, banner. And it publishes in a kind of serial form a work doesn’t credit with any original author. And this is the first version of the Protocols of the Learned Elders of Zion. But what it’s actually describing is a Judeo-Masonic plot to rule the world. Those two terms are always combined together. And I think in the earlier version, there’s far more mentions of Freemasons than there are Jews."
            },
            {
                "speaker": "",
                "time": "(01:57:26)",
                "text": "And the publisher of Znamya is closely connected to a thing called the Union of Russian People. The Union Russian Men, which was ostensibly existed to defend the empire against subversion and particularly against what it thought was Jewish subversion when they also argued that the prominence of Jews in revolutionary movements somehow proved that this was in some way a Jewish revolution. But again, this is not a mainstream newspaper. It’s not appealing to a mainstream population. Very few people saw it, but this is where it appears. Now keep in mind that’s two or three years before it’s usually said to have been written, or the other version is that there’s this crazy priest by the name of Sergei Nilus, and he wrote it or actually appended it as an appendix to his work in 1905. Now it was around before that. So Nilus didn’t create it. It wasn’t drafted in Paris in 1904 and 1905. It was serialized in an obscure right wing Russian newspaper, 1903."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:58:34)",
                "text": "And by the way, we should say that these are 24 protocols."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:58:41)",
                "text": "Well, it varies."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:58:42)",
                "text": "It varies."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:58:43)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:58:44)",
                "text": "That are, I guess supposed to be meeting notes about the supposed cabal where the Jews and Freemasons are planning together a world domination. But it’s like meeting notes, right?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:58:59)",
                "text": "Protocol, which are Russian term basically for notes of a meeting."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:59:04)",
                "text": "Yeah."
            },
            {
                "speaker": "Rick Spence",
                "time": "(01:59:05)",
                "text": "Well, it’s notes of a meeting. These are the goofiest things I’ve ever seen because what you’ve got here, it’s not notes. No one takes notes from a meeting that way. What you’ve got is the exposition of a Bond villain. All right. It’s all of this, boy, all them, we’re going to do this. And then the last thing you want to do is lay out, if you’ve got a plan for world domination, my suggestion would be don’t write it down. So it’s not notes of a meeting. It’s again, it’s another sort of narrative or story that’s being told. It bears no resemblance to the Dialogue in Hell Between Machiavelli and Montesquieu. But what it is, the best thing, it’s not particularly readable in some ways. There was an Italian writer by the name of Cesare Michelis, who wrote a book translated in English called The Non-Existent Manuscript. And what it is, is that he takes the different versions starting with the 1902, 1903 versions and looks through the other ones, and he tries to, in the process, to reconstruct what he thinks the original might have been."
            },
            {
                "speaker": "",
                "time": "(02:00:20)",
                "text": "But the other thing he does, which was fascinating to me, is that he takes this whole sort of initial text and in bold type he indicates the paragraphs, but more often sentences or phrases that appear to be identical from the Joly work and they’re just scattered throughout it. There’s no particular rhyme or reason to it. You don’t plagiarize that way. I mean, who does that? It’s sentence here, sentence there, which has led to a peculiar theory of mine, which of course I will have to expound upon, which is that I think that the original author of the protocols was the same Maurice Joly. I think what someone stumbled across was a work which he wrote and never published, and which he just drew. It’s exactly what someone would do working from your own kind of material, because I’ve written things and then taken what I’ve written and then sort of repackaged that into something else."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:01:31)",
                "text": "Sentence here, sentence there."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:01:32)",
                "text": "Yeah. And the same sort of thing comes out, only sort of bits and pieces of it remain. So why would Joly have done that? Joly was, we’re talking about a man whose career basically spanned the 1850s to 1870s. He’s an obscure figure. I’m not even totally sure he existed, I mean, but it’s one of those things you go looking for him."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:01:58)",
                "text": "I love that you’re a scholar of people that just kind of emerge out of the darkness."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:02:03)",
                "text": "They just come from nowhere."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:02:05)",
                "text": "Yeah. And there’s the Okhrana there also. And we should also say this was, I guess the original would be written. I mean, what’s the language of the original? Russian?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:02:12)",
                "text": "Russian. But my hunch is that that’s adopted from a French version. First of all, they’re constantly harping on Freemasons, which wasn’t nearly as a big idea as there. If you go back to France in the 1890s, there’s some big scandals. Well, there’s the Dreyfus scandal. We got that. All right. Where you’ve got a Jewish officer on trial for being a traitor. All right. So that was [inaudible 02:02:34]. So you bring in the whole Jewish element. Jews is disloyal Dreyfus case 1894. Earlier you had the Panama scandal, which was this huge investment scandal when the Panama Canal company in Paris collapsed. And again many of the major players in that were Jewish financiers. And then you’ve got the Taxil hoax."
            },
            {
                "speaker": "",
                "time": "(02:02:59)",
                "text": "So the Taxil hoax was the work of this guy. His real name was I think Jogand-Pages. He was kind of a French journalist. I don’t know. He started out writing porn. So I mean, he wrote things like Sex Lives of the Popes and the Erotic Bible and various things of that kind. He was a Catholic, broke with the Catholic Church, wrote bad stuff about the Popes, and apparently became a Freemason for a while, and then supposedly recanted his evil ways, went back to the church. And then under the name Leo Taxil began writing these whole series of articles, basically arguing that there was a Masonic-Satanic conspiracy run, by the way, by an American, Albert Pike. And this also included child sacrifice. It’s got Pizzagate and it is as well by a high priestess Diana Vaughan."
            },
            {
                "speaker": "",
                "time": "(02:03:56)",
                "text": "And so there’s like child sacrifice, weird Robie, Bohemian Grove stuff, and the Freemasons or devil worshipers going back to the Knights Templars. And so there’s a thing called the Devil in the 19th Century and the Secrets of Freemasonry, and this became a bestseller in France. So France is just obsessed with all these kinds of conspiracies. So evil, Satanic, Freemasons, evil, Jewish financiers, Dreyfus. This, this is the brew where all of this come. So want to figure out how Freemasons and Jews get connected together? France is the place where this happens."
            },
            {
                "speaker": "",
                "time": "(02:04:36)",
                "text": "Now, Taxil or Jogand-Pages eventually pulls another interesting thing in this around 1897, critics argue that he’s making this stuff up and demand that he present Diana Vaughan, suppose Satanic, high priestess toddler killer. And he says, oh, we’re going to have a press conference. She’ll appear and say all of this stuff as she returns to the church and possibly becomes a nun. And so people show up, high figures in the Catholic Church shows up, and he does. No Diana Vaughan and Jogand-Pages goes, it’s all a hoax. I made it up. You’re all a bunch of idiots for believing it. Okay. You, you members of the church, especially just what gullible morons you are, and that’s it. He confesses."
            },
            {
                "speaker": "",
                "time": "(02:05:21)",
                "text": "To this day however, you will find people who will insist that it’s actually true because they desperately want it to be true. But this is, I think the milieu that, I like that word apparently that this comes out of, and this is this whole kind of unhealthy mix. So France to me is the only place that in the decade preceding it, that something like this would be concocted. So it was either created by some sort of unknown person there. But I still think that even though he dies in like 1879, that in Maurice Joly’s troubled career, he went from being an opponent of French Emperor, Napoleon III, which is what the whole dialogues was written against."
            },
            {
                "speaker": "",
                "time": "(02:06:17)",
                "text": "And then he was for a time, a close political ally of a French politician by the name of Adolphe Cremieux. So Adolphe Cremieux, well, what’s he got going for him? Well, he was kind of a radical politician. He was an opponent of Napoleon III. He was a Freemason. Oh, and he was Jewish. In fact, at one point, I think he was actually the head, both of the Scottish right in France, and an important figure in the Alliance Israélite, the Jewish organization in France. So he was publicly very prominently Jewish and Masonic. So someone else who would’ve linked them together."
            },
            {
                "speaker": "",
                "time": "(02:07:06)",
                "text": "Joly, as he did with virtually everyone, this was a guy whose life largely consisted of dual threats and fistfights. So he gets angry at Cremieux, and it’s exactly the type of thing that he might write to vent his spleen about it. But he died, probably a suicide, that’s kind of difficult to tell in obscurity. His son seems to have inherited most of his literary works, and his son became a journalist, worked for newspapers in France in the 1890s, but was also associated with some people on the fringes of the Okhrana or the Russian press in France. So one of the little things that had happened by this time is that France and Russia had become allies, even though their political systems were completely incompatible."
            },
            {
                "speaker": "",
                "time": "(02:08:16)",
                "text": "And so the Russians were using money to subsidize French newspapers that were championing the alliance between the two. Russian meddling. Okay. Now they’re just paying to have the right kind of newspapers come out. So there’s this whole connection between the kind of Russian journalistic world and the French journalistic world and all of these scandals which are going on, and Joly’s son and then 10 years down the road, this thing pops up in a newspaper in Saint Petersburg. That’s where I think the origins lay."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:08:57)",
                "text": "Why do you think it took off? Why do you think it grabbed a large number of people’s imaginations and even after it was shown to be not actually what it’s supposed to be, people still believe it’s real?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:09:14)",
                "text": "Well, it doesn’t take off immediately. Okay. Never receives any kind of wide, I mean, nobody much reads the first edition of it. It keeps getting, there is something like 18 or 19 different versions as it goes through. I mean, people leave this protocol out or leave another one. As time goes on, there’s more and more emphasis on Jews and less and less on Freemasons. So it’s sort of, and the whole thing could have begun as an anti-Masonic tract."
            },
            {
                "speaker": "",
                "time": "(02:09:46)",
                "text": "I mean, you could leave Jews out of it entirely and just turn it into a Masonic plot to rule the world, but let’s just throw them in as well since the two things are already being combined elsewhere. It doesn’t become a big deal until really after the first World War because the initial versions of it are all in Russian. And let’s face it, well, that’s widely read in Russia. It’s not much read anywhere else. It’s a different alphabet. Nobody can even see what it means. So it has no particular influence outside of Russia. But then you get to 1919 and you get all these different versions of it. So suddenly you get two English versions in the US, another English version in Britain, a German edition, a French edition, a Dutch edition. Everybody is coming up with these things. So it’s not until in the immediate aftermath of the first World War that this metastasizes and it begins to show up in all of these different foreign editions."
            },
            {
                "speaker": "",
                "time": "(02:10:49)",
                "text": "And I think that it just has to do with the changes that have taken place during the war. One of the things that people began looking for was that why was there a war? And we’ve just had this whole disastrous war and the world has been turned upside down. So there has to be some kind of explanation for that. I don’t know. And one of the things this offered to, see there’s this evil plan, there’s this evil plan that has been put into motion, and this could possibly explain what’s taking place. The reason with the protocols were, I think widely bought then and why they still are in many ways is the same reason that the Taxil hoax I was talking about was. Because it told a story that people wanted to believe."
            },
            {
                "speaker": "",
                "time": "(02:11:37)",
                "text": "So in France in the 1890s, there was widespread suspicion of Freemasons. It was seen as a somewhat sinister, secretive organization, certainly secretive. And there was also the same sort of generalized prejudices about Jews, clannish distinct, too much influence, all of the things that went on. So it was sort of easy to combined those two things together. And even though Taxil admits it was a hoax, there were those who argued that this is just too, it’s too accurate. It describes things to completely to be a hoax. And that you get the same arguments, in fact, I’ve heard the same arguments with the protocol. I don’t even buy this as an example of plagiarism, because you can’t actually prove what’s being plagiarized in any sense. To me, the protocols are a prime example of what I call a turd on a plate. These things crop up. I have to explain that now."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:12:47)",
                "text": "Yeah, please."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:12:47)",
                "text": "But afterward. What is a turd on a plate? Well, a turd on a plate is a turd on a plate. Suppose you come in and there’s a plate sitting on the table and there’s a turd on it. Now the first thing you’re going to wonder, is that a turd? Is it a human turd? Where did it come from? Why would someone poop on a plate? There are all these questions that come to mind. It makes no sense, but that’s what you come, it’s just there. Right. I don’t know where it came from. I don’t know why. But there’s a turd on a plate, and that’s what the protocols, that they’re just there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:13:24)",
                "text": "But the reality is just like with a turd on a plate, you take a picture of that in modern day and it becomes a meme, becomes viral and becomes a joke on all social media, and now it’s viewed by tens of millions of people or whatever. It becomes popular. So wherever the turd came from, it did captivate the imagination."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:13:43)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:13:44)",
                "text": "It did speak to something,"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:13:45)",
                "text": "But does it seemed to provide an explanation?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:13:48)",
                "text": "Can you just speak to Jew hatred? Is it just an accident of history? Why was it the Jews versus the Freemasons? Is it the collective mind searching for small group to blame for the pains of civilization and then Jews just happened to be the thing that was selected at that moment in history?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:14:15)",
                "text": "It goes all the way back to the Greeks. Let’s blame them. So one of the first occasions you find the idea that Jews are a distinct, mean-spirited, nasty people goes back to, and a Greco-historian named Manetho. This is around, I think 300 B.C. early, can’t even rope the Romans into this one. So Manetho is trying to write a history of the dynasties of Egypt. I think his history of dynasties of Egypt still is one of the basic works in this. But he tells this whole story, which essentially describes the kind of first blood libels, that the Jews to celebrate their various religious holidays would capture Greeks and fatten them up in the basement and then slaughter them and eat them or drain their blood or do something. Yeah. It’s just the sort of earlier version of that kind. Also, I think it repeats the sort of Egyptian version of the Exodus out of Egypt, which is quite different than the biblical version. In this case, the Egyptian, they stole all the stuff out of the Egyptian’s houses and ran off into the desert."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:15:45)",
                "text": "The Jews stole all the stuff and ran off?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:15:47)",
                "text": "Yeah, Hebrews. Hebrews robbed the Egyptians. They were taken in. We took them in and sheltered them, gave them jobs, and then they stole all the jewelry and ran away. We didn’t even chase them. We were glad to see them gone. So it’s a different narrative on that story, but it essentially portrays the Jews as being hostile, that they don’t like other people, they’re contemptuous of other people’s religions, the rest of it. And see, the Greeks tended to think of themselves as being extremely cosmopolitan. Now, the Greeks run across people worshiping other gods. They go, oh, well those are just our gods under different names. Okay. Everything was sort of adjusted into their landscape. So you end up with that kind of hostility, which was there at the time. And that was probably influenced also by some of these earlier rebellions that had taken place in Egypt."
            },
            {
                "speaker": "",
                "time": "(02:16:53)",
                "text": "During the Roman period, you not only have the Judean Rebellion in 70 A.D., but you have a couple of other uprisings in North Africa, and they were very bloody affairs. And in some cases, Jews began massacring other people around them. They start killing the Greeks and the Greeks start killing them. So there was a fair amount of, from that periodonic, a certain amount of bad blood of mutual contempt between Greeks or between Hellenes, between the people who became Hellenized as the Romans would be and the Jews. And the Romans also seems to have developed much of that idea. They considered Judea as being a horrible place to have to govern, inhabited by a stubborn, obnoxious people, not well-liked."
            },
            {
                "speaker": "",
                "time": "(02:17:48)",
                "text": "So that’s really where you see the earliest version of that. And the reasons for it would be complicated, but you could say is that going back to Manetho and to the Roman period, Jews, Judeans frequently experienced difficulties, conflicts with other people living around them. And part of that probably had to do with the diaspora, which was the movement. Well, you get the idea. The Romans came in and kicked everybody out, which they didn’t. Jews had been leaving Judea since it was a poor limited area. And moving into areas like North Africa, Egypt, Cyrenaica, all the way into Southern France. They moved widely around the Roman Empire. So that sense of both distinctness and hostility existed since ancient times."
            },
            {
                "speaker": "",
                "time": "(02:18:48)",
                "text": "So it wasn’t just, the attitude of the church towards Jews was mixed by… Well, one of the ideas, of course, is that at the end of time, just before the second coming, one of the signs, how are we going to know that Jesus is going to return and the world is going to end? Well, the Jews will all convert. There will be a mass conversion. They’ll sort of see the light. Now, so there have to be Jews around to do that, or we won’t. It’s like a canary in a coal mine. You have to have them there to tip it off. So that was one of the arguments as to why, within the church as to why Jews would not be forcibly converted beyond the fact that it’s just kind of bad policy to forcibly convert people because you don’t know whether it’s sincere, but they need to be preserved as a kind of artifact, which will then redeem itself at the end of time. It’s not something which is encouraged. It predates Christianity, and then Christianity, of course, in its own way, just sort of…"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:20:00)",
                "text": "… of course, in its own way, just plagiarizes the whole Jewish thing, doesn’t it? I mean, I hesitate to use that term, but that’s what you do. It’s just like, “Well, we’re the Jews now. You used to have a unique relationship with God, but now it’s been passed over to us. Thanks for the Bible.” I can remember that on my mom’s side, I was periodically exposed to Sunday school, and pretty much the Old Testament was always presented as if somehow it was the history of, for lack of better term, Europeans in some way. It was a Christian history. It was all the prequel to that. First, the term Hebrew was always used, never Jews. So the ancient Hebrews, and somehow the Hebrews just became the Christians, and I don’t know, the Jews, they didn’t get a memo or something."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:20:59)",
                "text": "So it’s basically like, Christianity, the prequel, is the Old Testament."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:21:05)",
                "text": "Well, they just take over. “We have the special dispensation now. Thank you very much.” You’re an artifact."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:21:13)",
                "text": "So it’s interesting. So this whole narrative that I would say is a viral meme started, as you described, in 300 BC. It just carried on in various forms and morphed itself and arrived after the Industrial Revolution in a new form to the 19th and 20th century, and then somehow captivated everybody’s imagination."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:21:41)",
                "text": "I think that modern antisemitism is very much a creation of the modern world and the Industrial Revolution. It’s largely a creation of Jewish emancipation. It’s the nasty flip side of that. All of the restrictions, they’re thrown off, but now also you become the focus of much more attention than what you had before. Prior to that, you had the ghettoization, which worked both ways. I mean, there were rabbis who praised the ghettos as a protection of Jews against the outside world, because inside we can live our life as we wish and we’re unmolested. The great fear is that if we were absorbed into this larger world, we’ll lose our identity. That sort of question comes up in the 18th century in things like the Haskalah movement in Germany, because the German Jews were always at the cutting edge of assimilation and modernity. And Moses Mendelssohn was an example of that, arguing that we just need to become Germans. So as much as possible, synagogues should look like Lutheran churches. Things should be given in good German. We need to become Jewish Germans. We don’t want to become a group of people who are apart in that way, and that has created great tensions ever since."
            },
            {
                "speaker": "",
                "time": "(02:23:29)",
                "text": "One of the essential points that seems to me in antisemitism, anti-Jew-ism is that all the Jews are in this together. Isn’t that one of the things? Okay. They’re always talking about as if they’re collective. Jews this, Jews that as if it’s a single, undifferentiated mass of people who all move and speak in the same way. From my personal experience, not being Jewish, it’s incredibly diverse in many ways, really. One of the things that anti-Semitism proposes is a continuity or a singularity of Jewish identity that never existed."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:24:10)",
                "text": "Just like you said, in one hand, there’s a good story, in the other hand is the truth, and oftentimes the good story wins out. And there’s something about the idea that there’s a cabal of people, whatever they are, in this case, our discussion is Jews seeking world domination, controlling everybody is somehow a compelling story. It gives us a direction of a people to fight, of a people to hate on which we project our pain, because life is difficult. Life for most is full of suffering. And so we channel that suffering into hatred towards the other."
            },
            {
                "speaker": "",
                "time": "(02:24:48)",
                "text": "Maybe if you can just zoom out, what do you, from this particular discussion, learn about human nature that we pick the other in this way? We divide each other up in groups and then construct stories. And we like constructing those stories, and they become really viral and sexy to us. And then we use those stories to channel our hatred towards the other."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:25:20)",
                "text": "Well, yeah. Jews aren’t the only recipient of that. I mean, anytime you hear people talking about Jews this or that, white people this or that, black people this or that, Asians this or that, where they’re an undifferentiated mass, who apparently all share something in common, well, then nobody’s really thinking. And the other thing you’ll find is that people who will express those views when pressed will argue that, “Oh, well, if they actually know anybody from those groups, those are okay.” It’s like Nazis. They go, “This is an okay Jew. They’re all right.” They would always be constantly making exceptions in one form. What they actually met an actual human being, and they seemed to be fairly normal, well, they were okay. So what it was that they hated weren’t actual people for the most part, it was just this golliwog vision that they had of them. You’re not even talking about real people."
            },
            {
                "speaker": "",
                "time": "(02:26:20)",
                "text": "I don’t know. What does that tell you about human nature? Well, okay, in 70 odd years, what have I learned about my fellow creatures? One, I don’t actually understand them any better than I ever did. In fact, less so. I would say this, when I was 17, I thought I had the world much more figured out than I do now. Completely deluded. But it seemed to make much more sense, and I could categorize things. Basic take upon human beings, most people, most of the time are polite, cooperative and kind until they’re not. And the exact tipping point and moment in which they go from one to the other is unpredictable."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:27:14)",
                "text": "God, that’s brilliantly put. Speaking of the tipping point, you gave a series of lectures on murderers, crimes in the 20th century. One of the crimes that you described is the Manson family murders, and that combines a lot of the elements of what we’ve been talking about and a lot of the elements of the human nature that you just described. So can you just tell the story at a high level as you understand it?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:27:41)",
                "text": "The Manson family. Well, you begin with Charles Manson, who’s the key element in this, and Charles Manson for most of his life up until the time that he’s around 33, is an unexceptional, petty criminal. In and out of prison, reform school from an early age, not really associated with violent crimes. He did stuff like steal cars, write bad checks, became an unsuccessful pimp and drug dealer. So around 1967, he gets out of his latest stint in federal lockup in Terminal Island near Los Angeles, California. By that time, he has learned how to play the guitar, has ambitions to become a musician, and also has proclaimed himself a Scientologist, not that he ever seems to have practiced, but that’s what he would claim that he was. Self-educated himself in prison to a certain degree. So when he gets out of prison in ’67, he was a model prisoner. He behaved himself and seemed… You can imagine his life is going in a completely different direction. And here, again, I’m going to say something good about Charles Manson, which is that he actually was a decent singer. If you really listened to some of the stuff he did… He’s not a great singer, but other people got recording contracts with less talent than he had, and he could play a guitar. The Beach Boys actually do record one of his songs without him."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:29:20)",
                "text": "How would you evaluate Hitler’s painting compared to Charles Manson’s-"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:29:24)",
                "text": "Well, you’re supposed to say it’s terrible. It looks average to me."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:29:28)",
                "text": "Yeah, it’s a landscape."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:29:30)",
                "text": "If you didn’t know it was Hitler, I don’t know what people would say about it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:29:38)",
                "text": "I’m sorry for the distraction."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:29:41)",
                "text": "He’s an average painter. That’s what it was. It’s nothing like crazy, genocidal, maniac paintings. You don’t really have those. So Manson, he could have done that. He made certain inroads into the music industry, and if he hadn’t been such a weirdo, he might’ve gotten further with it. But his life could have taken a different turn. So this is one of the questions I have. Where did a guy who’s an unexceptional career petty criminal suddenly emerge into some sort of criminal mastermind, a Svengali who can bend all of these people to his will and get them to go out and commit murder? That’s a real shift that you have."
            },
            {
                "speaker": "",
                "time": "(02:30:23)",
                "text": "So the first thing that could tell you that something odd is going on is he gets out of prison in LA County and he’s on parole. Parolees are supposed to have a job, not supposed to leave the jurisdiction of their parole. He heads straight for the Bay Area, violates parole right off the bat. Two weeks later, he drifts into the parole office in the Bay Area, whereupon he should have been arrested and sent back to Terminal Island, but instead they just assign him a [inaudible 02:30:57]. I don’t know, maybe things were easier then in some way. So he gets assigned a parole officer, Michael Smith. Michael Smith is initially handling a number of parolees. But after a while, once he takes on Manson, he only has one parolee he’s supervising, Charlie Manson, which is odd. Then you also find out that Michael Smith, in addition to being a parole officer, is a graduate student at the University of California studying group dynamics, especially the influence of drugs on gangs in groups. He’s also connected to the Hayett Ashbury Free Clinic, which is a place where the influence of… Because Hayett Ashbury had lots of drugs and lots of groups. So Charlie Manson never gets a regular job, hangs around with young girls, ex-cons, engages in criminal activity. He is repeatedly arrested, but nothing ever sticks for the next couple of years."
            },
            {
                "speaker": "",
                "time": "(02:32:04)",
                "text": "Who gets that type of thing? Who gets a get out of jail free card? Informants. So here is what? Again, this is speculation, but Manson at some point after he got out of prison is getting this treatment because he is recruited as a confidential informant."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:32:28)",
                "text": "For who?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:32:29)",
                "text": "For who? That’s the interesting question. So, probably not for any local police departments. My best suspicion is probably the Federal Bureau of Narcotics, precursor to the DEA. Federal parolee, federal parole officer, graduate student in drugs and group dynamics. And eventually with permission, he goes back down to LA. And what is he part of when he’s there? Well, he’s on the fringes of the music industry. The Wilsons and elsewhere, which also brings him to the fringes of the film industry. So one of the things, if you’re looking in terms of Hollywood music industry elites in the flow of… Oh, and he’s also dealing in drugs and girls. So an early version of Jeffrey Epstein. Manson attracted lots of underage runaways and trained them, used them, also associating with biker gangs who produced the drugs, et cetera."
            },
            {
                "speaker": "",
                "time": "(02:33:41)",
                "text": "So that’s part of it. He’s an informant in the movement of drugs basically within the film and music industries. And he’s given pretty much a free rein at that point. What then happens in August of 1969 is that there are these murders. First, Sharon Tate and her friends in Cielo Drive. I think everybody has probably pretty much heard that story before. And of course, the question is why Cielo Drive? Why Sharon, Tate, Frykowski and the rest of them? Manson was familiar with the place. He had been there before. Members of the family had been there before, so he knew where it was. It wasn’t an easy place to find. The original house is no longer there, but the same property and a house is built there. And if you didn’t know where it was… It’s not some place, “Let’s just go for a drive in the Hollywood Hills and murder people in a house.” Well, that isn’t the one that you would come across. There are lots of connections there. Wojciech Frykowski was one of the people killed at the Cielo Drive house, was involved in drug dealing. That’s a possible connection between the two, probably a fairly likely one. Probably not unfortunate Sharon Tate at all. She was probably in the wrong place at the wrong time. Her husband might’ve been, you never know."
            },
            {
                "speaker": "",
                "time": "(02:35:06)",
                "text": "And then the next night after the slaughter there… Which by the way, Manson is not at. So this is one of the interesting things about it is, Charles Manson doesn’t kill any of these people. His crime is supposedly ordering the killings to be done. He supposedly thought that the killings at the Tate house were sloppy, and he was going to give everybody a crash course in how you apparently commit seemingly random murders. So the next night he takes a group of people over to the LaBianca’s house in a different section of LA. You’ve got Leno, Rosemary LaBianca, the guy is a grocer. His wife runs a dress shop, upper middle class, and they’re bound and gagged and hacked to death. As at the Tate residence, various things like piggy are written, various messages in blood, things that are supposed to look like cat’s paws. Because one of the groups trying to be framed for this was the idea was the Black Panthers."
            },
            {
                "speaker": "",
                "time": "(02:36:10)",
                "text": "So the general story that comes out in the subsequent trial is that this was all a part of something called Helter Skelter, which supposedly was an idea that… That sounds like a Beatles song. That’s where he got it from. He thought the Beatles were talking to him through their music and that there was going to be an apocalyptic race war, and this was all part of a plan to set this off. So this is why the Black Panthers were trying to be implicated in this. Although, how it was supposed to do that is never really explained."
            },
            {
                "speaker": "",
                "time": "(02:36:46)",
                "text": "Here is what I think was really happening, what really happened and how I think it fits together. Before Sharon Tate and her friends or the LaBiancas were killed, there was a murder by members of the family of some of the same people involved in the later killings of a musician, drug manufacturer by the name of Gary Hinman. So Manson, again was involved in the drug trade, and Hinman made them. He was a cook, basically, and he brewed them up in his basement, sold the drugs to Manson, who sold them to biker gangs like the Straight Satans, which was one of the groups that he used, and they distributed them elsewhere. Well, one day, the Straight Satans show up and complain that the last batch of meth or whatever it was that they got from Manson, had made some of their brothers very, very ill, and they were quite unhappy about that, and they wanted their $2,000 back. Manson had gotten those drugs from Gary Hinman. So he is unhappy, and he sends Bobby Beausoleil, and a couple of the girls over to Hinman’s place to get the money from him. As the story is later relayed, I think by Susan Atkins, Hinman denied that there was anything wrong with his drugs and refused to pay up, which led to a interrogation torture session in which he was killed."
            },
            {
                "speaker": "",
                "time": "(02:38:22)",
                "text": "And the idea was here, what are we going to do with that? Well, one of the other groups that Hinman had sold drugs to were, guess what? People associated with the Black Panthers. So we’ll leave these things up and they will do it. So it’s Bobby Beausoleil who then takes Hinman’s car and decides to drive it up the coast, by the way, with a bloody knife with Hinman’s blood and hair on it, and blood on the seats in the car, and then he pulls it off the road and decides to sleep it off, and he gets busted. So, find Hinman’s body, find Beausoleil in Hinman’s car with a bloody knife with him. He gets arrested. So Beausoleil was very popular with some of the girls. There’s consternation in the family that Bobby has been arrested. So how can we possibly get Bobby out of jail? Copycat killings. So if we go kill more people and we make it look the same, then see, Bobby couldn’t possibly have done it. Now, see, he just borrowed the car. Okay, he stole the car, but the knife was already in… He didn’t have anything to do with this. So that to me makes the most sense out of what followed."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:39:39)",
                "text": "How often do people talk about that theory? That’s an interesting theory."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:39:43)",
                "text": "Well, it’s there. It’s just not the one that… Bugliosi obviously wanted to go with Helter Skelter because again, it was a story that people could understand. It was sensational and it would catch on. Also, another probable issue in that was that his star witness was Linda Kasabian. Linda Kasabian, she was present at both the Tate and LaBianca murders. She didn’t participate in the killings, according to her. She drives the car. But everybody else talked about what had happened. Well, okay, she turns [inaudible 02:40:19] evidence and gets total immunity, and it’s largely in her testimony that all the rest of the case is based. Now, if you start throwing into the equation that she proclaimed her love for Bobby Beausoleil, and that she, according to others, was the chief proponent of the copycat killings, well then that would get messy. Now, there’s one guy that’s at the center of this, it’s Charles Manson. He ordered all of this done to ignite a race war, even though, how would any of that do it?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:40:58)",
                "text": "So that doesn’t make sense. But he is nevertheless at the center of this because he’s the glue of the family. Right?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:41:05)",
                "text": "He exerts a tremendous amount of psychological control over them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:41:08)",
                "text": "How was he able to do that? Sorry to interrupt. Because you said he was a petty criminal. It does seem he was pretty prolific in his petty crimes. He did a lot of them."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:41:17)",
                "text": "He had a lot of access to LSD. Which he started getting at the free clinic in San Francisco. So lots of it floating around. Some descriptions of the family at Spahn Ranch is that people were basically taking acid on a daily basis, which by the way was also a potential problem with Linda Kasabian’s testimony since she also admitted to being high most of the time, and also thinking she was a witch. Where do you want to go with that? See, if Manson wasn’t Manson, if he hadn’t actually acted like the crazed hippie, psycho goofball that Bugliosi painted him as being, then Kasabian’s testimony wouldn’t have been as strong because you could… I mean, the first thing against her is you’ve got an immunity for telling the story the prosecution wants. That’s a little iffy, and we won’t even bring in the witch and the drugs and being in love with Bobby Beausoleil. So if Manson had been dressed like you, sitting there in a suit and tie, and behaved himself and spoken normally… This isn’t to say that he wasn’t guilty as hell."
            },
            {
                "speaker": "",
                "time": "(02:42:38)",
                "text": "So what he supposedly did to inspire all of these killings, and I think that’s probably beginning with the Hinman killing, he told him to go over there and get the money one way or the other. I don’t know whether he told him, “If you don’t get the money, kill him.” But, Hinman’s dead. And then he might also have seen the value in terms of having copycat killings as a way of throwing off any other blame. The other story you get is that one of the people who had lived at the Cielo house where Sharon Tate was before, was a record producer by the name of Terry Melcher. Melcher supposedly, as the general story goes, had welched on a deal with Manson in terms of a record contract. He screwed over Manson in some sort of a record deal, and Manson wanted to get revenge and sent them to kill everybody in the house, which again, doesn’t make much sense. One, Manson knew that Melcher wasn’t living there anymore. He probably knew where Melcher was living. If he wanted to get Melcher, he could have found him. It wasn’t that difficult to do."
            },
            {
                "speaker": "",
                "time": "(02:43:57)",
                "text": "And so it’s not revenge on Terry Melcher that drew him there. He was familiar with the house. So if the idea was to simply commit random killings that would muddy the whole waters with the Hinman killing, then you might pick some place you knew of. He knew the place was [inaudible 02:44:23]. There would be someone there, and you really didn’t care, in the same way that the LaBiancas seemed to have been. Manson was familiar with that because it supposedly had been the scene of creepy crawling. This is little interesting things that the family would be taught to do. Creepy crawling is when you sneak into somebody’s house at night while they’re there asleep, or when they’re not there, and you move things around. So when they get up in the morning or they come home, they’ll suddenly notice that someone has been in their house, which will freak them out, which is the whole point of that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:45:02)",
                "text": "But it doesn’t seem like the murder or the creepy crawling was the… Well, creepy crawling maybe. But it doesn’t seem like the murder… Like some of the other people you’ve covered like the Zodiac Killer, the murder is the goal. Maybe there’s some psychopathic artistry to the murder that the Zodiac Killer had and the messaging behind that. But it seems like, at least the way you’re describing it with the Charles Manson family, the murder was just… They just had a basic disregard for human life, and the murder was a consequence of operating in the drug underworld."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:45:40)",
                "text": "So Manson set up a base, I think called the Spahn Movie Ranch, which was an old movie ranch out on the northwest edge of LA, and they just camped out there. He used the girls, in particular, “Squeaky” Fromme to get the owner or operator, George Spahn to let them hang out there. Basically, she slept with him, and he was perfectly happy to let them hang out. They also had a place out in the desert that they had. They dealt in credit card fraud, stolen cars. It was a chop shop that they ran out of the place. So he had a fairly good little criminal gig going, which with the protection he had probably would’ve… The one thing they couldn’t cover him on was murder."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:46:31)",
                "text": "So you think if he was an informer, you think there was still a connection between DEA, FBI, CIA, whatever with him throughout this until he committed murder?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:46:41)",
                "text": "Well, the real question is… There is a book written on this by Tom O’Neill called Chaos. I’m not necessarily saying it’s the easiest thing to get through. There’s a lot of material there. I don’t think O’Neill necessarily knows what to make of some of the stuff he came up with, but he does a very good job of demolishing the whole Bugliosi narrative. One of the people he mentions is a name that I had run into elsewhere, and so I really paid attention to it when I saw it again. And the name is Reeve Whitson. Reeve Whitson shows up on the fringes, even though he has no judicial function. He hangs around Bugliosi in the prosecution. He’s just there. In the same way that he was one of these guys… He grew his hair long, wore bell-bottoms, hung around the music community and elsewhere in Hollywood, but no one could tell you exactly what he did. I know what he did later. A decade later, he shows up as a CIA officer in Central America."
            },
            {
                "speaker": "",
                "time": "(02:47:51)",
                "text": "So Reeve Whitson, later in his career at least, is CIA. What was he in 1969? What is he doing in this? The other thing about it is he appears to have been the person who called… There’s a little question of when the bodies at Cielo Drive are discovered. So the general story is that Sharon Tate’s housekeeper shows up around 8:30 in the morning, finds the bloody scene and goes screaming next door. But there was another fellow who knew… I think the owner of the house is a photographer. Last name may be Hatami. He gets a call earlier in the morning saying that there’d been murders there, and the person he recalls calling him is Reeve Whitson. So someone had been at the house before the bodies were discovered, and they had not called the police. So I don’t know what’s going on there, but it’s a curious situation."
            },
            {
                "speaker": "",
                "time": "(02:49:07)",
                "text": "And Manson in a lot of ways, self-immolates himself. I mean, his behavior at the trial is bizarre. It’s threatening, it’s disruptive. He’s got his girls out on the street carving X’s in their forehead, carrying knives. One of the attorneys, initially, his attorney, Ron Hughes, becomes Van Houten’s attorney. And he figures out that the three girls, supposedly on Charlie’s insistence, are going to confess. They’ll confess that it was all their idea and Charlie had nothing to do with it. Hughes doesn’t like this because his defense for her is that she was under his influence and therefore not responsible for her own actions. He was having psychic control, so he refuses to go along with it. There’s a break in the trial. He goes camping up in the mountains with some friends, disappears during a rainstorm, and then some months later, his decomposed remains are found."
            },
            {
                "speaker": "",
                "time": "(02:50:12)",
                "text": "Rumors, always the rumors. What would history be without rumors? Members of the family, they were off at Ron Hughes because he messed up Charlie’s idea to get him off and so they killed him. Maybe they did. Maybe he drowned. That’s absolutely impossible to say. You’ve got that story. There’s a guy named Juan Flynn, who was an employee at the Spahn Ranch, didn’t like Manson, held Manson responsible for the murder of his boss. He would testify that Manson told him that he had ordered all the killings, and that Manson also admitted that he had killed 35 people. Maybe he did. On the other hand, Juan Flynn didn’t like him, and other than his word had no real proof of what he was saying."
            },
            {
                "speaker": "",
                "time": "(02:51:03)",
                "text": "So please understand me in this case, is that unlike some people who argue that Charles Manson got a raw deal, I don’t think that’s the case. I think that he influenced tremendous influence over the people there through drugs. Sex was another frequent component in it. He had a real whammy over a lot of these people’s minds. I’m not sure how. That still puzzles me. He was a scrawny guy and he wasn’t physically intimidating. I mean, even a lot of women wouldn’t be physically intimidated by him. But he nevertheless had this real psychological power. And if you look around him, the male followers he had were fairly big guys. So he could get people to do what he wanted. And again, to me, the simplest explanation for this is that it began with the Hinman killing, and probably on Manson’s instigation the others were copycat killings to throw off what was going on. If I was a cop, that’s what I would focus on because that seems to make the most sense."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:52:19)",
                "text": "It still is fascinating that he’s able to have that much psychological control over those people without having a very clear ideology. So, it’s a cult."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:52:29)",
                "text": "Yes. The great focus on Charlie, the leader. The excessive devotion."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:52:35)",
                "text": "But there’s not an ideology behind that, like something like Scientology or some kind of religious or some kind of… I don’t know, utopian ideology. Nothing like this?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:52:48)",
                "text": "No. I think that Madison, again, was essentially a criminal. He had a sociopathic mindset, and he hit upon a pretty good deal."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:52:57)",
                "text": "But how do people convince anybody of anything? With a cult, usually you have either an ideology or you have maybe personal relations, like you said, sex and drugs. But underneath that, can you really keep people with sex and drugs? You have to convince them that you love them in some deep sense. There’s a commune of love."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:53:18)",
                "text": "You have a lot of people there in the cult. They have some sort of, what we like to call dysfunctional families. A lot of the females in particular seem to have come from more or less middle-class families, but those are full of dysfunction. Their parents didn’t love them. They were semi-runaways. And now they had this whole family. A lot of the younger women had children, some of them by Manson, some of them by the others. They bonded together."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:53:53)",
                "text": "And again, we return to that pull towards belonging that gets us humans into trouble. So it does seem that there was a few crimes around this time. So, the Zodiac Killer."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:54:13)",
                "text": "Well, California, where I’m from… I remember this period vividly. By the way, the Tate LaBianca killings occurred on my birthday, the year I graduated from high school. So I remember this."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:54:28)",
                "text": "Happy birthday."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:54:29)",
                "text": "A term which has been used for that… There’s a writer by the name of Todd Wood who’s [inaudible 02:54:34]… I wish I’d come up with this. Killerfornia. Which is a chronicle of these serial killers and disappearances in the late sixties and seventies. So you’ve got the Zodiac, you’ve got other ones. I mean, I hate to say it, I’m not trying to be flippant about it, but I mean, young female hitchhikers were disappearing at an alarming rate in Northern California. There are bodies that have never been attributed. Some think that they’re-"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:55:00)",
                "text": "That have never been attributed. Some think that they’re the Zodiac’s victims, but it was a dangerous time. Edmund Kemper, the co-ed killer was another one. There were a lot of creepy psychopaths running around. I don’t know whether it was something in the water or what was going on, but it was a menacing in some cases. Hitchhiking, especially if you were alone and female, was not something you wanted to do in much of the Golden State, certainly not up around the Bay Area. So a lot of these strange killings that were going on, the Zodiac, it’s one of those things where you have these people who have theories about it, and if you don’t share their theory, then you’re part of the problem in some form or another. So I’m not sure, for instance, that the Zodiac killings were all committed by the same person. I think there might’ve been multiple people involved."
            },
            {
                "speaker": "",
                "time": "(02:56:02)",
                "text": "And the first killings are all of couples. It’s very clear that they… I remember in my examination of it, one of the things I was looking at specific, what else is there to say about this zodiac killings? What I was going to look at is that there are all of these accusations that there was an occult aspect to it, that there was some sort of ritualistic aspect. So I looked at different things, locations, victims, phases of the moon. That’s always worth looking at. I didn’t find much correspondence in any of those. In one of the killings, I think the one in Lake Berryessa, he does appear in this kind of weird hooded costume. He’s got his symbol that sort of compass or aiming reticle circle with a cross through it. It can mean a variety of things. He used guns and he used knives, but he certainly had to think for couples. Except in the last of the killings, which is of a cab driver in downtown San Francisco, who he shoots in full view of witnesses, which is completely atypical."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:57:12)",
                "text": "And also when he was stabbing the victims, it doesn’t seem like he was very good at it. Or if the goal was to kill them, he wasn’t very good at it because some of them survived."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:57:23)",
                "text": "Yeah, he’s not particularly thorough about it. He seems to have had much more…. More of the violence seems to be directed at the females than the males."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:57:33)",
                "text": "So I mean, there’s a couple of questions to ask here. First of all, did people see his face?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:57:38)",
                "text": "There is a composite drawing of his face, which I think is based upon the Stine killing, the cab driver killing, where there were people who saw him or who claimed that they saw him. The other ones were all when it was fairly dark. I’m not sure that anyone else got a look at his face. The one that occurred in the daylight at Berryessa, he was wearing a mask. So there’s something in common initially in the targeting of victims, which doesn’t in the last case. Then after that, there’s just these different cases of where there’s a pretty good case to be made. A woman who claims, I think she and a small child were picked up. Her car broke down, she got a flat tire, and she was picked up by this guy who she got a very sort of strange vibe from who eventually just let her go. Well, that might’ve been the Zodiac. It might not have been."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:58:35)",
                "text": "You do this kind of rigorous look saying like, okay, what is the actual facts that we know? Reduce it to the thing that we know for sure. And in speaking about his motivation, he said that he was collecting souls."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:58:53)",
                "text": "Souls for the afterlife."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:58:55)",
                "text": "For the afterlife."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:58:56)",
                "text": "That’s kind of a cultie."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:58:57)",
                "text": "Yeah, I mean that’s what I believe. Is it the Vikings or the Romans? They believed this in battle."
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:59:04)",
                "text": "You’re essentially making sacrificial victims, and they will be your ghostly servants in the afterlife."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:59:10)",
                "text": "Do you think he actually believed that?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(02:59:12)",
                "text": "Who knows? I mean, here’s the question. Was he making that up just to be scary or is that what his actual? That’s what he’s saying his motivation is. So let’s take him at face value rather than trying to wish that into the cornfield to get rid of it. Let’s just take it at face. So he’s claiming that he’s killing these people in order to acquire slave servants in the afterlife. He will subsequently go on to claim many more victims, I’m not sure, 44 eventually he will have before he just kind of vanishes. One of the really interesting clues to me when I was looking at that case, which I didn’t find anybody else that tended to make much of it, is that it all has to do with this kind of Halloween card that he sends to the press in San Francisco. And it’s talking about sort of rope by gun by fire, and there’s this whole sort of wheel, like the zodiacs. But what this is drawn from, where he got this from is from a Tim Holt Western comic book published in 1951, and you see the same thing in the cover."
            },
            {
                "speaker": "",
                "time": "(03:00:27)",
                "text": "It’s Wheel of Fortune, but with different forms of grisly death on it. And all of the things that he mentioned are shown on the cover of this. So whoever put together that card saw that comic book. Well, that’s kind of an interesting clue. So does that mean he’s a comic book collector? When would he have… I mean, that one and also where he got the idea from, and so he’s incorporating these things from. Then there are of course his codes, which people have, which aren’t all that difficult to decipher probably because they weren’t meant to be. The other thing that you find often with serial or psychopathic killers is they’re toying with the press. I mean, this goes all the way back to Jack the Ripper. They get attention, and then he just disappears."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:01:20)",
                "text": "Why do you think he was never caught?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:01:22)",
                "text": "I don’t think they knew who to look for. There was nothing much to go on. There was a guy who was long a suspect, and then eventually they tested his DNA and find it didn’t match any of the things that they’d found. Again, it goes back to, I’m not even sure that it’s one person who’s responsible for all of them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:01:44)",
                "text": "So one of the interesting things you bring up here and our discussion of Manson inspires this, but there does seem to be a connection, a shared inspiration between several killers here, the Zodiac, the Son of Sam later, and the monster of Florence. So is it possible there’s some kind of underworld that is connecting these people?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:02:11)",
                "text": "Well, take the Zodiac and you get his claim that he’s collecting souls for the afterlife. There are other things that are occult-ish connected to that. He may have picked some of the killing sites due to their physical location, to their position in a particular place. If you look at the Son of Sam case, of course, David Berkowitz will on and off claim that he was part of a Satanic cult that was carrying out, again, these killings mostly of couples and young women similar to the Zodiac, and that he had only committed some of them and was witnesses to others. And that has really created the whole idea that yes, there is this some kind of Satanic cult, which engages in ritual murders. Then if you go all the way to Florence, you’ve got murders who go on and off for a long period of time. Again, focusing on couples in isolated areas, which Italian prosecutors ultimately tried to connect to some kind of satanic cult, although I’m not sure they ever made a particularly strong case for that. But that element comes up in all three of them. So you can with a little imagination, argue that those similarities, that those things should come up in each of those cases in different places, either suggest that oddly enough, psychopathic criminals all sort of thinking the same way, or that there is some sort of higher element involved in this, that there’s some kind of common inspiration. Here you come back to something similar we were talking before about, do pedophiles exist? Okay, so do satanic cults exist? Well, they do. Okay. There was one in my hometown, apparently quite harmless as far as I know, never did anything. But there are people who robes. Here we come again, robes, cut the head off a chicken, naked woman as an altar. You can get off on that I suppose, if that’s your thing. So professed satanists exist, satanic cults exist, serial killers exist, ritual murders exist. Are those things necessarily connected? No. Could they be connected? Yes. There’s nothing. Don’t ever tell me that something is just too crazy for people to do because that’s crazy talk."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:04:58)",
                "text": "You’ve studied secret societies. You gave a lot of amazing lectures on secret societies. It’s fascinating to look at human history through the lens of secret societies because they’ve permeated all of human history. You’ve talked about from everything from the Knights Templar to Illuminati, Freemasons, like we brought up. Freemasons lasted a long time. Illuminati, you’ve talked about in its sort of main form, lasted a short time, but its legend."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:05:26)",
                "text": "Never gone away."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:05:27)",
                "text": "Never gone away. So maybe Illuminati is a really interesting one. What was that?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:05:33)",
                "text": "Well, the Illuminati that we know started in the 1776. In fact, you can pin it down to a day, the 1st of May, May Day, 1776 in Ingolstadt, Germany, founded by a professor Adam Weishaupt. It wasn’t initially called the Illuminati because that’s not really the name of the organization. It was called the Order Perfectibilists. Apparently that changed. Weishaupt would say things like never let our organization be known under its real name anywhere, which leaves wondering what’s its real name. So Illuminati is simply the plural of Illuminatus, which means one who is illuminated, one who has seen the light. So in Roman times, Christian converts were Illuminati because they had seen the light, anyone who thinks. And there have been organizations called Illuminati. The term is not trademarked, not copyrighted. Anybody who thinks they’ve seen the light about anything is an Illuminati. So it defines nothing."
            },
            {
                "speaker": "",
                "time": "(03:06:44)",
                "text": "The symbol of the order was an owl, which interestingly enough is almost identical to the owl which is the emblem of the Bohemian Club."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:06:55)",
                "text": "Oh, boy."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:06:56)",
                "text": "Make of that what you will. I don’t make that much out of it because one owl looks pretty much like another owl to me. But compare them, you got to kind of wonder about, there’s a little, just a little thing. Maybe there’s some kind of connection there. But that supposedly has to do with the connection to the goddess Minerva and the owl was sacred to her and the order was the Minerva of all, the person who was brought in. The number of levels changed over time. There was a higher level, so the order that people at the lower level didn’t know about, pretty typical for this. But the thing about Weishaupt was that he was a luminous correspondent with members with his Illuminati, both during the time that it legally existed in Bavaria and later on."
            },
            {
                "speaker": "",
                "time": "(03:07:50)",
                "text": "So Weishaupt himself lives, I think until 1830, dies in Gotha, which was ruled by an Illuminati prince. And so nothing ever happens to these. No Illuminati is ever put to death or arrested in prison for any period of time. What happens is that their plan… Well, what was his plan? His plan was to essentially replace all existing religions and governments in the world with a one world order governed by the Illuminati. So to do this, you had to subvert and destroy all the existing order. And he argued the purpose for this is we wish to make men happy and free, but first we must make them good."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:08:37)",
                "text": "Oh, right."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:08:39)",
                "text": "So that’s what the order is all about. Of course, he also said things like, oh man, is there nothing that you won’t believe? So myth would be used in that. Also thought women should be brought into it. He had a rather interesting view about that was that we should appeal to women in part because women have a chip on their shoulder because they’re left out of things. So we should appeal to their vanity on that point and offer that in the future, all things will be open and they will be emancipated. So we should hold out the prospect of female emancipation to attract them because he argued in the short term, there’s no better way to influence men than through women. Get women on our side by promising them emancipation, but made sure we’ll never actually deliver it to them because the future world will be a boys club."
            },
            {
                "speaker": "",
                "time": "(03:09:29)",
                "text": "So he talks about these things fairly openly, and this is where you get this idea of some sort of a new world order, which is to be based upon the destruction of the existing order. So there are those who argue that there is a trail of descent that leads from Weishaupt’s Illuminati to the Communist manifesto, and in fact, communism itself, that Marxism was simply a further restating of this idea. And you can draw some sort of, I mean, the idea never entirely goes away. The Bavarian government gets a hold of the order’s, inner texts. So the story is they’re delivered to them. I think that Weishaupt gave them to him. I think he engineered the exposure of his order because it gave him publicity. By being exposed in Bavaria, you gained great renown. And they continued to recruit after this, and the Bavarian government actually bans the Illuminati four different times. Why? Because apparently the first three times didn’t work. So the fourth one does. You can notice that it’s like Papal bans on Freemasonry. They just go on and on and on because this clearly isn’t working."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:10:52)",
                "text": "And you actually highlight, speaking of publicity, that there’s a difference between visibility and transparency. That a secret society could be visible, it could be known about, it could be quite popular, but you could still have a secrecy within it."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:11:08)",
                "text": "You have no idea what’s going on inside. It’s like a black box. If I set a black box on this table, we can see that there is a black box. What’s in the black box? A cat? Who knows?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:11:18)",
                "text": "In fact, the secrecy might be the very thing that makes it even more popular."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:11:21)",
                "text": "Adam Weishaupt, again, there is no more convincing than a concealed mystery. Give people a concealed mystery in the thought. So we need to make the order mysterious for that exact reason. Always hold out the possibility that knowledge, special knowledge that no mere mortals have other than you will have in that way. So he senses a lot of things, the use of vanity and ego to recruit people to influence both men and women, it’s quite sophisticated and as you might expect from a professor of canon law trained by Jesuits. So I certainly don’t think that it ceased when it was banned in Bavaria because everybody just scatters and goes elsewhere like Paris. And then you have the French Revolution."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:12:21)",
                "text": "So the idea of the Illuminati to put it crudely, the branding is a really powerful one. And so it makes sense that there’s a thread connecting it to this day that a lot of organizations, a lot of secret societies can adopt the branding."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:12:39)",
                "text": "Anybody can call it. You can go out and form a club, and call it the Illuminati."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:12:43)",
                "text": "And if you are effective at it, I think it does attract. It’s the chicken or the egg. But powerful people tend to have gigantic egos, and people with gigantic egos tend to like the exclusivity of secret societies. And so it’s a gravitational force that pulls powerful people to these societies. It’s exclusive."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:13:05)",
                "text": "Only certain. And you also notice something goes back to when we were talking about much earlier when we were talking about intelligence. Remember MEIS? Ego."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:13:12)",
                "text": "Ego, yeah."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:13:12)",
                "text": "Ease of recruitment and control. That’s a great Achilles heel in human beings, the exploitation of ego."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:13:21)",
                "text": "And of course, if we go back to the conversation of intelligence agencies, it would be very efficient and beneficial for intelligence agencies to infiltrate the secret societies because that’s where the powerful people are."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:13:36)",
                "text": "Or the secret societies to infiltrate the intelligence agencies."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:13:39)",
                "text": "Oh boy. Well, I mean that’s actually in all the lectures, I kind of had a sense that intelligence agencies themselves are kind of secret societies, right?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:13:53)",
                "text": "Well, I’ll give you my definition of secret societies, what they come down to. One is that generally their existence isn’t secret. It’s what they do is secret. It’s what’s in the box as opposed to the existence of the box. So one of the most important criteria is that they are self-selecting. You just don’t join. They pick you. They decide whether or not you’re going to, they admit you. And oftentimes they will sort of recruit you. Once you have been recruited, you have to pass tests and initiations, and you also have to swear oaths of loyalty. Those are always very, very critical. So broadly speaking, what the entrance into an intelligence organization does, they decide whether you get in. You just don’t automatically get the job. You have to pass tests, a lie detector test, for instance, field training tests, a whole variety of tests. And then you’re sworn to secrecy. You never talk about what you do ever. Or there will be dire consequences."
            },
            {
                "speaker": "",
                "time": "(03:15:05)",
                "text": "So the method is very much the same. And also this idea of creating a kind of insular group. The organization is us, and everyone else is outside of that. We are guardians of special knowledge. See, this is the type of thing that would generally happen if you question whatever any kind of intelligence agency did. Well, we know things that you don’t. Why? Because we’re the organization that knows things. We collect information, we know the secrets, we guard the secrets. Therefore, if we tell you, you must believe us."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:15:45)",
                "text": "I have this sense that there are very powerful secret societies operating today, and we don’t really know or understand them. And the conspiracy theories in spirit might have something to them but are actually factually not correct. So an effective, powerful secret society or intelligence agency is not going to let you know anything that it doesn’t want you to know, right?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:16:13)",
                "text": "They’ll probably mislead you if you get too close. So I think the question is what’s the most powerful or important secret society? Probably the one you don’t know about, one that doesn’t advertise its existence, the one which is never known anywhere under its real name. You’ve got things like the Bohemian Club, you’ve got the Bilderbergers, which is another formed in the 1950s, largely the creation of a guy by the name of Josef Retinger, Polish, mysterious, appears out of who knows where, a schemer for years, a man expelled from Britain, France and the United States at one point or another, long active in the Mexican labor movement. Retinger is a mysterious figure. In fact, I think there was even a book written about him called Eminence Grise, Grey Eminence. The fellow who was the front man for the Bilderbergers was Prince Bernhard of the Netherlands, who was at one point a Nazi and then a Dutch freedom fighter."
            },
            {
                "speaker": "",
                "time": "(03:17:21)",
                "text": "All right, take your pick. But Retinger is the moving hand behind the whole thing, and I’ll be damned if I can figure out who Retinger is. So the idea is that, well, you get like influential people in media, business, politics, and you bring them together just to talk, to try to find common answers or common questions. It’s all very much sort of Western Anglo-European. It’s all very closely sort of connected to NATO, the whole concept of a kind of Atlanticist world, which is essentially the Anglo-American combine combined with Western Europe. But you got a bunch of these things. I mean, the Council on Foreign Relations is very similar to that and the Bilderbergers, and there’s an overlap with the Bohemian Club. And then you’ve got the Pinay Cercle or Le Cercle, which is more military, but also linked to the so-called secret Gladio. The idea of the Soviets over around Western Europe, there would be a stay behind organization called Gladio. There’d be these freedom fighters."
            },
            {
                "speaker": "",
                "time": "(03:18:43)",
                "text": "So the question I have about that is that how many secret organizations do you need? I mean, why all these separate groups which often seem to have the same people into them?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:18:53)",
                "text": "Yeah. The closer I look, the more I wonder the same question we asked about the Russian intelligence agencies is where’s the center of power? It seems to be very hard to figure out. Does the secrecy scare you?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:19:07)",
                "text": "Well, I guess on one level I’m comforted that there’s somebody actually making decisions as opposed to, I mean, what do you want? Do you want chaos or do you want everything kind of rigidly controlled? And I don’t put much stock in the idea that there actually is some small group of people running everything, because if they were, it would operate more efficiently. I do think that there are various disparate groups of people who think that they’re running things or try to, and that’s what concerns me more than anything else."
            },
            {
                "speaker": "",
                "time": "(03:19:51)",
                "text": "Well, I hate to go back to them again because what you’re bringing up, you go back to the Nazis. They had their whole idea about a new world order, and they only had 12 years to do it. And look what a mess they made. I mean, look at the damage, the physical damage that can be done by an idea inspiring a relatively small group of people controlling a nation based upon some sort of racial or ideological fantasy that has no real basis in reality and yet guides their actions. It’s this differentiation that I always make. And I would try to get across to students between always be clear about what you know and what you believe. You don’t know many things."
            },
            {
                "speaker": "",
                "time": "(03:20:40)",
                "text": "You know your name, you know when you were born, you probably know who your father is, but that’s not absolute unless you’ve had a DNA test and only if you trust DNA tests. So you know who your mother is. You believe this man is your father. Why? Because your mother told you he was. So you believe things generally because someone has told you this is to be true, but you don’t really know for sure."
            },
            {
                "speaker": "",
                "time": "(03:21:09)",
                "text": "Well, because we know so little, we tend to go by beliefs. So we believe in this. We believe in that. You believe that your cult leader is the answer to everything. And it seems to be very, very easy to get people to believe things. And then what happens is that whether or not those beliefs have any real basis in reality, they begin to influence your actions. So here again, regrettably in some ways to bring it back to the Nazis, what were the Nazis convinced of? They were convinced that Jews were basically evil aliens. That’s what it comes down to. They weren’t really humans. There’s some sort of evil contamination which we must eradicate. And they set out to do that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:21:59)",
                "text": "And they were sure that there’s just a few problems that can be solved. And once you solve them that you have this beautiful utopia where everything would be just perfect, it’d be great, and we can just get there. And I think it’s really strong belief in a global utopia. It just never goes right. It seems like impossible to know the truth in it."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:22:21)",
                "text": "For some reason, not long ago, I was listening on YouTube to old Wobbly songs, the Workers of the World. I don’t know why. I know there was a whole album of Wobbly songs, and there was one of them called Commonwealth of Toil. And like most of them, they’re sort of taken from gospel songs. And it’s talking about in the future how wonderful everything will be in the Commonwealth of Toil that will be. And now these are revolutionary leftists, in this case, Wobblies. But nonetheless, it’s like a prayer for communism everything. Now in the future, everything will be good because the earth will be shared by the toilers. And from each abilities and to each according to his need. And it’s this kind of sweet little song in some way. But I’m just sort of imagining this. If I was going to stage that, I’d have this choir of children singing it with a huge hammer and sickle behind them because that’s what it’s combining. And you can think that the sentiments that express in that song, which are legitimate in some way of all the horrors that then leads to."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:23:52)",
                "text": "It is fascinating about humans. A beautiful idea on paper, an innocent little idea about a utopian future can lead to so much suffering and so much destruction and the unintended consequences you see described."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:24:08)",
                "text": "The law of unintended consequences."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:24:10)",
                "text": "And we learn from it. I mean, that’s why history is important. We learn from it hopefully."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:24:13)",
                "text": "Do we?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:24:15)",
                "text": "Slowly or slow learn."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:24:19)",
                "text": "I’m unconvinced of that, but perhaps."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:24:22)",
                "text": "Speaking of unconvinced, what gives you hope? If human beings are still here, maybe expanding out into the cosmos 1000, 5,000, 10,000 years from now, what gives you hope about that future, about even being a possible future about it happening?"
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:24:44)",
                "text": "Most people are cooperative and kind most of the time. And that’s one of those things that can usually be depended upon. And usually you’ll get back to what you put into it. Another thing that I have a weird fascination of watching are people who have meltdowns on airplanes because it’s just bizarre."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:25:20)",
                "text": "That’s fascinating to watch."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:25:21)",
                "text": "The people who will, there’s some sort of psychotic break that occurs, and it’s always going to end the same way. The cops are going to come on and drag you off the plane. Now. True, and you’re going to inconvenience everybody there. And usually at some point, they don’t care about that. That’s the one little sense of power that they have. So they have some sort of sense of powerlessness. And if their only way of power is just to piss off everybody else on that plane, they’re going to go ahead and do it even though it’s going to lead nowhere for them."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:25:56)",
                "text": "And there’s similar sometimes psychological behavior in traffic."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:26:00)",
                "text": "Well, the road rage thing."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:26:01)",
                "text": "The road rage, yeah. It’s fascinating."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:26:03)",
                "text": "And I bet that most, there again, those are all people who up to some point were cooperative and kind and polite, and then they snap. So those are all part of the human makeup as well."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:26:17)",
                "text": "But also part of the human makeup, difference between humans and chimps is the ability to get together, cooperate on a mass scale over an idea, create things like the Roman Empire did. Laws that prevent us and protect us from crazy human behavior, manifestations of a man, some type of human."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:26:39)",
                "text": "Well, human beings are just weird animals all year round. It’s just completely peculiar. I’m not sure that we’re all together natural."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:26:46)",
                "text": "But I think we are all together beautiful. There is something magical about humans, and I hope humans stay here even as we get advanced robots walking around everywhere. More and more intelligent robots that claim to have consciousness, that claim they love you, that increasingly take over our world. I hope this magical things that makes us human still persists."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:27:11)",
                "text": "Well, let us hope so."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:27:13)",
                "text": "Rick, you’re an incredible person. You have so much fascinating work, and it’s really an awesome."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:27:20)",
                "text": "I’ve never had anybody ask me as many interesting questions as you have."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:27:24)",
                "text": "Thank you so much."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:27:25)",
                "text": "Or as many questions."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:27:27)",
                "text": "This was so fun. Thank you so much for talking today."
            },
            {
                "speaker": "Rick Spence",
                "time": "(03:27:29)",
                "text": "Well, thank you."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(03:27:31)",
                "text": "Thanks for listening to this conversation with Rick Spence. To support this podcast, please check out our sponsors in the description. And now, let me leave you words from John F. Kennedy. “The very word secrecy is repugnant in a free and open society. And we are as a people, inherently and historically opposed to secret societies, to secret oaths, and to secret proceedings. We decided long ago that the dangers of excessive and unwarranted concealment of pertinent facts far outweighed the dangers which are cited to justify it.”"
            },
            {
                "speaker": "",
                "time": "(03:28:07)",
                "text": "Thank you for listening and hope to see you next time."
            }
        ]
    },
    {
        "title": "Bernie Sanders Interview",
        "guest": "Bernie Sanders",
        "thumbnail": "https://lexfridman.com/files/thumbs_ai_podcast/bernie_sanders.png",
        "video_link": "https://www.youtube.com/watch?v=MzkgWDCucNY",
        "episode_link": "https://lexfridman.com/bernie-sanders",
        "transcript_link": "https://lexfridman.com/bernie-sanders-transcript",
        "timestamps": [
            {
                "time": "0:00",
                "chapter": "Introduction"
            },
            {
                "time": "1:40",
                "chapter": "MLK Jr"
            },
            {
                "time": "4:33",
                "chapter": "Corruption in politics"
            },
            {
                "time": "15:50",
                "chapter": "Healthcare in US"
            },
            {
                "time": "24:23",
                "chapter": "2016 election"
            },
            {
                "time": "30:21",
                "chapter": "Barack Obama"
            },
            {
                "time": "36:16",
                "chapter": "Capitalism"
            },
            {
                "time": "44:25",
                "chapter": "Response to attacks"
            },
            {
                "time": "49:22",
                "chapter": "AOC and progressive politics"
            },
            {
                "time": "57:13",
                "chapter": "Mortality"
            },
            {
                "time": "59:20",
                "chapter": "Hope for the future"
            }
        ],
        "transcript": [
            {
                "speaker": "Bernie Sanders",
                "time": "(00:00:00)",
                "text": "The ideas that I am talking about are ideas that are widely supported. Everything that I talk about raising them, minimum wage, health care for all, a tax system which demands the billionaires pay their fair share, those are all popular ideas, but people didn’t know. You got to run for president and have 20,000 people come out to your rallies and win 23 states. They say, “Hmm. Well, maybe those ideas are not so crazy after all, and we’ve got to entertain them.” The establishment doesn’t like that. They really don’t. They want to tell you, and this is their main… This is how they succeed. What they say, Lex, is, “The world is the way it is. It always will be this way. We got the wealth. We got the power. And don’t think of anything else. This is the way it is. You have no power. Give up.” They don’t say it quite that way, but that’s really what the intent is."
            },
            {
                "speaker": "",
                "time": "(00:00:50)",
                "text": "And what we showed is, guess what? Running an outsider campaign, we took on the Democratic establishment, we came close to winning it, and we did win 23 states. And the ideas that we’re talking about are the ideas that working class people, young people believe in."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:01:10)",
                "text": "The following is a conversation with Bernie Sanders, senator from Vermont and two-time presidential candidate, both times as the underdog who, against the long odds, captivated the support and excitement of millions of people both on the left and the right. This is the Lex Fridman Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Bernie Sanders."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:01:40)",
                "text": "Growing up, did you ever think you’d be a politician?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:01:43)",
                "text": "Nope. Not in a million years."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:01:47)",
                "text": "Yeah. I know that you hate talking about yourself, which is rare for a politician, I would say. What’s your philosophy behind that? You like talking about the issues. You like talking about-"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:01:55)",
                "text": "Yeah, I do. Everybody talks about themselves. It’s not about me. Nice guy, not a nice guy. What politics should be about? Is the issues facing the people of our country, the people of the world, and how we’re going to address it. That’s what it should be."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:02:10)",
                "text": "That said, there’s a interesting aspects to your life story. For example, in 1963, you were very active in the Civil Rights Movement, got arrested even for protesting segregation in Chicago, and you attended the famous March on Washington where MLK gave his I Have a Dream speech. What was that like?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:02:30)",
                "text": "It was extraordinary. Took a bus ride down with fellow students in the University of Chicago, and there was a zillion people there. I’m not sure if it was the first time I’d ever been in Washington in my life, but it was a very impressive moment. And what he was talking about, people very often forget about that, it was not only racial justice, it was jobs. Jobs and justice, that was the name of that rally. And so it’s something I’ve never forgotten."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:02:59)",
                "text": "What influence did he have on you? What’d you learn about the way he enacted change in the world?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:03:06)",
                "text": "King was a very impressive guy, more impressive, I think, than people think that he was. And what he did is he created his movement from the bottom on up. So he developed real organization, grassroots organization which put pressure on communities and officials to end segregation, to open up voting patterns. And I think what has to also be remembered about King, which is really quite extraordinary, is he won the Nobel Peace Prize. And there was, oh, you’re great, you’re wonderful. But then to the end of his life, he took on Lyndon Johnson on the war in Vietnam. And as soon as he did that, suddenly the editorial pages throughout America, the establishment papers no longer thought he was so great. In fact, the message sent out, “You’re black. Deal with civil rights. Don’t worry about foreign policy. We’ll take care of that.” But he said, “If I talk about peace and nonviolence, I can’t sit back and allow what’s going on in Vietnam to continue without speaking out.”"
            },
            {
                "speaker": "",
                "time": "(00:04:12)",
                "text": "Incredible courage to do that. And by the way, when he was assassinated at a fighting for the rights of AFSCME workers, garbage, guys that delivered the garbage who were treated terribly, low wages, bad working conditions. And he went out to support their right to form a union. That’s when he got killed."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:04:33)",
                "text": "So on the war front, one of the things that people don’t often talk about, your work in politics. You gave what I think is a truly brave speech on the Iraq War in 2002, I believe. You voted no on the Iraq Resolution, you voted no on the Patriot Act, and you basically predicted very accurately what would happen if we go into Iraq. What was your thinking at the time behind those speeches, behind voting no on the Patriot Act on the Iraq Resolution?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:05:09)",
                "text": "It maybe ironically came out of maybe the war in Vietnam and the ease and lies that people told. We went into Vietnam under a lie. We lost close to 60,000 Americans. Millions of people in the Vietnam and Cambodia died as a result of that. So I think twice about it. And then the war in Iraq, you had people like Dick Cheney and others telling us, “Oh, they have nuclear weapons and all that stuff. It’s the only way we can resolve the issue.” I didn’t believe it. I didn’t agree with it. And you’re right, it turns out, historically, I was right."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:05:46)",
                "text": "What’s the way to fight this thing that Martin Luther King tried to fight, which is the military industrial complex?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:05:54)",
                "text": "It’s huge. It gets to the broader issue of where we are as a nation. And what I almost uniquely in Congress talk about is the fact that we are moving, Lex, to an oligarchic form of society. And not a lot of people are familiar with that term, but what it means… We talk about oligarchy in Russia. Oh, Putin is surrounded by the oligarchs. Well, guess what? What do you think is happening in the United States? So what you have right now is an economy with more concentration of ownership than we’ve ever had. All right? That means whether it’s agriculture, transportation, healthcare, whatever it may be, fewer and fewer massively large corporations control what’s produced and the prices we pay. And then you look at our political system, and we don’t talk about it. What is the reality of the political system today? And that is that billionaires are spending huge amounts of money to buy this election. In Trump’s campaign, you got three multi-billionaires spending over $200 million, three people. Democrats have their billionaires. It’s not quite as concentrated."
            },
            {
                "speaker": "",
                "time": "(00:06:55)",
                "text": "But at the end of the day, billionaires play an enormous role in terms of electing politicians and in Washington in determining what legislation gets seen and not seen."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:07:07)",
                "text": "But it’s not just single billionaires. It’s companies with lobbyists."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:07:10)",
                "text": "You got it. Let me give you one example, lobbyists. We pay, in the United States, by far the highest prices in the world for prescription drugs. This is an issue I’ve been working hard on with some success. Take a wild and crazy guess how many lobbyists are there from the drug companies in Washington D.C.?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:07:28)",
                "text": "Over a thousand."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:07:29)",
                "text": "Over a thousand. There are 100 members of the Senate, 435 members of the House, 535 members of Congress. There are 1800 well-paid lobbyists representing the drug companies, including former leaders of the Republican and Democratic Party. That is why, one of the reasons why we pay the highest prices in the world for prescription drugs. Military-industrial complex, you’ve got a revolving door. People go from the military into the General Dynamics, into Lockheed Martin, and the other large companies, and what we see there is an institution in the Pentagon. We spend a trillion dollars a year on the Pentagon. It is the only federal agency that is not able to submit to an independent audit. So if you think there’s not massive fraud and waste and cost overruns in the Pentagon, you would be sorely mistaken."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:08:22)",
                "text": "Do you think most politicians are corrupt in accepting the money, or is the system corrupt? Or is it a bit of both?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:08:30)",
                "text": "If the corrupt means that, “Hey, here’s $10,000, vote this way,” it doesn’t work like that. Very, very rare. Occasionally. Very, very rare. That’s corruption. What happens is that if you are in a campaign… And right now, the amount of money that people have to raise, you’re running for Senate in Ohio, you’re talking about 50, $60 million. Where the hell are you going to get that money? It’s not going to be $10 donations. You’re going to be surrounding yourself with people who have the money. You’re going to go $5,000 [inaudible 00:09:02], etc. So you surround yourself with those people who say, “Oh, these are my problems. This is what I need, and this is… I need a tax break for billionaires,” blah, blah, blah, blah. So you live in that world. They are your financial support."
            },
            {
                "speaker": "",
                "time": "(00:09:15)",
                "text": "They are, in a sense, your political base, so you’re very cognizant of what you do in terms of not upsetting them. So it’s not corruption in the sense of people taking envelopes with huge amounts of money to vote a certain way. That very, very rarely, if ever, happens. It is the power of big money to make politicians dependent on those folks. And that’s why when I ran for president, what I probably may be most proud of is the fact that we received millions and millions of campaign contributions averaging 27 bucks apiece, I think, in 2016."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:09:52)",
                "text": "Have companies, lobbyists ever tried to buy you, tried to influence you?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:09:56)",
                "text": "We don’t welcome them into our office. I do deal with these guys, but it’s usually on a confrontational tone. No, so they don’t come into my office very often telling me their problems."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:10:04)",
                "text": "So how do we fix the system? How do we get money out of politics?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:10:09)",
                "text": "Like many other issues, we don’t have to reinvent the wheel here. It exists in other countries. If you go to… Every country has their own election system, but nobody has a system where billionaires can spend unlimited sums of money through super PACs to elect the candidates of their choice. So first thing you got to do… One of the things, Lex, I found that the more important the issue, the less discussion there is. The less important the issue, the more discussion there is. A number of years ago, the United States Supreme Court, in one of its more pathetic decisions, passed the Citizens United decision. What Citizens United Decisions said is you’re a multi-billionaire. You want the freedom. You’re a free person in a free country. You want the freedom to buy the government, and how terrible it would be to deny you the freedom to spend hundreds of millions of dollars on a campaign to elect the candidates. And they said that’s your freedom, and that’s what Citizens United is about."
            },
            {
                "speaker": "",
                "time": "(00:11:10)",
                "text": "We’ve got to end that. And in my view, we move to public funding of elections. That means you want to run for governing, you want to run for Senate, show that you have some support, get $5 contributions from X number of people to show you you’re not a flake. You have some support and the government will pay a certain amount more, and there’ll be a limit in the amount of money that can be spent. So it’ll be a real… You can run against me and I’m not going to outspend you 10 to one. That’s what we should be moving toward in my view."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:11:39)",
                "text": "How do we make that happen when there’s so much money in the system and the politicians owe to the people who paid for their election? Does it have to come from the very top, essentially sort of a really strong, popular populist president?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:11:54)",
                "text": "But you’re right. You raised exactly the question. If I’m getting a huge amount of money from billionaires, do you think I’m going to go out and announce, “I think billionaires should not be involved in buying elections”? I doubt that very much. So what you’re going to need, and you tell me if I’m missing something, but I pay attention, you don’t hear either of the major candidates talking about that issue, do you?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:12:16)",
                "text": "I think what happens is when an individual politician speaks out about it, they get punished, but I think this is a popular idea. So if a lot of them speak out, that’s why if it came from the top, if a president was using a very large platform to basically speak out, it provides a safety blanket for the other politicians to get it out of the system. But there has to be kind of a mass movement of it."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:12:40)",
                "text": "Yes, it does. And every place I go, I always speak about the issue, and it always… People understand it. You’re a Republican, you’re a Democrat, you’re progressive, you’re conservative, who really believes that we are a democracy when billionaires can spend tens and tens of millions of dollars to buy elections? So it is a very popular issue. It’s important. You’re right. We need political leaders to be speaking out on that, but we need a grassroots movement to say, when somebody is at a town meeting, you’re running for the Senate, you’re running for the House, what’s your view on Citizens United? Are you prepared to vote to overturn that decision and move to public funding of elections? Extraordinarily important."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:13:18)",
                "text": "So many of your policy proposals are quite radical."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:13:23)",
                "text": "No, they’re not. I beg to differ."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:13:25)",
                "text": "Okay, great."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:13:26)",
                "text": "[inaudible 00:13:26]"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:13:27)",
                "text": "Well, they’re popular. So what I mean is relative to what the way other politicians speak, it’s usually a little bit more moderate. So from everything you’ve learned from politics, is it better to go sort of radical, maybe we can come up with a different word, versus a more moderate, safe, ambiguous kind of policies?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:13:45)",
                "text": "Okay, let’s talk about it. Fair enough. We talked about one issue, very important, money in politics."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:13:50)",
                "text": "Money, yes."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:13:51)",
                "text": "Getting big money out of politics, do you think that’s a radical idea?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:13:55)",
                "text": "Well, yeah. It’s a popular idea. It’s an idea that makes sense. But in order to implement it and actually make it happen, it requires to flip the system upside down, right? In that sense, it’s radical."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:14:09)",
                "text": "In that sense, it’s radical. But if you go walk down the street here and you say, “Do you think billionaires should be able to spend as much money as they want to buy politicians?” I would say nine out of 10 people will say, “That’s crazy. That’s not what America’s supposed to be about.” So in that sense, it’s certainly not radical. Let’s talk about healthcare. Go out on the street, do it, or do a poll, and I’ve done the polling, is healthcare a human right? Should every American be able to go to a doctor when they need, regardless of their income? Do you know what people say? I would say about 85, 90% of the people say, “Of course.” The idea that healthcare is a human right available to all exists, Lex, in every major country on earth except the United States. So you’re here with me in Burlington, Vermont, right?"
            },
            {
                "speaker": "",
                "time": "(00:14:55)",
                "text": "If you got a car, go 50 miles north to Canada, walk into Canada and ask people, “When you go to the hospital, how much does it cost you, which kind of bill?” And they say, “What are you talking about? Doesn’t cost us anything. It doesn’t cost us a nickel.” That’s the case in virtually every country in Europe. So the idea that healthcare should be available to all or that there should be no out-of-pocket expense because it’s a human right is widespread around the world and very much agreed to in this country. Bottom line is that because of our corrupt political system, we have a healthcare system designed not to provide healthcare to all people, to make huge profits for the drug companies and the insurance companies. And that is what’s happening, and we got to change that system. So I’m a strong advocate, and I’ve led the effort on Medicare for all."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:15:50)",
                "text": "Okay, let’s talk about Medicare for all. If you could snap your fingers today and implement the best possible healthcare system for the United States of America, what would that look like?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:16:01)",
                "text": "Well, we have a pretty good system."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:16:00)",
                "text": "What would that look like?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:16:01)",
                "text": "Well, we have a pretty good system, not great, but a pretty good system in Medicare. So it’s there for the elderly and Lyndon Johnson passed that in the 1960s, a huge step forward. It is being chopped away by the private insurance companies through Medicare Advantage. But if you strengthen Medicare and you do away with the kind of deductibles that seniors now have to pay and you do away with other stuff, and you say basically right now you’re a senior in America, go to any doctor you want when you’re in the hospital, Medicare will pay the entire bill if you expand Medicare to cover dental hearing and vision, which it doesn’t now cover. You do all of those things and then the next thing you do is say, okay, to be eligible for Medicare, now you have to be 65. First year we’re going to lower it to 55, then we’ll lower it to 45, then we’ll lower it to 35."
            },
            {
                "speaker": "",
                "time": "(00:16:52)",
                "text": "Then we’ll have everybody in the system. So I think in a four or five year period you can strengthen Medicare and have everybody in the system. And when you do that, and this is not just me talking, number of studies have pointed this out. When you take the profit motive out of it from the insurance companies and the drug companies, you can end up providing quality care to all people at no more than we’re spending right now. Because right now we are spending twice as much per personal healthcare as the people of any other nation. Incredibly wasteful system."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:17:23)",
                "text": "So the way to pay for the system is to increase taxes. But you’re saying if you cut that cost and increase the taxes you’re saying it’s going to-"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:17:31)",
                "text": "Here’s the story, and I’ve gotten my share of 30 second ads attacking me on this. Bernie Sanders wants to raise your taxes on healthcare. It’s true, in a progressive way. But right now, do you have health insurance?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:17:46)",
                "text": "Yes."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:17:46)",
                "text": "Okay. Somebody’s paying for your health insurance. It depends, if you are working, most people get their health insurance through their jobs, okay? So if you’re working for a large company, your employer is paying your health insurance, and by the way, that comes out of your wages. Healthcare costs in America are very high. And your employer will tell you, honestly, look, I can’t give you more than a 3% wage increase because I got a 10% increase in your healthcare costs. You want that? Or if you’re union negotiating, you know what? They’ll say, Hey, you want decent wages? We’re going to have to cut back on your healthcare. That’s what every union has to deal with every negotiating session. So we’re paying for it through employers out of pocket. We pay through it through Medicare, Medicaid, veterans Administration, et cetera. What I am proposing is really not radical. It’s what exists in Canada and other countries."
            },
            {
                "speaker": "",
                "time": "(00:18:34)",
                "text": "It is publicly funded like the police departments and libraries are like public education. This is publicly funded in a progressive way. So right now, rather than paying out of your own pocket, if you are a family, let’s just say you’re self-employed right now and you have a couple of kids and a wife, it could cost you 15, $20,000 a year in insurance costs. Well, that’s all eliminated. Will you have to pay more in taxes? Of course you will. Maybe it depends on your income level, but it could be that you’d be paying $12,000 more in taxes, but not $20,000 more in premiums, co-payments and deductibles, you save money. So it’s paying taxes rather than paying money to the insurance company. You got a better deal through the tax system."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:19:23)",
                "text": "So the most painful thing in today’s system is the surprise bills, the number one cause of bankruptcy and the psychological pain that comes from that, just worrying stress in debt."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:19:36)",
                "text": "You got it."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:19:36)",
                "text": "And just basically afraid constantly of getting sick because you don’t know if insurance is going to cover it. And if you’re not insured, you don’t know how much it’s going to cost. So you’re not going to go to the hospital even if there’s something wrong with you, if there’s pain and all that. So you just live in a state of fear, psychological fear. That’s the number one problem. It’s just not just financial, psychological-"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:19:55)",
                "text": "You got it. Look, and I think you said it very well. I’m chairman of the committee that deals with this stuff. So I talk to a lot of doctors. And doctors in Vermont and all over this country tell me that they’re astounded at people walk into their offices much sicker than they should have been. And the doctor said, why didn’t you come here six months ago when you first felt your symptoms? And they said, well, I have a high deductible. I’ve a $10,000 deductible. I don’t have any money to pay. I’m uninsured. Some of those people don’t make it. Other people, and this is what is totally crazy, they end up in the hospital at huge expense to the system rather than getting the care they need when they needed it. So that is how… I’ll give you another example of it. We pay the highest prices in the world for prescription drugs."
            },
            {
                "speaker": "",
                "time": "(00:20:46)",
                "text": "One out of four Americans can’t afford the drugs their doctors prescribe. So you walk into the doctor’s office, they say, okay, Look, you got this, that, and the other thing. Here’s a prescription. You can’t afford to fill it. What happens? You get sicker. You end up in the emergency room, which is an extremely expensive proposition. Or you end up in the hospital, rather than dealing with the problem when it occurs. And what is not talked about… I mentioned earlier how we don’t talk about some of the major issues. The estimate is that some 60,000 people in America die every single year unnecessarily because they can’t get to a doctor when they need because of financial reasons. And you want to hear even crazier, one out of four people who get cancer treatment in this country either go bankrupt or deplete their financial resources of their family."
            },
            {
                "speaker": "",
                "time": "(00:21:33)",
                "text": "So your point is, right. If somebody diagnoses you with cancer, you’re scared to death. You’re worried about how you’re going to live, you’re going to die, what’s going to happen? And then on top of that, you got to worry about whether your family goes bankrupt. How insane and cruel is that? So to me, I think healthcare is what unites us all. Everybody has family. They get sick, we all get born, we all die, we all want care. And we all have got to come together to create a system that works for all of us, not just the drug companies or the insurance companies."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:22:03)",
                "text": "There’s just so many stories and not even the horrific stories. There’s countless horrific stories, but just basic stories of cost. Like my friend Dr. Peter Attia has this story where he happens to be wealthy so he can afford it, but he had to take his son to the emergency room and the son was dehydrated and the bill was $6,000. They just did a basic test and gave him an IV, a basic thing. And he has really good insurance and the insurance covered $ 4,000 of it. So he had at the end paid $2,000 for a basic emergency room visit. And there’s a lot of families for whom that one visit for such a simple thing would be just financially devastating."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:22:43)",
                "text": "And you know what? People know that, and you know what they say? I don’t feel well today. Something’s wrong. I ain’t going to go to that emergency room because I don’t want a $6,000 bill. And what happens? He had insurance that paid two thirds of it, right?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:22:57)",
                "text": "Yes."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:22:58)",
                "text": "So what happens if he didn’t? What happens if he didn’t have money? He’d be handed by bill collectors for the rest of his life. So it is a disgusting system. It is an inhumane system, but the insurance companies and the drug companies are very powerful and they make a lot of campaign contributions, have a lot of lobbyists than we are where we are. But I think the American people want fundamental changes there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:23:21)",
                "text": "So that’s another good example of a really popular idea that is not implemented because of the money in politics."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:23:29)",
                "text": "You got it. That’s wonderful. And I’ll tell you that not only that, not only is it not implemented because of money, it’s not even discussed. All right? So I’m saying here and no one disputes me, we are spending twice as much per person on healthcare, right? And yet 85 million Americans are uninsured or underinsured, and our life expectancy is lower than virtually every other major country. Do you think that might be an issue that we’d be discussing?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:23:59)",
                "text": "Again, if a single politician discusses it to get punished for it. So there needs to be a mass movement and probably, I mean from my perspective, it has to come from the very top. It has to come from the president. And the president has to be a populist president where they don’t care about the parties with the rich people. They just speak out because they know it’s a popular message and they know it’s the right thing. So speaking of that, you had a historic campaign run for president in 2016, and in the eyes of many people, mine included, you were screwed over by the DNC, especially the WikiLeaks emails showed. What’s your just looking back feelings about that? And you’re angry, are upset?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:24:47)",
                "text": "Yeah, of of course I’m angry and of course I’m upset. But when you take on, in this case, the democratic establishment who have controlled that party forever, moneyed interests of the Democratic Party, you’re taking on corporate America when you’re taking on the corporate media. And when you’re calling for a political revolution that creates the government that works for all and not just the few, the opposition is going to be extraordinary. But what I am extremely proud of from that campaign in 2020 as well, is that we took on the anointed candidate of the establishment and we showed, despite the fact the entire establishment I had in the Senate, I had one supporter, there were 50 Democrats, I had one supporter, I had no governor supporting me. I think maybe a few people in the house."
            },
            {
                "speaker": "",
                "time": "(00:25:46)",
                "text": "But we took on the whole political establishment and we did… We got millions of votes. And the ideas that we brought forth were ideas that they had to eventually deal with in one way or another. And if you look at the American Rescue Plan, which I’m proud to have helped write during the midst of COVID, a lot of the ideas that we fought forward were implemented in that bill. And I want to make them obviously permanent."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:26:12)",
                "text": "And you almost won. And a lot of people thought that you would win against Donald Trump."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:26:17)",
                "text": "I think we would’ve. I think would’ve. Trump is a very… I think he’s a little bit crazy between you and me, but he is a smart politician. And he’s appealing to a lot of the anger that working class people feel. And you know what? Working class people should feel angry, but they should make sure that their anger is directed in the right direction and not against people who are even worse off the nail, which is what demagogues like Trump always do. So I think we had, as I went around the country then, and now we have a lot of support from working class people who understand that there is something wrong."
            },
            {
                "speaker": "",
                "time": "(00:26:57)",
                "text": "And this is an incredible fact that no one talks about. All right, I’m going to ask you a question. Are you ready for this Lex?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:27:02)",
                "text": "Let’s go."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:27:03)",
                "text": "Here we go. Over the last 50 years, there’s been a massive increase in worker productivity as a result of technology, right? Everyone agrees to that. And I don’t know exactly what is, but the worker today is producing a lot more than the work of 50 years ago doing something similar. Is the worker today in real inflation accounted for dollars making more money than that work 50 years ago?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:27:27)",
                "text": "Well, there’s a lot of close arguments there, but your point is well taken. It’s either the same or a little bit higher or a little bit lower, depending on the statistics. It has not increased significantly, and the wealth inequality has increased significantly."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:27:40)",
                "text": "That is the point. So you would think that if a worker is producing a lot more, that worker would be better off, would be working lesser hours, et cetera. That hasn’t been the case. And what happened in that 50 years is according to the RAND Corporation, there has been a 50 trillion, trillion with a T, redistribution of wealth in the bottom 90% to the top 1%. So you got CEOs today making 300 times more than their workers. You got three people on top owning more wealth on the bottom half of American society. So that’s why people are angry and they’re worried that their kids may have a lowest standard of living than they in the country in the history of the world. So there’s a lot of anger out there, and I think we tap some of that anger in a constructive way, essentially saying, you know what? We don’t need so few to have so much in wealth and power. Let’s distribute it more fairly in America."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:28:36)",
                "text": "I got to get back to 2016 because it’s such a historic moment. So there’s a lot of fans of yours that wanted you to keep fighting. Because you forgave in the end the establishment and joined them in support. And your fans wanted to keep fighting for a takeover, for a progressive takeover, the Democratic Party. If you just look back and had to do it all over again, what would you do different?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:29:02)",
                "text": "Well, by the way, in terms of a takeover of the Democratic Party, we did try, we ran… Do you know who Keith Ellison is? Keith is now the Attorney General of the state of Minnesota. He’s doing a great job. Really one of the outstanding attorneys generals in the country. And Keith was then a member of Congress and we ran Keith to become the head of the DNC and the establishment for the President of the United States on down went crazy. And they beat him by a few votes, not a whole lot. Look you faced… And that’s the exact same position that many of us are in right today. So people say, well, why did you support Hillary Clinton?"
            },
            {
                "speaker": "",
                "time": "(00:29:42)",
                "text": "Yeah, what’s the alternative? Donald Trump? I think Donald Trump is an extremely dangerous person trying to undermine American democracy. So I can’t support him. Hillary Clinton, obviously his views are very, very different than mine. But that in that moment, that’s where politics becomes really tricky and it ain’t easy. And sometimes you have to do things that you’re not really all that excited about. But I think it was right to try to do what I could to prevent Trump from getting elected. And in 2020 I did the same with Biden and we had more success with Biden than we had with Clinton."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:30:21)",
                "text": "Well, there’s this interesting story about a long time coming meeting between you and Obama in 2018, I believe. So Ari Rabin-Havt, who was a former deputy campaign manager, wrote a great book I would say about you called The Fighting Soul: On the Road with Bernie Sanders. And he tells many great stories, but one of them is your meeting with Obama. And he says that Obama told you, Bernie… I wish I could do a good Obama impression. Bernie, you’re an Old Testament prophet. A moral voice for our party giving us guidance. Here’s the thing though, prophets don’t get to be king. Kings have to make choices, prophets don’t. Are you willing to make those choices? Basically Obama’s making the case that you have to sort of moderate your approach in order to win. So was Obama right?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:31:14)",
                "text": "Look, and again, that’s why politics is very, very fascinating. Sometimes you can run and lose and you really win if your goal is not just individual power, but transforming society. One of my heroes, you mentioned Martin Luther King Jr. who is one of my heroes. Another one of my heroes is Eugene Victor Debs. Does that ring a bell?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:31:38)",
                "text": "Yeah. Yes."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:31:39)",
                "text": "Okay."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:31:40)",
                "text": "For many reasons, yes."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:31:41)",
                "text": "All right. Many listeners may not know who Debs was. Debs was a union organizer in the early 1900s, helped form the American Railway Union, ran for president, I think five times. Ran the last time while he was in a jail cell because of his opposition to World War I and got a million…"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:32:00)",
                "text": "… while he was in a jail cell because of his opposition to World War I and got a million votes doing that. Debs lost badly in every race that he ran. In 1932, Franklin Delano Roosevelt ran for president. And much of what Roosevelt ended up doing was at least some of what Debs had talked about. Debs helped lay the groundwork for ideas. So sometimes you can lose and win if you’re into transforming society. What my view is, where I disagree with Obama, is I think you have got to raise consciousness among ordinary people. And when people know what’s going on and are prepared in an organized way to fight for change, they can make incredible changes. And we’ve seen that in recent years. Today, we take for granted we have a woman running for president of the United States I’m supporting. We have had other women running for president."
            },
            {
                "speaker": "",
                "time": "(00:32:54)",
                "text": "We have women governors and senators. Not so many years ago in the United States Senate, there were 98 men, two women. Even before that 1920, it was when women got the right to vote. How did that change? How did women’s role in society change? It changed because women and their male allies stood up in force. Gay rights, old enough to remember that anybody I knew who was gay, you think they would talk about it? Come out about it? No they wouldn’t. That’s changed. We have seen in terms of civil rights, massive changes. Change happens when people at the grassroots level demand that… We talked about a healthcare a moment ago, we will get universal Medicare for all when millions of people make it clear that’s what they want. So I believe politics starts at the grassroots level, and that’s how you got to bring about change."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:33:42)",
                "text": "So just to go back to Obama though, in many ways, he too is a singular historic figure in American politics who has brought about a lot of change. He’s a symbol I think that would be remembered for a long time. What do you admire most about Obama?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:33:59)",
                "text": "Well, I know him. We’re not best friends, but I know him well and we chat every once in a while. First of all, don’t underestimate what it was in 2008 to be the first black president in the history of this country. And I think few would deny that he’s an extraordinarily intelligent guy. Very, very articulate, one of the best speakers that there is in America, and that he and his family, and again, it’s a lot harder than it looks. He and his family for eight years, that’s his wife Michelle and his kids, really held that office in a way that earned I think the respect of the American people, even if people disagreed him politically. So he deserves… And again, don’t underestimate. I think years ago there were people who said, “A black president in our lifetimes never going to happen. Can’t happen. Too racist the country.”"
            },
            {
                "speaker": "",
                "time": "(00:35:00)",
                "text": "He did it. And that is a huge accomplishment. And I think he has had some significant achievements in his presidential tenure. He and I did disagree on a number of issues. I think he will tell you, I think his public stance is that, yeah, if you have to start all over again, he would do Medicare for all single payer. But where we are right now, the best he could do is the Affordable Care Act. Well, we disagree on that and we disagree on other things, but I think he deserves an enormous amount of credit for what he has accomplished."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:35:36)",
                "text": "And he, like you, also gave a damn good speech opposing the Iraq war before running for president. And that takes courage."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:35:44)",
                "text": "Yes, it does."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:35:45)",
                "text": "But then it also shows that once you get into office, it’s not so easy to oppose or to work against the military industrial complex."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:35:53)",
                "text": "It is very hard. People do not fully appreciate how powerful the establishment is, whether it is the healthcare industry, whether it’s the military industrial complex, whether it’s the fossil fuel industry. These people have unlimited amounts of money. They’re very smart lobbyists in Washington D.C, and they’re very, very greedy people. They want it all."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:36:16)",
                "text": "I have to ask you about capitalism, the pros and cons. So you wrote a book, It’s Okay To Be Angry About Capitalism. That is a thorough, rigorous criticism of I would say hypercapitalism, a certain kind of capitalism that you argue that we are existing in today in the United States. But a lot of people would attribute to capitalism all the amazing technological innovations over the past 70 plus years that have contributed to increase in quality of life in GDP, decrease in poverty, decrease in infant mortality, increase in expected life expectancy. So how do you see the tension, the pros of capitalism and the cons of capitalism?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:37:09)",
                "text": "Some of my European friends, they say Bernie, in the United States, you’re considered to be very radical. If you were here in France or Denmark or someplace, you’d be kind of mainstream left guy. Not all that radical. So this is what I think. I mean, I think the best that we could do right now, where we are right now, it’s the great a society which does two things. It encourages innovation, but at the same time, it makes sure that all people in a wealthy nation have a decent standard of living. And some countries, if you look at Scandinavia, and this shocks people because we don’t talk about this at all. So in Scandinavia it has been the case, Denmark, Finland, Norway for years that people have healthcare. That’s not a big thing. You end up in the hospital. So what? They don’t pay a bill."
            },
            {
                "speaker": "",
                "time": "(00:38:01)",
                "text": "And this shocks people. In America right now, we have people who will get one week, two weeks off paid vacation. Sometimes people get nothing. You know that there are people out there who have vacation all. In Germany, you got six weeks paid vacation and other holidays as well. People are shocked by that. In America, we don’t have paid family and medical leave. The only major country not to do it. Other countries, your wife gets sick, you stay home with her, your kids get sick, not a big deal. You get a certain amount of paid family and medical leave. Cost of prescription drugs are far more affordable. So what you want to do is create what’s called a social safety net. That means I don’t care what your income is, of course you’re going to have healthcare is the human right. Of course you’re going to have housing that is affordable."
            },
            {
                "speaker": "",
                "time": "(00:38:51)",
                "text": "Of course your kids are going to have great quality education from child care to university without much cost. Every country has a little bit different. But there are countries in the world right now, I think in Germany, I think college is now tuition-free, as I recall, for obvious reasons. They want to have the best educated workforce they can. So in terms of government playing a role in a civilized democratic society of providing all basic needs, healthcare, education, housing, retirement benefits, yes, that is what we’ve got to do. Now, does that mean then that the government is going to run every mom and pop store on the corner? Of course not. You want innovation, you want to go out and start a business, produce a product, good luck to you. Make money. But on the other hand, in terms of even making money, we want you to be able to do that. Come up with good products, good services."
            },
            {
                "speaker": "",
                "time": "(00:39:46)",
                "text": "But do I think you should end up with $100 billion? No, I don’t. And you know what? It’s funny. I did an interview with Bill Gates, who’s I think the third-wealthiest guy in the country, struggling behind Musk and Bezos I think, and he’s only worth a hundred plus billion. But he gets by. And I said to him, “Bill,” he was supposed to ask me questions. I asked him the question, I said, “Bill, tell me something. You’re an innovator with Microsoft and all that stuff. Did you know that you’d become a multi-billionaire? And was that what motivated you?” And he said, “No.” And I believe he was honestly, “I loved doing whatever. I loved programming.” He was a kid. He started doing that. He loved it. He was motivated by it. Do you think that there are scientists out there who working day and night trying to develop drugs to deal with Alzheimer’s or cancer that they motivate? Boy, if I come up with this drug, I’m going to become a billionaire?"
            },
            {
                "speaker": "",
                "time": "(00:40:39)",
                "text": "So I think we want to reward success. Fine, but you don’t need a billion dollars. We want people to get satisfaction from what they accomplish, the work they’re doing, whether it’s cleaning the street or developing a new drug. So I think we have gone a little bit far, and you’re right, in talking about the book was an attack on I call, you call hypercapitalism or ubercapitalism. But right now, and this is not an American issue, this is a global issue. It’s not an accident that Musk is over there in Saudi Arabia talking to the trillionaire families in the mid-East, these guys, Putin and his friends, you got probably not more than five, 10,000 extraordinarily wealthy families who have unbelievable economic power over 7 billion people on this planet."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:41:24)",
                "text": "Well, Elon Musk is actually an interesting case because he’s investing all the money back into the businesses. So I think there is a balance to be struck and you just spoke to it, which is we can still celebrate even big companies that are bringing wealth to the world, that are building cool stuff, that are improving quality of life. But we can question of why is it that the working class does not have a living wage? In many cases, and sort of trying to find that balance."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:41:52)",
                "text": "That’s right. Look, I am no great fan of Elon Musk, especially in the role that he’s playing right now in Trump’s campaign. But is he a brilliant guy? Of course he is. Does he work like a dog? Of course he does. Does he come up with these incredible innovations in companies? Yes, he does. Does he deserve credit for that? Yeah, he does. But even in terms of encouraging innovation, I would hope that we are focusing on the important issues. I would love to see great innovators figure out how we build the affordable housing that we need, come up with the great drugs that we need to solve many of the terrible illnesses that plague people. Climate change for God’s sakes. All right, do we need innovation? We’re making some progress in this country. Should we do more? What kind of technologies out there can really cut back on carbon emissions?"
            },
            {
                "speaker": "",
                "time": "(00:42:41)",
                "text": "So I hope we focus on some of the most important issues that impact humanity, but reward innovators. I don’t have a problem with that, but I do have a problem when three people end up owning more wealth at the bottom half of American society."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:42:54)",
                "text": "Maybe you can briefly speak to something you tweeted recently about Donald Trump going to McDonald’s and the minimum wage, I believe of $7.50. Can you just speak to that tweet?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:43:05)",
                "text": "Look, nothing new. Trump didn’t invent it. It’s called a photo opportunity. I’ve done one or two in my life too. So you go to a place. He puts on an apron. Good old Donald Trump, just another McDonald’s worker. But anyhow, he was a… So fine, he did his photo op. That’s fine. Kamala Harris was in North Carolina handing out food to people who were victims of the hurricane. Fine. That’s what politicians do. But some reporter asked him, they said, “Mr. Trump, are you for raising the minimum wage?” And that was a fair question because you got, I don’t know how many, but many, many thousands of McDonald’s workers and millions of other American workers right now are trying to get by on 9, 10, 11 bucks an hour. Federal minimum wage is seven and a quarter. You have people working at McDonald’s right now for sure who are working with 12, 13 bucks an hour."
            },
            {
                "speaker": "",
                "time": "(00:43:55)",
                "text": "So the reporter said, what do you think about raising the federal minimum wage? And he’s, “Oh, these are great workers. I love McDonald’s and so forth.” He didn’t answer the question Well, I think that in the richest country in the history of the world, if you work 40 hours a week, you should not be living in poverty. And that means we should have a federal minimum wage, not absurdly seven and a quarter an hour, but in my view, $17 an hour. Will that solve all the economic problems for working-class people? No, it won’t. It’ll help. It’ll help."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:44:25)",
                "text": "Since running for president, you’ve often been attacked, especially from the right about being worth I believe $2 million and owning three houses. So from my perspective, the answer to that is most of your wealth has been earned from writing books and selling those books. And you are one of the most famous politicians in the world. And so your wealth in the context in comparison to other people of that fame level and other politicians is actually quite modest. So what’s your response usually to those attacks?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:44:59)",
                "text": "Do I own three residences? Yeah, I do. I live here in Burlington, Vermont. We live in a middle-class neighborhood. Nice house. Guess what? I’m a United States senator and I own a home in Washington DC as do most senators. You live there year after year. Actually when I was in Congress for 16 years, I rented all the time, but I got elected. Okay, got a six-year term. You know what? Let’s buy a house. So we bought a house and guess what? Like many thousands of people in the state of Vermont, I have a summer camp. It’s a nice one on Lake Champlain. That’s it. Now how did I get the money? You’re right. I wrote two best-selling books, including this book on capitalism. It was New York Times bestseller for a while. And also another book was a youth book. I make, I don’t know, $175,000 a year. And that’s more or less how I became the zillionaire that I am."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:45:57)",
                "text": "Well, I should also mention that sometimes the word mansion is used and I think your residences are quite modest, at least-"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:46:03)",
                "text": "Normal houses and they’re not… They’re middle-class houses. Very nice house."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:46:07)",
                "text": "So when you started in politics I read you are worth $1,100."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:46:12)",
                "text": "That much."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:46:13)",
                "text": "Yeah, that much. That’s right. Has the increase in wealth changed your ability to relate to the working class?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:46:20)",
                "text": "Well, it’s a good question. And obviously growing up in a working-class family has been maybe the most singularly significant aspect of my politics. I grew up without money in a family that lived in a rent controlled apartment in Brooklyn New York. So that has impacted me. I’ll tell you, I don’t really give a damn about money. I drive a car that’s 11 years old. It’s an old car and money… Here is my jewelry. It’s a solar watch and my wedding ring. That’s about it. I don’t have a Rolex watch, would not be interested in it. But I’ll tell you what has impacted me, my wife who also grew up in a working-class family will tell you the same. We don’t worry… You raise that issue. If we have to go to the doctor, if our kids have to go to the doctor, we go to the doctor."
            },
            {
                "speaker": "",
                "time": "(00:47:08)",
                "text": "I don’t stay up nights worrying. There was a time I have to worry about how to pay my electric bill. I don’t worry about that anymore. So what has happened that stress, that economic stress of not worrying about a financial disaster, that’s gone and that is enormous. I maybe as much or more than any other member of the Senate work hard not only for, but with working-class people. I’m chairman of the committee deals with labor issues. We have been involved probably in dozens of strikes all over this country. I’ve been on picket lines. So I do my best. It’s a very easy trap to fall into. You can get separated from ordinary people and their struggles. Not hard to do. I try as hard as I can not to do that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:47:53)",
                "text": "So sometimes people say, can money buy happiness? I think I agree with you that worry, sort of being able to fill up your car and not worry about how much it’s going to cost or be able to get a-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:48:00)",
                "text": "And not worry about how much it’s going to cost or be able to get food for dinner and not worry about how much it’s going to cost. Or even, I’ve been poor most of my life, but I’ve been very fortunate recently to have enough wealth to not worry about healthcare, to have insurance, and be able to afford an emergency room visit. And that worry is just such a giant lift off your shoulders."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:48:26)",
                "text": "Lex, I think you said it very well. I remember even I saw this change in myself. When I used to go out, and I do the grocery shopping. My wife does a lot of the cooking, I do the grocery shopping. And I used to look at the prices of everything, I do that less now. I said, “What the hell? So what? It costs 50 cents more for this can of stuff. So, what?” But that’s a luxury you have when you don’t have to worry about that. And I don’t have to worry about that."
            },
            {
                "speaker": "",
                "time": "(00:48:52)",
                "text": "But your point is, again, to me, I don’t like big fancy cars or big fancy homes, don’t go on… My wife will tell you we’ve not been on a real vacation for God knows how long, because I work pretty hard. But the major thing about having money, which is enormously important, is just what you said. I don’t have to worry. If somebody in my family gets sick, I don’t have to worry about that. I don’t have to worry about putting food on the table or paying the mortgage. So, that’s what money has done."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:49:21)",
                "text": "Okay. Let me ask you about the future of the Democratic Party. So one of the biggest impacts you’ve had is you’ve been in the fuel, the catalyst for the increase of the progressive caucus, the progressive movement within the Democratic Party. Do you think that is the future, the progressives, even Democratic socialist leaders will take over the party?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:49:42)",
                "text": "That is the most important question, regarding to my mind, American politics. One of the successes that we’ve had, and I’m proud to have played a role in this, is that if you go to the House of Representatives right now, you’ll see almost a hundred members of the Progressive Caucus led very well by a woman from Washington, Pramila Jayapal. Does a great job. That’s people like Alexandria Ocasio-Cortez and Ilhan Omar and many others. Many of them are young, often women, people of color. And many of them come from working-class backgrounds. So, what we have been able to do in recent years, elect a number of strong progressives who represent working families very, very effectively."
            },
            {
                "speaker": "",
                "time": "(00:50:27)",
                "text": "The struggle in the Democratic Party is between the corporate wing and the progressive wing. And the corporate wing takes a whole lot of money, sees its salvation in getting a whole lot of money from wealthy individuals and large corporations. And is not very vigorous in my view, in representing the needs of working-class people. If they were, we would have healthcare for all, we would have a minimum wage that was a living wage, we would not have a housing crisis. We would not have a tax system in which billionaires pay an effective tax rate that is lower than a truck driver or a nurse."
            },
            {
                "speaker": "",
                "time": "(00:51:11)",
                "text": "So, I think one of the reasons that Trump has had political success is, it’s not so much his ideas. Most working class people don’t think we should give tax breaks to billionaires or worry about the size of Arnold Palmer’s genitalia. But they are angry, people are angry. And the Democrats have not responded effectively to that anger. So, the struggle that we are waging right now is the future of the Democratic Party. Will it be a party of the working class and represent working class issues, whether you black or white or Latino or Asian or whatever you may be? Or will it be a corporately dominated party? That’s the struggle we’re in right now."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:51:49)",
                "text": "Did you consider running in 2024? From my perspective, I would’ve loved it if you ran. I think you would’ve had a great chance of winning. Not just the primary, but the presidency."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:52:00)",
                "text": "I gave about five minutes thought to it. And the reason was we have a slogan of the progressive movement, it’s not about me, it’s about us. And to have taken on Biden, who in my view on domestic issues, has been quite strong, would’ve really split the Democratic Party and laid the groundwork for an easy Trump victory. And that I did not want to see."
            },
            {
                "speaker": "",
                "time": "(00:52:25)",
                "text": "So sometimes in life, and I know that a lot of younger people don’t agree with me, but you got to make choices which are painful. So I strongly supported Biden, because I liked his domestic record. He’s done some good things against a lot of opposition. And I’m supporting Kamala right now. But I’m doing my best to see that a dangerous guy like Donald Trump does not become president."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:52:51)",
                "text": "And the hope for you is that there will be future candidates that are populist, that are progressive?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:52:56)",
                "text": "Yes, absolutely."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:52:57)",
                "text": "Let me ask you about AOC. She’s become one of the most influential voices for the progressive cause in the United States. You two had a great conversation on your podcast and in general, you work together. So, what to you is most impressive about her?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:53:12)",
                "text": "I really like Alexandria a whole lot. She is a young woman who comes from a working class background. She helped a mother clean houses. She was a bartender in the Bronx, New York. And I’m very proud that my campaign for president inspired her to run. And she ran on a progressive working class program. And she took on one of the more powerful guys, a guy named Joe Crowley, who was pretty high up in the Democratic Party. And she knocked on doors, she had no money. She did a very strong grassroots effort, and I appreciate that. So, that’s number one. I like what she stands for, she’s incredibly smart. And she has that certain charisma that maybe you’re born with it, maybe you develop it. I don’t know."
            },
            {
                "speaker": "",
                "time": "(00:54:05)",
                "text": "A couple of years ago she came up here to Vermont to spent some time. She and her partner, Riley, came up. And we were out in the street and people saw her and they said, “Oh, Congresswoman.” and she just smiled. And she had an approach to people, which was beautiful. I mean, it wasn’t phony, it was real. But to be a politician, you got to know how to… You could be a great intellectual, but you can’t relate to people. She relates well to people. And so, I think both from a personality perspective, from an intellect perspective, from an ideological perspective, she helped create the Green New Deal concept, the need to create jobs as we transform our energy system away from fossil fuel. Strong advocate for Medicare for all workers rights. So, I’m a big fan of Alexandria."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:54:53)",
                "text": "What do you think is the most powerful enduring impact you’ve had on American politics? Looking back, you’ve been in it for quite a bit."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:55:00)",
                "text": "Well, I don’t know that I can give you a singular answer. I was mayor of this city and proud of what we accomplished here, proud of my accomplishments as a U.S. Senator. When COVID was devastating this country and we had a massive economic downturn, as chairman of the budget committee, I helped write the American Rescue Plan, which put a lot of money into people’s pockets. We cut childhood poverty by 40% by providing a child tax credit. We kept hospitals going, we kept colleges going, kept people from getting evicted, helped get public health out there, people getting the vaccines. I’m proud of that."
            },
            {
                "speaker": "",
                "time": "(00:55:35)",
                "text": "But at the end of the day, I think what I have shown is that the ideas, gets back to the early part of this conversation, the ideas that I am talking about are ideas that are widely supported. So Donald Trump says, “Oh, Bernie Sanders is a far left.”, it’s like I’m some kind of extremist coming up with ideas that nobody supports. Everything that I talk about, raising the minimum wage, health care for all, a tax system which demands the billionaires pay their fair share, those are all popular ideas. But people didn’t know you got to run for president and have 20,000 people come out to your rallies and win 23 states. And they say, “Well, maybe those ideas are not so crazy after all.” And we’ve got to entertain them."
            },
            {
                "speaker": "",
                "time": "(00:56:20)",
                "text": "The establishment doesn’t like that. They really don’t. They want to tell you, and this is their main, this is how they succeed. What they say, Lex, is, “The world is the way it is. It always will be this way. We got the wealth, we got the power. And don’t think of anything else. This is the way it is. You have no power. Give up.” They don’t say it quite that way, but that’s really what the intent is."
            },
            {
                "speaker": "",
                "time": "(00:56:42)",
                "text": "And what we showed is, guess what? Running an outsider campaign, we took on the Democratic establishment, we came close to winning it. And we did win 23 states. And the ideas that we’re talking about are the ideas that working-class people, young people believe in."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:57:00)",
                "text": "Yeah, you showed that it’s possible to win. And that’s an idea that will resonate for decades to come."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:57:07)",
                "text": "And out of that came dozens of candidates now in the House of Representatives, people on city council, people on state legislature who did win."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:57:14)",
                "text": "So we mentioned about the worry of getting sick, the worry of life that many people in the working class are suffering from. But there’s also the worry that we all experience of the finiteness of life. Do you ponder your own mortality? Are you afraid of it?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:57:32)",
                "text": "Well, when you’re 83, it does come across."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:57:33)",
                "text": "All right."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:57:35)",
                "text": "Yeah, of course I do. And-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:57:36)",
                "text": "Are you afraid of it?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:57:37)",
                "text": "No, I’m not afraid of death. What I am afraid of, I think, is infirmity. I have been, knock on wood, this is wood, I think, reasonably healthy with an exception. I had a heart attack five years ago. And what blew me away was that my body failed me for the very first time in my life. That was stunning to me, that suddenly, I was in a hospital bed."
            },
            {
                "speaker": "",
                "time": "(00:58:02)",
                "text": "I have a great deal of compassion for people as we speak, who are in nursing homes, having a hard time walking. Maybe your mental agility is slipping a little bit. That’s tough. That’s what worries me. We are all going to die, and that’s that. So I’m not afraid of that, but that aspect of getting older, and that does concern me."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:58:27)",
                "text": "That said, your mind is as sharp as any politician that I’ve ever heard. And also just off mic, I should say, just the warmth that you radiate. And I deeply, deeply appreciate that-"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:58:28)",
                "text": "Oh, thank you."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:58:42)",
                "text": "… just as a human being. So, you still got it. After all that, after all those speeches, after all those houses, after all of it, there’s still the humility and just the sharpness, the wit is all there. So Bernie, yeah, like I said, I wish you would’ve ran this year, but I also wish that there’s future candidates."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:59:05)",
                "text": "Yeah. And there will be, Lex. I absolutely do. And I think you asked about my legacy, the idea that they’re all wonderful, really, really wonderful people who are now, got involved in the political process that are fighting for justice. That’s a great legacy."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:59:20)",
                "text": "What gives you hope about the future of this country, about the future of the world?"
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(00:59:24)",
                "text": "Sometimes one can become very cynical. You look at the terrible wars that are going on right now, you look at the divisiveness in this country, the ugliness, the poverty, you look at climate change. You can get depressed from all that. But I am lucky in this sense, in that I’ve had the opportunity… People often, “What inspires you? How do you keep going?” And I remember, actually it was in California where it really crystallized me. I was at a rally in the agricultural area of California. And we did a rally, it was sunset, thousands of people were out. And you looked around the crowd and there were young people, black and white and Latino and Asian American, huge cross section. There were older people, and they all wanted to make America a very much better country. And it really moved me."
            },
            {
                "speaker": "",
                "time": "(01:00:17)",
                "text": "I mean, I see that time and time, and I’ve just been on the campaign trail. And you see great people, really beautiful people who, not interested in becoming billionaires. They want to improve life for other people in this country. So, I am grateful that I… It sounds like a platitude. It’s what every politician says, oh, blah, blah, blah, blah. But when you go out around the country, you go to Native American reservations and you go to factories and everything, and you see so many wonderful people. I have been able to see things that many others have not. I’ve been to every state in the country, and that inspires me."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:00:55)",
                "text": "I share their optimism, I share your optimism. Bernie, I’ve been a fan for a long time. It’s a great honor to speak to you today. Thank you so much."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(01:01:02)",
                "text": "Well, thank you very much for what you’re doing. Let me just say a word about what you’re doing."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:01:06)",
                "text": "Okay. Let’s go."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(01:01:06)",
                "text": "Return the compliments here."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:01:09)",
                "text": "Okay."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(01:01:09)",
                "text": "I think there is a growing dissatisfaction with corporate media. And not because it’s fake news or the reporters lie all the time, that’s nonsense. They don’t. But I think people want to hear folks really talk about in a calm manner, about some of the very important issues which are not discussed in corporate media. And I think that’s what you and some others are doing. So, I thank you very much. It’s a very important service to the country."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:01:35)",
                "text": "And thank you from a mayor perspective, for creating a wonderful town. And I look forward to looking at the fall leaves walking around tonight."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(01:01:44)",
                "text": "Well, I did quite great the leaves. I did create some other things."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:01:47)",
                "text": "Okay. Thank you so much, Bernie."
            },
            {
                "speaker": "Bernie Sanders",
                "time": "(01:01:48)",
                "text": "Thank you, Lex."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:01:50)",
                "text": "Thanks for listening to this conversation with Bernie Sanders. To support this podcast, please check out our sponsors in the description."
            },
            {
                "speaker": "",
                "time": "(01:01:57)",
                "text": "And now, let me leave you with some words from Aristotle. ” The real difference between democracy and oligarchy is poverty and wealth. Wherever men rule by reason of their wealth, whether they be few or many, that is an oligarchy. And where the poor rule, that is democracy.” Thank you for listening and hope to see you next time."
            }
        ]
    },
    {
        "title": "Lost Civilization of the Ice Age & Ancient Human History",
        "guest": "Graham Hancock",
        "thumbnail": "https://lexfridman.com/files/thumbs_ai_podcast/graham_hancock.png",
        "video_link": "https://www.youtube.com/watch?v=NMHiLvirCb0",
        "episode_link": "https://lexfridman.com/graham-hancock",
        "transcript_link": "https://lexfridman.com/graham-hancock-transcript",
        "timestamps": [
            {
                "time": "0:00",
                "chapter": "Introduction"
            },
            {
                "time": "1:34",
                "chapter": "Lost Ice Age civilization"
            },
            {
                "time": "8:39",
                "chapter": "Göbekli Tepe"
            },
            {
                "time": "20:43",
                "chapter": "Early humans"
            },
            {
                "time": "25:43",
                "chapter": "Astronomical symbolism"
            },
            {
                "time": "37:11",
                "chapter": "Younger Dryas impact hypothesis"
            },
            {
                "time": "55:31",
                "chapter": "The Great Pyramid and the Sphinx of Giza"
            },
            {
                "time": "1:16:04",
                "chapter": "Sahara Desert and the Amazon rainforest"
            },
            {
                "time": "1:25:25",
                "chapter": "Response to critics"
            },
            {
                "time": "1:49:31",
                "chapter": "Panspermia"
            },
            {
                "time": "1:56:58",
                "chapter": "Shamanism"
            },
            {
                "time": "2:20:58",
                "chapter": "How the Great Pyramid was built"
            },
            {
                "time": "2:28:17",
                "chapter": "Mortality"
            }
        ],
        "transcript": [
            {
                "speaker": "Graham Hancock",
                "time": "(00:00:00)",
                "text": "The big question for me in that timeline is why didn’t we do it sooner? Why did it take so long? Why did we wait until after 12,000 years ago, really after 10,000 years ago to start seeing the beginnings of civilization?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:00:15)",
                "text": "The following is a conversation with Graham Hancock, a journalist and author who for over 30 years has explored the controversial possibility that there existed a lost civilization during the last ice age and that it was destroyed in a global cataclysm some 12,000 years ago. He is the presenter of the Netflix documentary series, Ancient Apocalypse, the second season of which has just been released and it’s focused on the distant past of the Americas."
            },
            {
                "speaker": "",
                "time": "(00:00:46)",
                "text": "A topic I recently discussed with the archeologist Ed Barnhart. Let me say that Ed represents the kind of archeologist scholar I love talking to on the podcast, extremely knowledgeable, humble, open minded, and respectful in disagreement. I’ll do many more podcasts on history, including ancient history. Our distant past is full of mysteries, and I find it truly exciting to explore those mysteries with people both on the inside and the outside of the mainstream in the various disciplines involved. This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Graham Hancock."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:01:34)",
                "text": "Let’s start with a big foundational idea that you have about human history. That there was an advanced Ice Age civilization that came before and perhaps seeded what people now call the sixth cradles of Civilization, Mesopotamia, Egypt, India, China, Indies, and Mesoamerica. So let’s talk about this idea that you have. Can you at the highest possible level describe it?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:01:57)",
                "text": "It would be better to describe it as a foundational sense of puzzlement and incompleteness in the story that we are taught about our past, which envisages more or less, there have been a few ups and downs, but more or less a straightforward evolutionary progress. We start out as hunter-foragers, then we become agriculturalists. The hunter-forager phase could go back hundreds of thousands of years. I mean, this is where it is also important to mention that anatomically modern humans, and we’re not the only humans. We had Neanderthals from, I don’t know, 400,000 years ago to about 40,000 years ago. They were certainly human because anatomically modern humans interbred with them. And we carry Neanderthal genes. There were the Denisovans maybe 300,000 to perhaps even as recently as 30,000 years ago. And again, interbreeding took place. They’re obviously a human species. So we’ve got this background of humans who didn’t look quite like us."
            },
            {
                "speaker": "",
                "time": "(00:03:08)",
                "text": "And then we have anatomically modern humans. And I think the earliest anatomically modern human skeletal remains are from Jebel Irhoud in Morocco and date to about 310,000 years ago. So the question is what were our ancestors doing after that? And I think we can include the Neanderthals and the Denisovans in that general picture. And why did it take so long? This is one of the puzzles, one of the questions that bother me. Why did it take so long? When we have creatures who are physically identical to us, we cannot actually weigh and measure their brains. But from the work that’s been done on the crania, it looks like they had the same brains that we do with the same wiring. So if we’ve been around for 300,000 plus years at least, and if ultimately in our future was the process to create civilization or civilizations, why didn’t it happen sooner?"
            },
            {
                "speaker": "",
                "time": "(00:04:07)",
                "text": "Why did it take so long? Why was it such a long time? Even the story of anatomically modern humans has kept on changing. I remember a time when it was said that there hadn’t been anatomically modern humans before 50,000 years ago, and then it became 196,000 years ago with the findings in Ethiopia and then 310,000 years ago. There’s a lot of missing pieces in the puzzle there. But the big question for me in that timeline is why didn’t we do it sooner? Why did it take so long? Why did we wait until after 12,000 years ago, really after 10,000 years ago to start seeing what are selected as the beginnings of civilization in places like Turkey, for example. And then there’s a relatively slow process of adopting agriculture. And by 6,000 years ago, we see ancient Sumer emerging as a civilization. And we’re then in the pre-dynastic period in ancient Egypt as well 6,000 years ago, beginning to see definite signs of what will become the dynastic civilization of Egypt about 5,000 years ago."
            },
            {
                "speaker": "",
                "time": "(00:05:21)",
                "text": "And interestingly round about the same time, you have the Indus Valley civilization popping up out of nowhere. And by the way, the Indus Valley civilization was a lost civilization until the 1920s when railway workers accidentally stumbled across some ruins. I’ve been to Harappa and Mohenjo-Daro, and these are extraordinarily beautifully centrally planned cities. Clearly they’re the work of an already sophisticated civilization. One of the things that strikes me about the Indus Valley Civilization is that we find a steatite seal of an individual seated in a recognizable yoga posture. And that seal is 5,000 years old, and the yoga posture is Mulabandhasana, which involves a real contortion of the ankles and twisting the feet back. It’s an advanced yoga posture. So there it is, 5,000 years ago. And that then raises the question, well, how long did yoga take to get to that place when it was already so advanced 5,000 years ago?"
            },
            {
                "speaker": "",
                "time": "(00:06:24)",
                "text": "What’s the background to this? China, the Yellow River Civilization again, it’s around about the same period, five to 6,000 years ago. You get these first signs of something happening. So it’s very odd that all around the world we have this sudden upsurge of civilization about 6,000 years ago, preceded by what seems like a natural evolutionary process that would lead to a civilization. And yet certain ideas being carried down and manifested and expressed in many of these different civilizations. I just find that that whole idea very puzzling and very disturbing, especially when I look at this radical break that takes place in not just the human story, but the story of all life on Earth, which was the last great cataclysm that the Earth went through, which was the Younger Dryas event. It was an extinction level event. That’s when all the great megafauna of the Ice Age went extinct."
            },
            {
                "speaker": "",
                "time": "(00:07:28)",
                "text": "It’s after that. It’s after event that we start seeing this what had taken to be the beginnings of the first gradual steps towards civilization, we come out of the upper Paleolithic as it’s defined the end of the old Stone Age and into the Neolithic. And that’s when the wheels are supposedly set in motion to start civilization rolling. But what happened before that and why did that suddenly happen then? And I can’t help feeling, and I’ve felt this for a very long while, that there are major missing pieces in our story. It’s often said that I’m claiming to have proved that there was an advanced lost civilization in the Ice Age. And I am not claiming to have proved that. That is a hypothesis that I’m putting forward to answer some of the questions that I have about prehistory. And I think it’s worthwhile to inquire into those possibilities because the Younger Dryas event was a massive global cataclysm, whatever caused it."
            },
            {
                "speaker": "",
                "time": "(00:08:32)",
                "text": "And it’s strange that just after it we start seeing these first signs."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:08:39)",
                "text": "So the current understanding in mainstream archeology is that after the Younger Dryas is when the civilizations popped up in different places of the globe with a lot of similarities, but they popped up independently."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:08:54)",
                "text": "Independently. And by coincidence. And by coincidence, those big civilizations that we all remember as the first civilizations, Sumer, Egypt, the Indus Valley Civilization, China, they all pop up at pretty much the same time. That is the mainstream view."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:09:10)",
                "text": "And they don’t just pop up, they kind of build up gradually. First there’s some settlements."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:09:15)",
                "text": "Oh, definitely, yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:09:16)",
                "text": "And then there’s different dynamics of how they build up and the role of agriculture. And that is also non-obvious, but it’s just there’s first a kind of settlement, a stabilization of where the people are living. Then they start using agriculture, then they start getting urban centers and that kind of stuff."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:09:33)",
                "text": "It seems like an entirely reasonable argument. Everything about that makes sense. There is no doubt that you’re seeing evolutionary progress, social evolution taking place in those thousands of years before Sumer emerges. But what’s happening now, really, I spent much of the nineties and the late 1980s investigating this issue of a lost civilization. I wrote a series of books about it. But by 2002 when I published a book called Underworld, which was the most massive and most heavy book that I’ve ever written, because I was writing very defensively at the time. By the time I finished that book, my wife Santha and I spent seven years scuba diving all around the world looking for structures underwater, often led by local fishermen or local divers to anomalies that they’d seen underwater. By the time that book was finished, I thought, actually, I’ve done this story. I’ve walked the walk."
            },
            {
                "speaker": "",
                "time": "(00:10:26)",
                "text": "I really don’t have much more to say about it. And I turned in another direction and I wrote a book called Supernatural Meetings With the Ancient Teachers of Mankind recently retitled Visionary. And that was about the role of fundamentally about the role of psychedelics in the evolution of human culture. And I didn’t think that I would go back to the lost civilization issue, but Göbekli Tepe in Turkey kept on forcing itself upon me the more and more discoveries there, the 11,600 year date from Enclosure D, which is the two largest megalithic pillars. And I reached a point where I realized I have to get back in the water and I have to investigate this again. And Göbekli Tepe was a game changer, but I think it’s a game changer for everything because Göbekli Tepe, the extraordinary nature of it. We are looking at a major megalithic site, which is at least five and a half thousand years older than Ġgantija in Malta, which was previously considered to be the oldest megalithic site in the world."
            },
            {
                "speaker": "",
                "time": "(00:11:32)",
                "text": "And this led of course to a huge amount of interest and attention, both from the Turkish government who see the potential tourism potential of having the world’s oldest megalithic site and from archeologists. And this in turn has led to exploration and excavation throughout the region. And what they’re finding throughout that whole region around Göbekli Tepe and going down into Syria and further down into the Jordan Valley as far as Jericho and even across a bit of the Mediterranean into Cyprus, is what Turkish archeologists are now calling the Taş Tepeler civilization. They’re calling it a civilization, the Stone Hills Civilization with very definite identifying characteristics, semi-subterranean circular structures, the use of T-shaped megalithic pillars, sometimes not anywhere near as big as those at Göbekli Tepe. It’s clear that Göbekli Tepe now was not the beginning of this process. It was actually in a way, the end of this process."
            },
            {
                "speaker": "",
                "time": "(00:12:33)",
                "text": "It was the summation of everything that Stone Hills Civilization had achieved. But what is becoming clear is that this is a period between before the foundation of Göbekli Tepe, as far as we know, that date of 11,600 years ago is the oldest date for Göbekli Tepe. But of course there’s a lot of Göbekli Tepe still underground, so we can’t say for sure that that’s the oldest, but it’s the oldest so far excavated. What we’re seeing is that in that whole region around there, there was something was in motion and it began to go into motion round about the beginning of the Younger Dryas. And this is where these two dates are really important. The Younger Dryas, I’ll round the figures off, begins around 12,800 years ago, and it ends around 11,600 years ago."
            },
            {
                "speaker": "",
                "time": "(00:13:24)",
                "text": "So Göbekli Tepe’s construction date, if it is 11,600 years ago, if they don’t find older materials, marks the end of the Younger Dryas, but the beginning of the Younger Dryas, we are already seeing the stirrings of the kind of culture that manifests in full form at Göbekli Tepe and after the construction of Göbekli Tepe, in fact, even during the construction of Göbekli Tepe, we see agriculture beginning to be adopted. The people who created Göbekli Tepe were all hunter-foragers at the beginning. But by the time Göbekli Tepe was finished, and it was definitely deliberately finished, closed off, closed down, deliberately buried, covered with earth, covered with rubble, and then topped off with a hill, which is why Göbekli Tepe is called what it is, Göbekli Tepe means pot-bellied hill or the hill of the navel. For a long time, Göbekli Tepe was thought to be just a hill that looked a bit like a pot belly."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:14:29)",
                "text": "You say how it was discovered, I think this is one of the most fascinating things on Earth, period. So maybe can you say what it is and how it was discovered?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:14:37)",
                "text": "Well, Göbekli Tepe is first of all the oldest fully elaborated megalithic site that we know of anywhere in the world. It doesn’t mean that older ones won’t be found, but it is the oldest so far found. The part of the site that’s been excavated, which is a tiny percentage of the whole site. We do know. My first visit to Göbekli Tepe was in 2013, and Dr. Klaus Schmidt, the late Dr. Klaus Schmidt, who died a year later, was very generous to me and showed me around the site for over a period of three days. And he explained to me that they’ve already used ground penetrating radar on the site, and they know that there’s much more Göbekli Tepe still underground. So anything is possible in terms of the dating of Göbekli Tepe. But what we have at the moment is a series of almost circular, but not quite circular enclosures, which are walled with relatively small stones."
            },
            {
                "speaker": "",
                "time": "(00:15:34)",
                "text": "And then inside them you have pairs of megalithic pillars. And the archetypal part of that site is Enclosure D, which contains the two largest upright megaliths, about 18 feet tall and reckoned to weigh somewhere in the range of 20 tons, if I have my memory correct, they’re substantial hefty pieces of stone. It isn’t some kind of extraordinary feat to create a 20 foot tall or 20 ton megalith, nor is it an extraordinary feat to move it. There’s nothing magical or really weird about that. Human beings can do that and always have, besides the quarry for the megaliths is right there. It’s within 200 meters of the main enclosures. So that’s not a mystery, but the mystery is, the mystery is why suddenly this new form of architecture, this massive, massive megalithic pillars appear, and the pillars, one of the things that interests me about the pillars is their alignment."
            },
            {
                "speaker": "",
                "time": "(00:16:36)",
                "text": "And there is good work that’s been done, which suggests that Enclosure D aligns to the rising of the star Sirius. And the rising points of the star Sirius appear to be mapped by the other enclosures, which are all oriented in slightly different directions. It was the work entirely of hunter-foragers. But by the time Göbekli Tepe was completed, agriculture was being introduced and was taking place there. Now you asked how Göbekli Tepe was found. The answer to that is that there was a survey of that pot-bellied hill in the 1960s by some American archeologists, and they were looking absolutely looking for Stone Age material, for material from the Paleolithic. And they had found some Paleolithic flints, upper Paleolithic flints around there. So it looked like a good place to look. But then they noticed sticking out of the side of the hill, some very finely cut stone, bits of very large and very finely cut stone."
            },
            {
                "speaker": "",
                "time": "(00:17:38)",
                "text": "And looking at that, the workmanship was so good that those archeologists were confident that it had nothing to do with the Stone Age, and they thought they were looking at perhaps some Byzantine remains, and they abandoned the site and never looked at it further. And it wasn’t until the German Archaeological Institute got involved, and particularly Klaus Schmidt, who I think was a genius, had real insight into this and started to dig at Göbekli Tepe that they’d realized what they’d found, that they’d found potentially the oldest megalithic site in the world. And they’d found it at a place where agriculture, according to the established historical timeline, that’s where agriculture, at any rate in Europe and Western Asia begins. It begins in Anatolia, in Turkey, and then it gradually disseminates westward from there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:18:27)",
                "text": "And yet the understanding is it was created by hunter-gatherers."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:18:31)",
                "text": "It was created by hunter-gatherers. Yeah, there was no agriculture 11,600 years ago in Göbekli Tepe. But by the time Göbekli Tepe was decommissioned, and I use that word deliberately, was closed down and buried. Agriculture was all around it. And this was agriculture of people who knew how to cultivate plants."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:18:54)",
                "text": "Do we have an understanding when it was turned into a, if I could say a time capsule so protected by forming a mound around it?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:18:54)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:19:04)",
                "text": "Is it around that similar time?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:19:05)",
                "text": "It stood from roughly 11,600 years ago to about 10,400 years ago to about 8,400 BC. So around 1200 years it was there, and it continued to be elaborated as a site. And while it was being elaborated as a site, we see agriculture, I’m going to use the word being introduced, there’d been no sign of it before, and suddenly it’s there. And to me, that’s another of the mysteries about Göbekli Tepe. And then with the new work that’s being done, we realize that it’s part of a much wider phenomenon which spreads across an enormous distance. And the puzzling thing is that after Göbekli Tepe there almost seems to be a decline. Things fall down again, and then we enter this long, slow process of the Neolithic, thousands of years, gradual developments until we come to ancient Sumer and Mesopotamia."
            },
            {
                "speaker": "",
                "time": "(00:20:02)",
                "text": "But agriculture has taken a firm root by then. Actually, one other thing, I’ll just say this in passing. When I talk about a lost civilization introducing ideas to people, I’m often accused of stealing credit from the indigenous people who had those ideas in the first place. So I do find it slightly hypocritical that archeology fully accepts that the idea of agriculture was introduced to Western Europe from Turkey, and that Western Europeans didn’t invent agriculture. It was absolutely introduced by Anatolian farmers who traveled west. So the notion of dissemination of ideas perhaps shouldn’t be so annoying to archeologists as it is."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:20:43)",
                "text": "And perhaps we should also state, if we look at the entirety of history of hominids, humans or hominids have been explorers. I didn’t even know this when I was preparing for this. Looking at Homo erectus 1. 9 million years ago."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:21:01)",
                "text": "Absolutely."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:21:01)",
                "text": "Almost right away they spread out through the whole world and we, Homo sapiens evolved from them. And we should also mention, since we’re talking about controversial debates going on, as I understand there’s still debates about the dynamics of all that was going on there. Like we mentioned in Africa that I think the current understanding, we didn’t come from one particular point of Africa, that there’s multiple locations."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:21:29)",
                "text": "This is the Out of Africa theory. I think it’s more than a theory. It’s really strongly evidenced. Why? Because we’re part of the Great Ape family and it’s an African family."
            },
            {
                "speaker": "",
                "time": "(00:21:39)",
                "text": "There’s no doubt that human beings, our deep origins are in Africa. But then as you rightly say, there were these very early migrations out of Africa by species that are likely ancestral to anatomically modern humans, including definitely Homo erectus and the astonishingly distant travels that they undertook. Yes, I think there is an urge to explore in all of humanity. I think there is an urge to find out what’s around the next corner, what’s over the brow of the next hill. And I think that goes very deep into human character. And I think it was being manifested in those early adventures of people who left Africa and traveled all around the world and then settling in different parts of the world. I think a lot of anatomically modern human evolution took place outside Africa as well, not only in Africa."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:22:32)",
                "text": "So I guess the general puzzlement that you’re filled with is given that these creatures explore and spread and try out different environments, why did it take hundreds of thousands of years for them to develop complicated society settlements?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:22:51)",
                "text": "That’s the first big question. Why did it take so long? And that raises in my mind a hypothesis, a possibility. Maybe it didn’t take so long. Maybe things were happening that we haven’t yet got hold of in the archeological record, which await to be discovered. And of course, there are huge parts of the world that have not been studied at all by archeology, but the fact that huge parts of the world have not been studied at all by archeology is not on its own enough to suggest that we’re missing a chapter in the human story. The reason that I come to that isn’t only puzzlement about that 300,000 year gap. It’s also to do with the fact that there’s common iconography. There’s common myths and traditions, and there’s common spiritual ideas that are found all around the world, and they’re found amongst cultures that are geographically distant from one another and that are also distant from one another in time."
            },
            {
                "speaker": "",
                "time": "(00:23:53)",
                "text": "They don’t necessarily occur at the same time. And this is where I think that archeology is perhaps desperately needing a history of ideas as well as just a history of things. Because an idea can manifest again and again throughout the human story. So there are particular issues, for example, the notion of the afterlife, destiny of the soul, what happens to us when we die? And believe me, when you reach my age, that’s something you do think about what happens. I used to feel immortal when I was in my forties, but now that I’m 74, I definitely know that I’m not. Well, it would be natural for human beings all around the world to have that same feeling, that same idea. But why would they all decide that what happens to the soul after death is that it makes a leap to the heavens, to the Milky Way, that it makes a journey along the Milky Way, that there it is confronted by challenges, by monsters, by closed gates."
            },
            {
                "speaker": "",
                "time": "(00:24:54)",
                "text": "The course of the life that that person has lived will determine their destiny in that afterlife journey. And this idea, the path of souls, the Milky Way is called the path of souls. It’s very strongly found in the Americas right from South America through Mexico, through into North America. But it’s also found in ancient Egypt, in ancient India, in ancient Mesopotamia, the same idea. And I don’t feel that that can be a coincidence. I feel that what we are looking at is an inheritance of an idea, a legacy that’s been passed down from a remote common source to cultures all around the world, and that has taken on a life of its own within those cultures. So the remote common source would explain both the similarities and the differences in the expression of these ideas. The other thing, very puzzling thing, is the sequence of numbers that are a result of the precession of the equinoxes."
            },
            {
                "speaker": "",
                "time": "(00:25:54)",
                "text": "At least I think that’s the best theory to explain them. Here, I think it’s important to pay tribute to the work of Giorgio de Santillana and Hertha von Dechend. Giorgio de Santillana was professor of history of science actually at MIT, where you are based, back in the sixties. And Hertha von Dechend was professor of the history of science at Frankfurt University, and they wrote an immense book in the 1960s called Hamlet’s Mill, and Hamlet’s Mill differs very strongly from established opinion on the issue of the phenomenon of precession. And I’ll explain what precession is in a moment. Generally, it’s held that it was the Greeks who discovered the precession and the dating on that is put back not very far, maybe 2,300 years ago or so. Santillana and von Dechend are pointing out that knowledge of precession is much, much older than that, thousands of years older than that."
            },
            {
                "speaker": "",
                "time": "(00:26:58)",
                "text": "And they do actually trace it. I think I’m quoting them pretty much correctly to some almost unbelievable ancestor civilization. Reading that book was one of the several reasons that I got into this mystery in the first place. Okay, now, the precession of the equinoxes, to give it its full name, results from the fact that our planet is the viewing platform from which we observe the stars. And our planet, of course, is rotating on its own axis at roughly a thousand miles an hour at the equator. But what’s less obvious is that it’s also wobbling on its axis. So if you imagine the extended North Pole of the earth pointing up at the sky in our time, it’s pointing at the star Polaris, and that is our pole star. But Polaris has not always been the pole star precisely because of this wobble on the axis of the Earth."
            },
            {
                "speaker": "",
                "time": "(00:27:52)",
                "text": "Other stars have occupied the pole position, and sometimes the extended North Pole of the earth points at empty space. There is no pole star. That’s one of the obvious results of the wobble on the Earth’s axis. The other one is that there are 12 well-known constellations in our time, the 12 constellations of the zodiac that lie along what is referred to as the path of the sun. The earth is orbiting the sun, and we are seeing what’s behind it, what’s in direct line with the sun in our view. And the zodiacal constellations all lie along the path of the sun. So at different times of the year, the sun will rise against the background of a particular zodiacal constellation. Today we live in the age of Pisces, and it’s definitely not an accident that the early Christians used the fish as their symbol. This is another area where I differ from archeology."
            },
            {
                "speaker": "",
                "time": "(00:28:46)",
                "text": "Think the constellations of the zodiac were recognized as such much earlier than we suppose. Anyway, to get to the point, the key marker of the year, certainly in the northern hemisphere, was the spring equinox. The question was, what constellation is rising behind the sun? What constellation is housing the sun at dawn on the spring equinox? Right now it’s Pisces. In another 150 years or so, it’ll be Aquarius. We do live in the dawning of the age of Aquarius. Back in the time of the late ancient Egyptians, it was Aries going back to the time of Ramesses or before. Before that it was Taurus and so on and so forth. It’s backwards through the zodiac until 12,500 years ago. You come to the age of Leo when the constellation of Leo houses the sun on the spring equinox. Now this process unfolds very, very, very, very slowly, the whole cycle, and it is a cycle."
            },
            {
                "speaker": "",
                "time": "(00:29:47)",
                "text": "It repeats itself roughly every 26,000 years. Put a more exact figure on it, 25,920 years. That may be a convention. Some scholars would say it was a bit less than that, a bit more. But you’re talking fractions. It’s in that area, 25,920 years. And to observe it, you really need more than one human lifetime because it unfolds very, very slowly at a rate of one degree every 72 years. And the parallel that I often give is hold your finger up to the horizon, the distant horizon. The movement in one lifetime, in a period of 72 years is about the width of your finger. It’s not impossible to notice in a lifetime, but it’s difficult. You’ve got to pass it on. And what seems to have happened is that some ancient culture, the culture that Santillana and von Dechend call some almost unbelievable ancestor culture, worked out the entire process of precession and selected the key numbers of precession, of which the most important number, the governing number is the number 72. But we also have numbers related to the number 72. 72 plus 36 is 108, 108 divided by two."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:31:00)",
                "text": "… 36 is 108. 108 divided by two is 54. These numbers are also found in mythology all around the world. There were 72 conspirators who were involved in killing the god Osiris in Ancient Egypt and nailing him up in a wooden coffer and dumping him in the Nile. There are 432,000 in the Rigveda. 432,000 is a multiple of 72."
            },
            {
                "speaker": "",
                "time": "(00:31:32)",
                "text": "And at Angkor, in Cambodia, for example, you have the bridge to Angkor Thom. And on that bridge you have figures on both sides, sculpted figures, which are holding the body of a serpent. That serpent is Vasuki, and what they’re doing is they’re churning the milky ocean. It’s the same metaphor of churning and turning that’s defined in the story of Hamlet’s Mill, of Amlodhi’s mill. There are 54 on each side. 54 plus 54 is 108. 108 is 72 plus 36. It’s a precessional number according to the work that Santillana and von Dechend did."
            },
            {
                "speaker": "",
                "time": "(00:32:13)",
                "text": "And the fascination with this numbers system and its discovery all around the world is one of the puzzles that intrigue me. And suggest to me that we are looking at ancestral knowledge that was passed down, and probably was passed down from a specific single common source at one time, but then was spread out very widely around the world."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:32:37)",
                "text": "One of the defining ways that you approach the study of human history that I think contrasts with mainstream archeology is that you take this astronomical symbolism and the relationship between humans and the stars very seriously."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:32:55)",
                "text": "I do, as I believe the ancients did."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:32:57)",
                "text": "I think it’s important to consider what humans would’ve thought about back then. Now we have a lot of distractions. We have social media, we can watch videos on YouTube and whatever. But back then, especially before electricity, the stars is the sexiest thing to talk about."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:33:18)",
                "text": "There’s no light pollution."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:33:19)",
                "text": "There’s no light pollution so, I mean, you’re [inaudible 00:33:21]-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:33:21)",
                "text": "That’s the majesty of the heavens."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:33:23)",
                "text": "Every single night you’re spending looking up at the stars. And you can imagine there’s a lot of status value to be the guy who’s very good at studying the stars, as the scientists of the day. And I’m sure there’s going to be these geniuses that emerge. They’re able to do two things. One, tell stories about the gods of whatever, based on the stars. And then also, as we’ll probably talk about, use the stars practically for navigation, for example."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:33:52)",
                "text": "Oh, yeah. Definitely."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:33:53)",
                "text": "So it makes sense that the stars had a primal importance for the ideas of the times, for the status, for religious explorations."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:34:07)",
                "text": "It was an ever-present reality, and it was bright and it was brilliant, and it was full of lights. It’s inconceivable that the ancients would not have paid attention to it. It was an overwhelming presence."
            },
            {
                "speaker": "",
                "time": "(00:34:19)",
                "text": "And that’s one of the reasons why I’m really confident that the constellations that we now recognize as the constellations of the zodiac were recognized much earlier, because it’s hard to miss when you pay attention to the sky, that the sun over the course of the solar year is month by month rising against the background of different constellations. And then there’s a much longer process, the process of precession, which takes that journey backwards and where we have a period of 2,160 years for each sign of the zodiac."
            },
            {
                "speaker": "",
                "time": "(00:34:49)",
                "text": "I think it would’ve been hard for the ancients to have missed that. They might not have identified the constellations in exactly the same way we do today. That may well be a Babylonian or Greek convention, but that the constellations were there I think was very clear. And that they were special constellations, unlike other ones higher up in the sky which were not on the path of the sun, that people paid attention to."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:35:11)",
                "text": "Well, but detecting the procession of the equinox is hard because especially they don’t have any writing systems, they don’t have any mathematical systems. So everything is told through words."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:35:22)",
                "text": "Yeah. Let’s not underestimate oral traditions. Oral traditions, that’s something we’ve lost in our culture today. One of the things that happens with the written word is that you gradually lose your memory."
            },
            {
                "speaker": "",
                "time": "(00:35:37)",
                "text": "Actually, there’s a nice story from Ancient Egypt about the god Thoth, the god of wisdom, who is very proud of himself because he has invented writing. “Look at this gift,” he says to a mythical pharaoh of that time, “Look at the gift that I’m giving humanity, writing. This is a wonderful thing. It’ll enable you to preserve so much that you would otherwise lose.” And the pharaoh in this story replies to him, “No, you have not given us a wonderful gift. You have destroyed the art of memory. We will forget everything. Words will roam free around the world, not accompanied by any wise advice to set them into context.” And actually that’s a very interesting point. And we do know that cultures that still do have oral traditions are able to preserve information for very long periods of time."
            },
            {
                "speaker": "",
                "time": "(00:36:27)",
                "text": "One thing I think is clear in any time, in any period of history, is human beings love stories. We love great stories. And one way to preserve information is to encode it, embed it in a great story. And so carefully done that actually, it doesn’t matter whether the storyteller knows that they’re passing on that information or not. The story itself is the vehicle. And as long as it’s repeated faithfully, the information contained within it will be passed on. And I do think this is part of the story of the preservation of knowledge."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:37:03)",
                "text": "That’s one of the reasons that you take myths seriously."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:37:06)",
                "text": "I take them very seriously. There’s many reasons, but I can’t help being deeply impressed and deeply puzzled by the worldwide tradition of a global cataclysm within human memory. I mean, we know scientifically that there have been many, many cataclysms in the past going back millions of years. I mean, the best-known one of course is the KPG event as it’s now called, that made the dinosaurs extinct 65 million or 66 million years ago."
            },
            {
                "speaker": "",
                "time": "(00:37:42)",
                "text": "But has there been such a cataclysm in the lifetime of the human species? Yeah, the Mount Toba eruption about 70,000 years ago was pretty bad. But a global cataclysm, the Younger Dryas really ticks all the boxes as a worldwide disaster, which definitely involved sea level rise, both at the beginning and at the end of the Younger Dryas. It definitely involved the swallowing up of lands that previously had been above water."
            },
            {
                "speaker": "",
                "time": "(00:38:12)",
                "text": "And I think it’s an excellent candidate for this worldwide tradition of a global cataclysm, of which one of, but not the only, distinguishing characteristics was a flood, an enormous flood, and the submergence of lands that had previously been above water, underwater. The fact that this story is found all around the world suggests to me that the archeological explanation is, look, people suffer local floods all the time. I mean, as we’re talking, there’s flooding in Florida, but I don’t think anybody in Florida is going to make the mistake of believing that that’s a global flood. They know it’s local."
            },
            {
                "speaker": "",
                "time": "(00:38:52)",
                "text": "But that’s the argument largely of archeology, dealing with the flood myths, or that some local population experienced a nasty local flooding event and they decided to say that it affected the whole world. I’m not persuaded by that, particularly since we know there was a nasty epoch, the Younger Dryas, when flooding did occur, and when the Earth was subjected to events cataclysmic enough to extinguish entirely the megafauna of the ice age."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:39:20)",
                "text": "There is the Younger Dryas impact hypothesis that provides an explanation of what happened during this period that resulted in such rapid environmental change. So can you explain this hypothesis?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:39:32)",
                "text": "Yes. The Younger Dryas impact hypothesis, YDIH for short, is not a lunatic fringe theory as its opponents often attempt to write it off. It’s the work of more than 60 major scientists working across many different disciplines, including archeology and including oceanography as well."
            },
            {
                "speaker": "",
                "time": "(00:39:59)",
                "text": "And they are collectively puzzled by the sudden onset of the Younger Dryas, and by the fact that it is accompanied 12,800 years ago by a distinct layer in the Earth. You can see it most clearly at Murray Springs in Arizona, for example. You can see, it’s about the width of a human hand, and there’s a draw there that’s been cut by flash flooding at some time. And that draw has revealed the sides of the draw."
            },
            {
                "speaker": "",
                "time": "(00:40:29)",
                "text": "And you can see the cross-section. And in the cross-section is this distinct dark layer that runs through the Earth. And it contains evidence of wildfires, there is a lot of soot in it. There are also nanodiamonds in it. There is shocked quartz in it. There is quartz that’s been melted at temperatures in excess of 2,200 degrees centigrade. There are carbon microspherules. All of these are proxies for some kind of cosmic impact."
            },
            {
                "speaker": "",
                "time": "(00:40:59)",
                "text": "I talked a moment ago about the extinction of the dinosaurs. Luis and Walter Alvarez, who made that incredible discovery, initially their discovery was based entirely on impact proxies, just as the Younger Dryas is. There was no crater. And for a long time they were disbelieved because they couldn’t produce a crater. But when they finally did produce that deeply buried Chicxulub crater, that’s when people started to say, “Yeah, they have to be right.” But they weren’t relying on the crater, they were relying on the impact proxies. And they’re the same impact proxies that we find in what’s called the Younger Dryas boundary layer all around the world."
            },
            {
                "speaker": "",
                "time": "(00:41:36)",
                "text": "So it’s the fact that at the moment when the Earth tips into a radical climate shift, it’s been warming up for at least 2,000 years before 12,800 years ago, people at the time must have been feeling a great sense of relief. “We’ve been living through this really cold time, but it’s getting better. Things are getting better.” And then suddenly, around 12,800 years ago, some might say 12, 860 years ago, there’s a massive global plunge in global temperatures, and the world suddenly gets as cold as it was at the peak of the ice age. And it’s almost literally overnight. It’s very, very, very rapid."
            },
            {
                "speaker": "",
                "time": "(00:42:15)",
                "text": "Normally in an epoch, when the Earth is going into a freeze, you would not expect sea levels to rise. But there is a sea level rise, a sudden one, right at the beginning of the Younger Dryas. And then you have this long frozen period from 12,800 to 11,600 years ago. And then equally, dramatically and equally suddenly the Younger Dryas comes to an end and the world very rapidly warms up. And you have a recognized pulse of meltwater at that time as the last of the glaciers collapse into the sea, called meltwater pulse 1B, around about 11,600 years ago."
            },
            {
                "speaker": "",
                "time": "(00:42:53)",
                "text": "This is a period which is very tightly defined, it’s a period when we know that human populations were grievously disturbed. That’s when the so-called Clovis culture of North America vanished entirely from the record during the Younger Dryas. And it’s the time when the mammoths and the saber-toothed tigers vanished from the record as well."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:43:13)",
                "text": "Is there a good understanding of what happened geologically, whether there was an impact or not? What explains this huge dip in temperature and then rise in temperature?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:43:24)",
                "text": "The abrupt cessation of the global meridional overturning circulation, of which the Gulf Stream is the best-known part, the main theory that’s been put forward up to now, and I don’t dispute that theory at all, is that the sudden freeze was caused by the cutting off of the Gulf Stream basically, which is part of the central heating system of our planet. So no wonder it became cold."
            },
            {
                "speaker": "",
                "time": "(00:43:53)",
                "text": "But what’s not really been addressed before is why that happened, why the Gulf Stream was cut, why a sudden pulse of meltwater went into the world ocean, and it was so much of it and it was so cold that it actually stopped the Gulf Stream in its tracks. And that’s where the Younger Dryas impact hypothesis offers a very elegant and very satisfactory solution to the problem."
            },
            {
                "speaker": "",
                "time": "(00:44:14)",
                "text": "Now, the hypothesis, of course, is broader than that. Amongst the scientists working on it are, for example, Bill Napier, an astrophysicist and astronomer. They have assembled a great deal of evidence, which suggests that the culprit in the Younger Dryas impact event or events was what we now call the Taurid meteor stream, which the Earth still passes through twice a year. It’s now about 30 million kilometers wide, takes the Earth a couple of days to pass through it on its orbit. It passes through it in June, and it passes through it at the end of October."
            },
            {
                "speaker": "",
                "time": "(00:44:54)",
                "text": "The suggestion is that the Taurid meteor stream is the end product of a very large comet that entered the solar system round about 20,000 years ago. Came in from the Oort cloud, got trapped by the gravity of the Sun, and went into orbit around the Sun, an orbit that crossed the orbit of the Earth. However, when it was one object, the likelihood of a collision with the Earth was extremely small."
            },
            {
                "speaker": "",
                "time": "(00:45:22)",
                "text": "But as it started to do what all comets do, which was to break up into multiple fragments because these are chunks of rock held together by ice, and as they warm up, they split and disintegrate and break into pieces, as it passed through that its debris stream became larger and larger and wider and wider. And the theory is that 12,800 years ago, the Earth passed through a particularly dense part of the Taurid meteor stream and was hit by multiple impacts all around the planet, certainly from the west of North America, as far east as Syria."
            },
            {
                "speaker": "",
                "time": "(00:45:58)",
                "text": "And that we are by and large not talking about impacts that would’ve caused craters, although there certainly were some, we are talking about air bursts. When an object is 100 or 150 meters in diameter and it’s coming in very fast into the Earth’s atmosphere, it is very unlikely to reach the earth, it’s going to blow up in the sky. And the best known recent example of that is the Tunguska event in Siberia, which took place on the 30th of June 1908."
            },
            {
                "speaker": "",
                "time": "(00:46:33)",
                "text": "The Tunguska event was, nobody disputes, it was definitely an air burst of a cometary fragment. And the date is interesting because the 30th of June is the height of the Beta Taurids. It’s one of the two times when the Earth is going through the Taurid meteor stream. Well, luckily that part of Siberia wasn’t inhabited, but 2,000 square miles of forest were destroyed. If that had happened over a major city, we would all be thinking very hard about objects out of the Taurid meteor stream and about the risk of cosmic impact."
            },
            {
                "speaker": "",
                "time": "(00:47:05)",
                "text": "So the suggestion is that it wasn’t one impact, it wasn’t two impacts, it wasn’t three impacts, it was hundreds of air bursts all around the planet. Coupled with a number of bigger objects, which the scientists working on this think hit the North American ice cap largely. Some of them may also have hit the Northern European ice cap, resulting in that sudden otherwise unexplained flood of meltwater that went into the world ocean and caused the cooling that then took place."
            },
            {
                "speaker": "",
                "time": "(00:47:34)",
                "text": "But this was a disaster for life all over the planet. And it’s interesting that one of the sites where they find the Younger Dryas boundary and where they find overwhelming evidence of an air burst and where they find all the shocked quartz, the carbon microspherules, the nanodiamonds, the trinitite, and so on and so forth, all of those impact proxies are found at Abu Hureyra. That was a settlement within 150 miles of Gobekli Tepe, and it was hit 12,800 years ago and it was obliterated. Interestingly, it was re-inhabited by human beings within probably five years, but it was completely obliterated at that time. And it is difficult to imagine that the people who lived in that area would not have been very impressed by what they saw happening by these massive explosions in the sky and the obliteration of Abu Hureyra."
            },
            {
                "speaker": "",
                "time": "(00:48:30)",
                "text": "Now this is a theory, the Younger Dryas impact. It’s a hypothesis actually, it’s not even a theory. A theory is, I think, considered a higher level than a hypothesis. That’s why it’s the Younger Dryas impact hypothesis. And of course it has many opponents and there are many who disagree with it. And there have been a series of peer-reviewed papers that have been published supposedly debunking the Younger Dryas impact hypothesis. One, I think was in 2011, it was called a Requiem for the Younger Dryas Impact Hypothesis. And there’s one just been published a few months ago or a year ago called a Complete Refutation of the Younger Dryas Impact Hypothesis, something like that, some lengthy title."
            },
            {
                "speaker": "",
                "time": "(00:49:14)",
                "text": "So it’s a hypothesis that has its opponents, and even within those of us who are looking at the alternative side of history, there are different points of view. Robert Schoch from Boston University, the geologist who demonstrated that the erosion on the Sphinx may well have been caused by exposure to a long period of very heavy rainfall, he doesn’t go for the Younger Dryas impact hypothesis. He fully accepts that the Younger Dryas was a global cataclysm and that the extinctions took place, but he thinks it was caused by some kind of massive solar outburst."
            },
            {
                "speaker": "",
                "time": "(00:49:50)",
                "text": "What everybody’s agreed on is the Younger Dryas was bad, but there is dispute about what caused it. I personally have found the Younger Dryas impact hypothesis to be the most persuasive, which most effectively explains all the evidence."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:50:05)",
                "text": "How important is the impact hypothesis to your understanding of the ice age advanced civilizations? Is it possible to have another explanation for environmental factors that could have erased most of an advanced civilization during this period?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:50:21)",
                "text": "In a sense, it’s not the impact hypothesis that is central to what I’m saying, it’s the Younger Dryas that’s central to what I’m saying. And the Younger Dryas required a trigger, something caused it. I think the Younger Dryas impact hypothesis, the notion that we’re looking at a debris stream of a fragmenting comet, and we can still see that debris stream because it’s still up there and we still pass through it twice a year, is the best explanation. But I don’t mind other explanations. It’s good that there are other explanations. The Younger Dryas is a big mystery, and it’s not a mystery that’s been solved yet."
            },
            {
                "speaker": "",
                "time": "(00:50:55)",
                "text": "And that word, advanced civilization, this is another word that is easily misunderstood. And I’ve tried to make clear many, many times that when we consider the possibility of something like a civilization in the past, we shouldn’t imagine that it’s us, that it’s something like us. We should expect it to be completely different from us, but that it would’ve achieved certain things."
            },
            {
                "speaker": "",
                "time": "(00:51:22)",
                "text": "Amongst the clues that intrigue me are those precessional numbers that are found all around the world, and are a category of ancient maps called Portolanos, which suddenly started to appear just after the crusade that entered Constantinople and sacked Constantinople, the Portolanos suddenly start to appear. And they’re extremely accurate maps. The most of the ones that have survived are extremely accurate maps of the Mediterranean alone, but some of them show much wider areas."
            },
            {
                "speaker": "",
                "time": "(00:51:54)",
                "text": "For example, on these Portolano-style maps, you do find a depiction of Antarctica again and again. And another thing that these maps have in common is that many of the mapmakers state that they base their maps on multiple older source maps, which have not survived. These maps are intriguing because they have very accurate relative longitudes."
            },
            {
                "speaker": "",
                "time": "(00:52:16)",
                "text": "Our civilization did not crack the longitude problem until the mid-18th century with Harrison’s chronometer, which was able to keep accurate time at sea so you could have the time in London and you could have the local time at sea at the same time. And then you could work out your longitude. There might be other ways of working out longitude as well, but there it is. The fact is these Portolanos have extremely accurate relative longitudes."
            },
            {
                "speaker": "",
                "time": "(00:52:43)",
                "text": "Secondly, some of them show the world, to my eye, as it looked during the ice age. They show a much extended Indonesia and Malaysian peninsula and the series of islands that make up Indonesia today are all grouped together into one landmass. And that was the case during the ice age. That was the Sunda Shelf. And the presence of Antarctica on some of these maps also puzzles and intrigues me and is not satisfactorily explained in my view by archeology, which says, “Oh, those mapmakers, they felt that the world needed something underneath it to balance it so they put a fictional landmass there.”"
            },
            {
                "speaker": "",
                "time": "(00:53:21)",
                "text": "I don’t think that makes sense. I think somebody was mapping the world during the last ice age, but that doesn’t mean that they had our kind of tech. It means that they were following that exploration instinct. That they knew how to navigate. They’d been watching the stars for thousands of years before, they knew how to navigate and they knew how to build seagoing ships. And they explored the world and they mapped the world."
            },
            {
                "speaker": "",
                "time": "(00:53:46)",
                "text": "Those maps were made a very, very long time ago. Some of them, I believe, were likely preserved in the Library of Alexandria. I think even then they were being copied and recopied. We don’t know exactly what happened to the Library of Alexandria, except that it was destroyed. I suggest it’s likely this was during the period of the Roman Empire. I suggest it’s likely that some of those maps were taken out of the library and taken to Constantinople, and that’s where they were liberated during the crusade and entered world culture again and started to be copied and recopied."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:54:23)",
                "text": "From this perspective, when we talk about advanced ice age civilization, it could have been a relatively small group of people with the technology of their scholars of the stars and their expert seafaring navigators."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:54:38)",
                "text": "Yes, that’s about as far as I would take it. And when I say that, as I have said on a number of occasions, that it had technology equivalent to ours in the 18th century, I’m referring specifically to the ability to calculate longitude. I’m not saying that they were building steam engines. I don’t see any evidence for that."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:54:57)",
                "text": "And perhaps some building tricks and skills of how to [inaudible 00:55:03]."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:55:02)",
                "text": "Well, definitely. And this, again, is where you come to a series of mysteries, which are perhaps best expressed on the Giza Plateau in Egypt with the three Great Pyramids. And the extraordinary megalithic temples that many people don’t pay much attention to on the Giza Plateau and the Great Sphinx itself. This is an area of particular importance in understanding this issue."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(00:55:31)",
                "text": "Well, can you actually describe the Sphinx and the Great Pyramids and what you find most mysterious and interesting about them?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(00:55:37)",
                "text": "Well, first of all, the astronomy. And here I must pay tribute to two individuals, actually three individuals in particular. One of them is John Anthony West, passed away in 2018. He was the first person in our era to begin to wonder if the Sphinx was much older than it had been."
            },
            {
                "speaker": "",
                "time": "(00:55:57)",
                "text": "Actually, he got that idea from a philosopher called Schwaller de Lubicz, who’d noticed what he thought was water erosion on the body of the Sphinx. John West picked that up, and he was a great amateur Egyptologist himself. He spent most of his life in Egypt and he was hugely versed in Ancient Egypt. And when he looked at the Sphinx and at the strange scalloped erosion patterns and the vertical fissures, particularly in the trench around the Sphinx, he began to think maybe Schwaller was right, maybe there was some of some sort of flooding here."
            },
            {
                "speaker": "",
                "time": "(00:56:29)",
                "text": "And that’s when he brought Robert Shoch, second person I’d like to recognize, geologist at Boston University. He brought Shoch to Giza, and Shock was the first geologist to stick his neck out, risk the ire of Egyptologists, and say, “Well, it looks to me like the Sphinx was exposed to at least a thousand years of heavy rainfall.” And as Shoch’s calculations have continued, as he’s continued to be immersed in this mystery, he’s continuously pushed that back. And he’s now, again, looking at the date of around 12,000, 12,500 years ago during the Younger Dryas for the creation of the Great Sphinx."
            },
            {
                "speaker": "",
                "time": "(00:57:05)",
                "text": "And then, of course, this is the period of the wet Sahara, the humid Sahara. The Sahara was a completely different place during the ice age. There were rivers in it, there were lakes in it, it was fertile, it was possibly densely populated, and there was a lot of rain. There’s not no rain in Giza today, but there’s relatively little rain. Not enough rain to cause that erosion damage on the Sphinx."
            },
            {
                "speaker": "",
                "time": "(00:57:31)",
                "text": "The next person who needs to be mentioned in this context is Robert Bauval. Robert and I have co-authored a number of books together. Unfortunately, Robert has been very ill for the last seven years. He’s got a very bad chest infection. And I think also that Robert became very demoralized by the attacks of Egyptologists on his work. But Robert is the genius, and it does take a genius sometime to make these connections because nobody noticed it before, that the three pyramids of Giza are laid out on the ground in the pattern of the three stars of Orion’s belt."
            },
            {
                "speaker": "",
                "time": "(00:58:09)",
                "text": "And skeptics will say, “Well, you can find any buildings and line them up with any stars you want,” but Orion actually isn’t any old constellation. Orion was the god Osiris in the sky. The ancient Egyptians called the Orion constellation Sahu, and they recognized it as the celestial image of the god Osiris. So what’s being copied on the ground is the belt of a deity, of a celestial deity. It’s not just a random constellation."
            },
            {
                "speaker": "",
                "time": "(00:58:36)",
                "text": "And then when we take precession into account, you find something else very intriguing happening. First of all, you find that the exact orientation of the pyramids as it is today, and pretty much as it was when they’re supposed to have been built 4,500 years ago, it’s not precisely related to how Orion’s Belt looked at that time. There’s a bit of a twist, they’re not quite right. But as you precess the stars backwards, as you go back and back and back and you come to around 10,500 BC, 12,500 years ago in the Younger Dryas, you find that suddenly they lock perfectly. They match perfectly with the three pyramids on the ground."
            },
            {
                "speaker": "",
                "time": "(00:59:20)",
                "text": "And that’s the same moment that the Great Sphinx, an equinoctial monument, aligned perfectly to the rising sun on the spring equinox. Anybody can test this through themselves. Just go to Giza on the 21st of March, be there before dawn, stand behind the Sphinx, and you will see the sun rising directly in line with the gaze of the Sphinx. But the question is what constellation was behind the Sphinx? And 12,500 years ago it was the constellation of Leo. And actually the constellation of Leo has a very Sphinx-like look. And I and my colleagues are pretty sure that the Sphinx was originally a lion entirely. And that over the thousands of years, it became damaged, it became eroded, particularly the part of it that sticks out the head. There were periods when the Sphinx was completely covered in sand, but still the head stuck out."
            },
            {
                "speaker": "",
                "time": "(01:00:14)",
                "text": "By the time you come to the Fourth Dynasty, when the Great Pyramids are supposedly built, by the time you come to the Fourth Dynasty, the lion, original lion head, would’ve been a complete mess. And we suggest that it was then re-carved into a pharaonic head. Egyptologists think it was the pharaoh Khafre, but there’s no real strong resemblance, but it’s definitely wearing the nemes headdress of an ancient Egyptian pharaoh. And we think that that’s a result of a recarving of what was originally not only a lion-bodied, but also a lion-headed monument."
            },
            {
                "speaker": "",
                "time": "(01:00:50)",
                "text": "It wouldn’t make sense if you create an equinoctial marker in the time of Khafre 4,500 years ago, and the Sphinx is an equinoctial marker. I mean, it’s 270 feet long and 70 feet high and it’s looking directly at the rising sun on the equinox. If you create it then, you’d be more likely to create it in the shape of a bull, because that was the age of Taurus, when the constellation of Taurus housed the sun on the spring equinox. So why is it a lion? And again, we think that’s because of that observation of the skies and putting on the ground as above, so below, putting on the ground an image of the sky at a particular time."
            },
            {
                "speaker": "",
                "time": "(01:01:32)",
                "text": "Now, the fact that the Giza Plateau, it’s a fact, of course, that Egyptologists completely dispute, but the fact that the principle monuments of the Giza Plateau, the three Great Pyramids and the Great Sphinx, all lock astronomically on the date of around 10,500 BC, to me, is most unlikely to be an accident. And actually, if you look at computer software at the sky at that time, you’ll see that the Milky Way is very prominent and seems to be mirrored on the ground by the river Nile-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:02:00)",
                "text": "…prominent and seems to be mirrored on the ground by the river Nile. I suggest that may be one of the reasons amongst many why Giza was chosen as the site for this very special place. The point I want to make is that an astronomical design on the ground, which memorializes a very ancient date, does not have to have been done 12,500 years ago. If, from the ancient Egyptian point of view, you’re there 4, 500 years ago, and there’s a time 8,000 years before that, which is very, very, very important to you, you could use astronomical language and megalithic architecture to memorialize that date on the Giza Plateau, which is what we think we’re looking at, except for one thing, and that’s the erosion patterns on the Sphinx."
            },
            {
                "speaker": "",
                "time": "(01:02:52)",
                "text": "We are pretty sure that the Sphinx, at least, does date back to 12 and a half thousand years ago and with it, the megalithic temples, the so-called Valley Temple, which stands just to the east and just to the south of the Sphinx and the Sphinx temple, which stands directly in front of the Sphinx. The Sphinx temple has largely been destroyed. But the Valley Temple, attributed to Khafre on no good grounds whatsoever, is a huge megalithic construction with blocks of limestone that weigh up to 100 tons each. Yet, it has been remodeled/refaced with granite. There are granite blocks that are placed on top of the core limestone blocks. Those core limestone blocks were already eroded when the granite blocks were put there. Why? Because the granite blocks have actually been purposefully and deliberately cut to fit into the erosion marks on the, we believe, much older megalithic blocks there."
            },
            {
                "speaker": "",
                "time": "(01:03:56)",
                "text": "I think Giza is a very complicated site. I would never seek to divorce the dynastic ancient Egyptians from the Great Pyramids. They were closely involved in the construction of the Great Pyramids as we see them today. But what I do suggest is that there were very low platforms on the Giza Plateau that are much older and that when we look at the three Great Pyramids, we are looking at a renovation and a restoration and a enhancement of much older structures that had existed on the Giza Plateau for a much longer period before that. Actually, the Great Pyramid is built around a natural hill. That natural hill might’ve been seen as the original primeval mound to the ancient Egyptians."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:04:44)",
                "text": "So the idea is that the Sphinx was there long before the pyramids, and the pyramids were built by the Egyptians to celebrate further an already holy place."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:04:55)",
                "text": "Yeah. There were platforms in place where the pyramids stand, not the pyramids as we see them today, but the base of those pyramids was already in place at that time."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:05:08)",
                "text": "What’s the evidence that the Egyptologists use to make the attributions that they do for the dating of the pyramids and the Sphinx?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:05:16)",
                "text": "Well, the three great pyramids of Giza are different from later pyramids. This is another problem that I have with the whole thing is the story of pyramid building. When did it really begin? The timeline that we get from Egyptology is the first pyramid is the pyramid of the Pharaoh, Djoser, the Step Pyramid at Saqqara, about 100 years or so before the Giza pyramids were built. Then, we have this explosion in the fourth dynasty of true pyramids. We have three of them attributed to a single Pharaoh, Sneferu, who built, supposedly, the pyramid at Meidum and the two pyramids at Dahshur, the Bent and the Red Pyramid."
            },
            {
                "speaker": "",
                "time": "(01:06:06)",
                "text": "Then, within that same 100-year span, we have the Giza pyramids being built. This is according to the Orthodox chronology. Then, suddenly, once the Giza project is finished, pyramid building goes into a massive slump in Ancient Egypt. The pyramids of the Fifth Dynasty are, frankly speaking, a mess outside. They’re very inferior constructions. You can hardly recognize them as pyramids at all. But what happens when you go inside them is you find that they’re extensively covered in hieroglyphs and imagery, repeating the name of the king who was supposedly buried in that place. Whereas, the Giza pyramids have no internal inscriptions whatsoever. What we do have is one piece of graffiti about which there is some controversy."
            },
            {
                "speaker": "",
                "time": "(01:06:56)",
                "text": "Basic statistics: it’s a 6 million-ton structure. Each side is about 750 feet long. It’s aligned almost perfectly to true north, south, east, and west within 3/60ths of a single degree, the 06ths, because degrees are divided into 60s. It’s the precision of the orientation and the absolute massive size of the thing plus its very complicated internal passageways that are involved in it. In the ninth century, the Great Pyramid still had its facing stones in place, but there was an Arab Caliph, Khalifa al-Mamun, who had already realized that other pyramids did have their entrances in the north face. Nobody knew where the entrance to the Great Pyramid was. But he figured if there’s an entrance to this thing, it’s going to be in the north face somewhere. He put together a team of workers. They went in with sledgehammers. They started smashing where he thought would be the entrance. They cut their way into the Great Pyramid for a distance of maybe 100 feet. Then, the hammering that they did dislodged something. They heard a little bit further away, something big falling, and they realized there was a cavity there. They started heading in that direction. Then, they joined the internal passageway of the Great Pyramid, the descending and the ascending corridors that go up."
            },
            {
                "speaker": "",
                "time": "(01:08:28)",
                "text": "When you go up the ascending corridor, every one of the internal passageways in the Great Pyramid that people can walk in slopes at an angle of 26 degrees. That’s interesting because the angle of slope of the exterior of the Great Pyramid is 52 degrees. We know mathematicians were at work as well as geometers in the creation of the Great Pyramid."
            },
            {
                "speaker": "",
                "time": "(01:08:50)",
                "text": "If you go up the Grand Gallery, which is at the end of the so-called ascending corridor, and it’s above the so-called Queen’s Chamber… You go up the Grand Gallery. You’re eventually going to come to what is known as the King’s Chamber in which there is a sarcophagus. That sarcophagus is a little bit too big to have been got in through the narrow entrance passageway. It’s almost as though the so-called King’s Chamber was built around the sarcophagus, already in place."
            },
            {
                "speaker": "",
                "time": "(01:09:17)",
                "text": "Above the King’s Chamber are five other chambers. These are known as relieving chambers. The theory was that they were built to relieve the pressure on the King’s Chamber of the weight of the monument. But I think what makes that theory dubious is the fact that even lower down, where more weight was involved, you have the Queen’s Chamber, and there are no such relieving chambers above that."
            },
            {
                "speaker": "",
                "time": "(01:09:38)",
                "text": "In the top of these five chambers, a British adventurer and vandal called Howard Vyse, who dynamited his way into those chambers in the first place, allegedly found… Well, he claims he found a piece of graffiti left by a work-gang naming the Pharaoh Khufu. It’s true. I’ve been in that chamber, and there is the cartouche of Khufu there. Quite recognizable. But the dispute around it is whether that is a genuine piece of graffiti dating from the Old Kingdom or whether Howard Vyse actually put it there himself because he was in desperate need of money at the time. I’m not sure what the answer to that question is. But it’s one of the reasons that Egyptologists feel confident in saying that the pyramid is the work of Khufu. Another is what is called the Wadi al-Jarf Papyri, where, on the Red Sea, the diary of an individual Merer was found. He talks about bringing highly polished limestone to the Great Pyramid. It’s clear that what he’s talking about is the facing stones of the Great Pyramid. He’s not talking about the body of the Great Pyramid. He’s talking about the facing stones of the Great Pyramid during the reign of Khufu. That’s another reason why the Great Pyramid is attributed to Khufu. But I think that Khufu was undoubtedly involved in the Great Pyramid and in a big way. But I think he was building upon and elaborating a much older structure."
            },
            {
                "speaker": "",
                "time": "(01:11:09)",
                "text": "I think the heart of that structure is the subterranean chamber, which is 100 feet vertically beneath the base of the Great Pyramid. Anybody who suffers from claustrophobia will not enjoy being down there. You’ve got to go down a 26-degree sloping corridor until a distance of about 300 feet. It’s 100 feet vertically, but the slope means you’re going to walk a distance of… Not walk. You’ve got to ape walk. You’re almost going to have to crawl. I’ve learned from long experience that the best way to go down these corridors is actually backwards. If you go forward, you keep bumping your head on them because they’re only three feet five inches high. You get down to the bottom. You have a short horizontal passage, and then you get into the subterranean chamber."
            },
            {
                "speaker": "",
                "time": "(01:11:54)",
                "text": "The theory of Egyptology is that this was supposed to be the burial place of Khufu, but after cutting out that 300-foot long, 26-degree sloping passage, a lot of which passes through bedrock, and having cut the subterranean chamber out of bedrock, gone to all that trouble, they decided they wouldn’t bury him there. They built what’s now known as the Queen’s Chamber as his burial chamber. But then they decided that wouldn’t do either. They then built the King’s chamber, and that’s where the Pharaoh is supposed to have been buried. Those Arab raiders under Khalifa al-Mamun didn’t find anything in the Great Pyramid at all."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:12:31)",
                "text": "Your idea is that the Sphinx and maybe some aspects of the pyramid were much earlier. Why that’s important is, in that case, it would be evidence of some transfer of technology-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:12:47)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:12:47)",
                "text": "…from a much older civilization. The idea is that during the Younger Dryas, most of that civilization was either destroyed or damaged, and they desperately scattered across the globe."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:13:01)",
                "text": "Seeking refuge."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:13:01)",
                "text": "Seeking refuge and telling stories of maybe, one, the importance of the stars, their knowledge about the stars, and their knowledge about building and knowledge about navigation."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:13:17)",
                "text": "That’s roughly the idea. It’s interesting that the ancient Egyptians have a notion of an epoch that they call Zep Tepi, which is the first time. It means the first time. This is when the gods walk the earth. This is when seven sages brought wisdom to Ancient Egypt. That is seen as the origin of ancient Egyptian civilization. There are king lists… by the ancient Egyptians themselves. There are king lists that go back way beyond the First Dynasty/go back 30,000 years into the past in Ancient Egypt, considered to be entirely mythical by Egyptologists. But nevertheless, it’s interesting that there’s that reference to remote time."
            },
            {
                "speaker": "",
                "time": "(01:14:02)",
                "text": "Now, what you also have in Egypt are what might almost be described as secret societies. The followers of Horus are one of those specifically tasked with bringing forward the knowledge from the first time into later periods. The souls of Pe and Nekhen are another one of these mysterious secret society groups who are possessors of knowledge that they transmit to the future. What I’m broadly suggesting is that those survivors of the Younger Dryas cataclysm, who settled in Giza may have been relatively small in number. It’s interesting that they’re referred to in the Edfu Building Texts as seven sages because that repeats again and again. It’s also in Mesopotamia."
            },
            {
                "speaker": "",
                "time": "(01:14:51)",
                "text": "It’s seven sages, seven Apkallu, who come out of the waters of the Persian Gulf and teach people all the skills of agriculture and of architecture and of astronomy. It’s found all around the world that there was a relatively small number of people who took refuge in Giza, who benefited from the survival skills of the hunter-foragers who lived at Giza at that time, and who also passed on their knowledge to those hunter-foragers. But it was not knowledge that was ready to be put into shape at that time. That knowledge was then preserved and kept and handled within very secretive groups that passed it down over thousands of years. Finally, it burst into full form in the fourth dynasty in Ancient Egypt."
            },
            {
                "speaker": "",
                "time": "(01:15:38)",
                "text": "The notion that knowledge might be transferred over thousands of years shouldn’t be absurd. We know, for example, in the case of ancient Israel… It goes back to the time of Abraham, which is pretty much, I think, around 2000 BC. Knowledge has been preserved from that time right up to the present day. If you can preserve knowledge for 4,000 years, you can probably preserve it for eight."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:16:05)",
                "text": "Now, of course, the air bars on this are quite large, but if an advanced ice-age civilization existed, where do you think it was? Where do you think we might find it one day if it existed, and how big do you think it might have been?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:16:19)",
                "text": "Well, this is where I’m often accused of presenting a God-of-the-gaps argument, that I think there was a lost civilization because there’s lots of the earth that archeologists have never looked at. Of course, I’m not thinking that. These are very special gaps that I’m interested in. I’m interested in them because of all the curiosities and the puzzlement that I’ve expressed to you before. It’s not just because they’re gaps in the archeological record. It’s because those gaps involve places that were very interesting places to live during the ice age. They specifically include the Sahara Desert, which was not a desert during the ice age and went through this warm wet period when it was very, very fertile. Certainly, some archeology has been done in the Sahara, but it’s fractional. It’s tiny. I think if we want to get into the true origins of Ancient Egyptian civilization, of the peoples of Ancient Egypt, we need to be looking in the Sahara for that."
            },
            {
                "speaker": "",
                "time": "(01:17:19)",
                "text": "The Amazon rainforest is another example of this. I think the Sahara is about 9 million square kilometers. The Amazon that’s left under dense canopy rainforest is about 5 million square kilometers, maybe closer to six. Then, you have the continental shelves that were submerged by sea level rise at the end of the ice age. Now, it’s well established that sea level rose by 400 feet, but it didn’t rise by 400 feet overnight. It came in dribs and drabs. There were periods of very rapid, quite significant sea level rise, and there were periods when the sea level was rising much more slowly. That 400-foot sea level rise is spread out over a period of about 10,000 years. But there are episodes within it like meltwater pulse 1B like meltwater pulse 1A when the flooding was really immense."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:18:12)",
                "text": "How big do you think it might’ve been? Do you think it was spread across the globe? If there were expert navigators, do you think they spread across the globe?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:18:23)",
                "text": "Well, the reason that I’m talking about the gaps is I don’t know where this civilization started or where it was based. All I’m seeing are clues and mysteries and puzzles that intrigue me and which suggest to me that something is missing from our past. I’m not inclined to look for that missing something in, for example, Northern Europe, because Northern Europe was not a very nice place to live during the ice age. I mean, nobody smart would build a civilization in Northern Europe 12,000 years ago. It was a hideous, frozen wasteland. The places to look are places that were hospitable and welcoming to human beings during the ice age. That, of course, includes the coastlines that are now underwater. Of course, it includes the Sahara Desert. Of course, it includes the Amazon rainforest as well. All of these places, I think, are candidates for “my lost civilization.” Because I think, largely from those ancient maps, that it was a navigating seafaring civilization, I suspect that it wasn’t only in one place. It was probably in a number of places."
            },
            {
                "speaker": "",
                "time": "(01:19:31)",
                "text": "Then, I can only speculate. Maybe there was a cultural value where it was felt that it was not appropriate to interfere with the lives of hunter-foragers at that time. Maybe it was felt that they should keep their distance from them, just as, even today, there is a feeling that we shouldn’t be interfering too much with the uncontacted tribes in the Amazon rainforest. Although interestingly, some of those tribes are now using cell phones. That possibility may have been there in the past. Only when we come to a global cataclysm does it become essential to have outreach and, actually, to take refuge amongst those hunter-forager populations. That is the hypothesis that I’m putting forward. I’m not claiming that it’s a fact. But, for me, it helps to explain the evidence."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:20:24)",
                "text": "That speaks to one of the challenges that archeologists provide to this idea, is that there is a lot of evidence of humans in the ice age and they appear to be all hunter-gatherers. But, like you said, only a small percent of areas where humans have lived have been studied by archeologists."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:20:46)",
                "text": "That’s right. Very tiny percent. Even a tiny percent of every archeological site has been studied by archeologists, too. Typically, one to 5% of any archeological site is excavated."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:20:55)",
                "text": "I mean, that’s why Göbekli Tepe fills my mind with imagination, especially seeing it as a time capsule. It’s almost certain that there is places on earth we haven’t discovered that, once we do, even if it’s after the ice age, will change our view of human history. What would be your dream thing to discover, like Göbekli Tepe, that says a definitive perturbation to our understanding of ice age history?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:21:29)",
                "text": "Some archive. Some hall of records. There’s both mystical associations with the Hall of Records at Giza from people like the Edgar Cayce organization. There’s also ancient Egyptian traditions which suggest that something was concealed beneath the Sphinx. This is not an idea that is alien to Ancient Egypt. It’s quite present in Ancient Egypt. So far, as far as I know, nobody has some dug down beneath the Sphinx. Of course, there’s very good reasons for that. You don’t want to damage the place too much. But let’s call it the Hall of Records. I’d love to find that."
            },
            {
                "speaker": "",
                "time": "(01:22:09)",
                "text": "But I think in a way that’s what Göbekli Tepe is. Göbekli Tepe is a hall of records. It’s interesting that just as I’ve tried to outline, I hope reasonably clearly, that the three great pyramids of Giza match Orion’s belt in 10,500 BC just as the Sphinx matches Leo in 10,500 BC, 12,500 years ago or so. Pillar 43 in Enclosure D at Göbekli Tepe contains what a number of researchers, myself included, regard as an astronomical diagram. Martin Sweatman of Edinburgh University has brought forward the best work in this field. But it was initially started by a gentleman called Paul Burley who noticed that one of the figures on Pillar 43 is a scorpion, very much like we represent the constellation of Scorpio today and that above it is a vulture with outstretched wings, which is in a posture very similar to the constellation that we call Sagittarius. On that outstretched wing is a circular object, and the suggestion is that it’s marking the time when the sun was at the center of the dark rift in the Milky Way at the summer solstice 12 and a half thousand years ago. That’s what it’s marking."
            },
            {
                "speaker": "",
                "time": "(01:23:28)",
                "text": "It’s interesting that the same date can be deduced from Pillar… Of course, it’s controversial. Martin Sweatman’s ideas are by no means accepted by archeology. But he’s done very, very thorough, detailed, statistical work on this. I’m personally convinced. We have a time capsule at Göbekli Tepe, which is memorializing a date that is at least 1,200 years before Göbekli Tepe was built if that dating of 11,600 years ago proves to be absolutely the oldest date as it is at present. The date memorialized on Pillar 43 is 12,800 years ago, the beginning of the Younger Dryas, the beginning of the impact event."
            },
            {
                "speaker": "",
                "time": "(01:24:09)",
                "text": "Then, Giza does the same thing but in much larger scale. It uses massive megalithic architecture, which is very difficult to destroy, and a profound knowledge of astronomy to encode a date in a language that any culture which is sufficiently literate in astronomy will be able to decode. We don’t have to have a script that we can’t read like we do with the Indus Valley civilization or with the Easter Island script. We don’t have to have a script that can’t be interpreted. If you use astronomical language, then any astronomical literate civilization will be able to give you a date."
            },
            {
                "speaker": "",
                "time": "(01:24:48)",
                "text": "Hoover Dam has a star map built into it. That star map is part of an exhibition that was put there at the founding of the Hoover Dam. What it does is it freezes the sky above the Hoover Dam at the moment of its completion. Oscar Hansen, the artist who created that piece said so specifically that this would be so that any future culture would be able to know the time of the dam’s construction. You can use astronomy and architecture to memorialize a particular date."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:25:22)",
                "text": "Quick pause. Bathroom break."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:25:24)",
                "text": "Sounds good."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:25:25)",
                "text": "To me, the story that we’ve been talking about… It is both exciting if the mainstream archeology narrative is correct and the one you’re constructing is correct. Both are super interesting because the mainstream archeology perspective means that there’s something about the human mind from which the pyramids/these ideas spring naturally. You place humans anywhere. You place them on Mars. It’s going to come out that way. That’s an interesting story of human psychology that then becomes even more interesting when you evolve out of Africa with homo sapiens, how they think about the world. That’s super interesting. Then, if there’s an ancient civilization/advanced civilization that explains why there’s so many similar types of ideas that spread, that means that there’s so much undiscovered still about the spring of these ideas of civilization that come. To me, they’re both fascinating. I don’t know why there’s so much infighting."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:26:29)",
                "text": "I think it’s partly territorial. I cannot speak of all archeologists, but some archeologists feel very territorial about their profession. They do not feel happy about outsiders entering their realm, especially if those outsiders have a large platform. I’ve found that the attacks on me by archeologists have increased step-by-step with the increase of my exposure. I wasn’t very interesting to them when I just had one minor bestseller in 1992 with a book called The Sign and the Seal. But when Fingerprints of the Gods was published in 1995 and became a global bestseller, then I started to attract their attention and appear to have been regarded as a threat to them."
            },
            {
                "speaker": "",
                "time": "(01:27:26)",
                "text": "That is the case today. That is why Ancient Apocalypse Season 1 was defined as the most dangerous show on Netflix. It’s why the Society for American Archeology wrote an open letter to Netflix asking Netflix to reclassify the series of science fiction. It’s why they accused the series of antisemitism, misogyny, white supremacism, and… I don’t know, a whole bunch of other things like that, that have nothing to do with anything that’s in the series. It was like, “We must shut this down. This is so dangerous to us.” There are many more dangerous things in the world than a television series going on right now. But maybe it was seen as a danger to archeology, that this non-archeologist was in archeological terrain and being viewed and seen and read by large numbers of people. Maybe that was part of the problem."
            },
            {
                "speaker": "",
                "time": "(01:28:28)",
                "text": "Human nature being what it is, I noticed that two of my principal critics, John Hoopes from the University of Kansas and Flint Dibble, who’s now teaching at the University of Cardiff in Wales in the UK, are both people who like to have media exposure. John Hoopes has just recently started a YouTube channel. Flint Dibble has had one for quite a while. A pretty small number of followers. I think that they feel that they should be the ones who are getting the global attention and that it’s not right that I am and that the best way to stop that is to stop me, to shut me down, to get me canceled and basically requiring Netflix to relabel my series from a documentary to a science fiction, which is what they actually had the temerity to suggest to Netflix."
            },
            {
                "speaker": "",
                "time": "(01:29:24)",
                "text": "If that had gone through, if Netflix had listened to them, that would’ve effectively been the cancellation of my documentary series. It would no longer have been ranked under documentaries. It was a deliberate attempt to shut me down. I see that going on again and again, and it’s so unfortunate and so unnecessary. I’ve become very defensive towards archeology. I hit back. After 30 years of these attacks on my work, I’m tired of it. I do defend myself. Sometimes, I’m perhaps over-vigorous in that defense. Maybe I was a little bit too strong in my critique of archeology in the first season of Ancient Apocalypse. Maybe I should have been a bit gentler and a bit kinder. I’ve tried to reflect that in the second season and to bring also many more Indigenous voices into the second season, as well as the voices of many more archeologists."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:16)",
                "text": "Yeah. In general, I got a chance to get a glimpse of the archeology community. In archeology/in science, in general, I don’t have much patience for this arrogance or snark or dismissal of general human curiosity that I think your work inspires in people. That’s why people like Ed Barnhart, who I recently had a conversation with… He radiates kindness and curiosity as well. It’s like that kind of approach to ideas, especially about human history, it inspires people."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:30:54)",
                "text": "Exactly."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:55)",
                "text": "Inspires millions of people to ask questions."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:30:57)",
                "text": "Exactly. Exactly."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:30:57)",
                "text": "I mean, that’s why you had Keanu Reeves on the new season. He’s basically coming to the show from that same perspective of curiosity."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:31:05)",
                "text": "Keanu is genuinely curious about the past and very, very interested in it. He’s bringing to it questions that everybody brings to the past. He’s speaking for every man in the series."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:31:17)",
                "text": "Given that, can you maybe steelman the case that archeologists make about this period that we’ve been talking about? Can make the case that that is indeed what happened; is it was hunter-gatherers for a long time, and then there was a cataclysm, a very difficult period in human history with the Younger Dryas, and that changed the environment and then led to the springing up of civilizations at different places on earth? Can you make the case for that?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:31:50)",
                "text": "No, I completely understand why that is the position of archeology because that’s what they’ve found. Archeology is very much wishing to define itself as a science. The techniques of weighing, and measuring, and counting are very key to what archeology does. In what they’ve found and what they’ve studied around the world, they don’t see any traces of a lost civilization. We live in a very politically correct world today. The idea that some lost civilization brought knowledge to other cultures around the world is seen as almost racist or colonialist in some way. It triggers that aspect as well."
            },
            {
                "speaker": "",
                "time": "(01:32:39)",
                "text": "But basically, I think majority of archeologists are in complete good faith on this. I don’t think that anybody’s really seeking to frame me. I think that what we are hearing from most archeologists… some much more vicious than others. But what we’re hearing from most archeologists is this is what we found, and we don’t see evidence for a lost civilization in it. To that, I…"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:33:00)",
                "text": "… civilization in it. And to that, I must reply, “Please look at the myths. Please consider the implications of the Younger Dryas. Please look at the ancient astronomy. Please look at those ancient maps and don’t just dismiss them and sneer at them. And for God’s sake, please look more deeply at the parts of the world that were immensely habitable and attractive during the ice age and that have hardly been studied by archaeology at all, before you tell us that your theory is the only one that can possibly be correct.” In fact, it’s a very arrogant and silly position of archeology, because archaeological theories are always being overthrown. It can take years, it can take decades. It took decades in the case of the Clovis-First hypothesis for the settlement of the Americas. But sooner or later a bad idea will be kicked out by a preponderance of evidence that that idea does not explain."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:33:57)",
                "text": "If we can just look back at your debate with Flint Dibble on Joe Rogan Experience, what are some takeaways from that? What have you learned? Maybe what are some things you like about Flint? You said that he’s one of your big critics, but what do you like about his ideas? And what were you maybe bothered by?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:34:17)",
                "text": "First of all, just very recently, and it can be found on my YouTube channel and it’s signaled on my website, I have made a video. Runs about an hour, which looks at a series of statements that Flint made during the debate, which I was not prepared to answer. And it turns out that some of those statements are not correct. The notion, for example, that there were three million shipwrecks that have been mapped, Flint actually uses the word “mapped.” Three million shipwrecks that have been mapped at one point in the debate. And I’ve put that clip into the video that I brought out. That is not a fact, that is an estimate, a UNESCO estimate. And actually in the small print on one of the slides that he has on the screen, you can see the word “estimate,” but he never expresses that word out loud. So those who are listening to the podcast rather than watching it wouldn’t even have a chance to see that. And I, sitting there in the studio didn’t see that word estimate either."
            },
            {
                "speaker": "",
                "time": "(01:35:19)",
                "text": "And I didn’t know that. I thought, “My God. If Flint has a point here. If there’d been three million shipwrecks found and mapped, if that’s the case, the absence of any shipwreck from a lost civilization of the ice age is a problem.” But then I discovered that it isn’t three million shipwrecks that have been mapped. It’s much, much less than that. And maybe it’s 250,000. Still a large number, but most of them from the last 1,000 years. And unfortunately, what Flint didn’t go into, and perhaps he should have shared with the audience … And again I go into this in the video, is that there is indisputable evidence that human beings were seafarers as much as 50 or 60,000 years ago. The peopling of Australia involved a relatively short 90 kilometers, 100-kilometer ocean voyage. But nevertheless, it was an ocean voyage."
            },
            {
                "speaker": "",
                "time": "(01:36:09)",
                "text": "And it must have involved a large enough people, a large enough number of people to create a permanent population that wouldn’t go extinct. The settlement of Cyprus is the same thing. It was always an island even during the ice age. And no ships have survived that speak to the settlement of Australia, and no ships have survived that speak to the settlement of Cyprus either. But that doesn’t mean that that thing didn’t happen."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:36:32)",
                "text": "I [inaudible 01:36:33] linger on this, because for me it was, the shipwrecks thing was convincing. And then looking back, first of all, watching your video, but also just realizing the peopling of Australia part, that’s mind boggling. 50,000 years ago. Just imagine being the person standing on the shore, looking out into the ocean. Standing on the shore of a harsh environment, looking out the ocean, a harsh environment and deciding that, “You know what? I’m going to go towards near certain death and explore-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:37:03)",
                "text": "You don’t know what’s on the other side of that water. You can’t see 90 kilometers-"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:37:06)",
                "text": "And humans did it."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:37:07)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:37:09)",
                "text": "I love humans so much."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:37:09)",
                "text": "Again, it’s that urge to explore. And I suggest that it probably began with a few pioneers who made the journey there and back. They ventured into the water. They definitely had boats. And lo and behold, after a two- or three-day voyage, they ended up on a coastline. You’re an individual. You’ve got by relatively straightforward island- hopping, where each island is within sight of each other as far as Timor. And when you get to Timor, suddenly you can’t island hop anymore. There’s an expansive ocean that you can’t see across. But that urge to explore, that curiosity, that is central to the human condition would undoubtedly have led some adventurous individuals to want to find out more and even be willing to risk their lives. And that first reconnoitering of what lay beyond that strait would’ve undoubtedly been undertaken by very few individuals. Not enough to create a permanent population in Australia, but when they came back with the good news that there’s a whole land there, that’s the land that geographers call Sahul, which just as Sunda was the Ice age Indonesian and Malaysian Peninsula all joined together into one landmass."
            },
            {
                "speaker": "",
                "time": "(01:38:25)",
                "text": "So Sahul was New Guinea joined to Australia. So they would’ve made landfall in New Guinea. And then they think, “Well, here is this vast open, incredible land. We need to bring more people here.” And that would’ve involved larger craft. You need to bring people with resources and you need to bring enough of them, both men and women in order to produce a population that will not rapidly become extinct. And it’s the same in Cyprus. There the work that’s been done suggests very strongly that we’re looking at planned migrations of groups of people in excess of 1,000 at a time, bringing animals with them. And this certainly would’ve involved multiple boats and boats of a significant size."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:39:15)",
                "text": "And there’s no archaeological evidence of those boats?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:39:18)",
                "text": "None whatsoever. The oldest boat that’s ever been found in the world is the Dokos shipwreck off Greece, which is around 5,000 years old if, I recall correctly."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:39:26)",
                "text": "So everything that makes a boat is lost at the time?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:39:30)",
                "text": "Yes. Boats can be preserved under certain circumstances. There’s a wreck at the bottom of the Black Sea, almost two miles deep. I didn’t know the Black Sea was that deep. But there’s a wreck and there’s no oxygen down there that is more than 2000 years old and is still in pretty much perfect condition. But in other conditions, the structure of the ship evaporates. Sometimes what you’re left with is the cargo of the ship. And you could say there was a ship that sank here, but the ship itself has gone. The fact is we know that our ancestors were seafarers as much as 50,000 years ago. And no ship has survived to testify to that, yet we accept that they were."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:40:10)",
                "text": "Do you think you one day we’ll find a ship that’s 10, 20, 30, 40, 50,000 years old?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:40:17)",
                "text": "It’s not impossible. I think it’s quite unlikely, given the very thin survival of ships the further back you go in time, with the oldest, as I say, being about 6,000 years old now. And then the other thing to take into account is the Younger Dryas event itself and the cataclysmic circumstances of that event. And the roiling of the seas that would’ve taken place then, how much would’ve survived in a boat accident at that time, would’ve survived for thousands of years afterwards, I’m not sure. But I don’t give up hope, it’s possible."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:40:55)",
                "text": "Okay. So that’s back to the three million shipwrecks."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:40:59)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:40:59)",
                "text": "So what’s your takeaway from that debate?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:41:01)",
                "text": "Well, my takeaway from that debate is that I should have been better prepared and I should have been less angry. I have to say that Flint had really disturbed me with these constant snide, not quite exact, references to racism and white supremacism in my work. I detest such things, and to have those labels stuck on me … He’s always avoided taking direct responsibility, pretty much always avoided. There’s one example that I include in the video I’ve made, where he really hasn’t successfully avoided it. But in most cases he’s trying to say that I rely on sources that were racist, but that he’s not saying that I myself am a racist."
            },
            {
                "speaker": "",
                "time": "(01:41:48)",
                "text": "But the end result of those statements is that people all around the world came to the conclusion that Graham Hancock is a racist and a white supremacist. And that really got under my skin and it really upset me. And I felt angry about it and I felt that I was there to defend Ancient Apocalypse, season one, whereas in fact, what I was there to do was to listen to a series of lectures where an archaeologist tells me what archaeologists have found. And that somehow I’m to deduce that from what they have found, they’re not going to find anything else. At least not anything to do with the lost civilization."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:42:23)",
                "text": "Listen, I feel you. I’ve seen the intensity of the attacks and the whole racism label is the one that can get under your skin. And it’s a toolbox that’s been prevalent over the past, let’s say decade, maybe a little bit more, as a method of cancellation. When a person is the opposite of racist, very often it’s hilarious to watch. But it can get under your skin, especially when you have certain dynamics that happen on the internet, where it seeps into a Wikipedia page and then other people read that Wikipedia page and you get to hear it from friends, “Oh, I didn’t know you’re … ” whatever. And you realize that Wikipedia description of who you are is actually has a lot of power, not by people that know you well, but people that just are learning about you for the first time-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:43:12)",
                "text": "Definitely."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:43:12)",
                "text": "And they can really start to annoy you and get onto your skin, when people are indirectly injecting … They’re writing articles about you. They can then be cited by Wikipedia. It can really bother a person who’s actually trying to do good science, or just trying to inspire people with different ideas."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:43:30)",
                "text": "I felt that my work was being deliberately misrepresented and I felt that I, as a human being, was being insulted and wronged in ways that are deeply hurtful. My wife and I have six children between us and we have nine grandchildren. And of those nine grandchildren, seven are of mixed race. And this is my family, and these are kids who are going to grow up and read Wikipedia and learn from reading Wikipedia that Grandpa was some kind of racist. This is a personal issue for me, and I’m afraid I carried that personal anger into the debate and it made me less effective than I should have been. But ultimately I do want to pay tribute to Flint. He is an excellent debater. He’s got a very sharp mind. He’s a very clever man and he’s very fast on his feet. And I recognize that."
            },
            {
                "speaker": "",
                "time": "(01:44:22)",
                "text": "I was definitely up against a superior debater in that debate. I’m not sure that I have those debating skills and I certainly didn’t have them on that particular day. I also admire about Flint something else, which is that he was willing to be there. Most archaeologists don’t want to talk to me at all. They want to insult me from the sidelines. They want to make sure that Wikipedia keeps on calling me a pseudo-archaeologist, or a purveyor of pseudo-archaeological theories. They want to make sure that the hints of racism are there, but they actually don’t want to sit down and confront me."
            },
            {
                "speaker": "",
                "time": "(01:44:54)",
                "text": "At least Flint was willing to do that and I’m grateful to him for that. And I think in that sense it is an important encounter between people with, let’s say, an alternative view of history and those with the very much mainstream view of history that archaeology gives us. And he’s also a very determined character. He doesn’t give up. So all of those things about him I admire and respect. But, I think he fought dirty during the debate, and I’ve said exactly why in this video that I now have up on YouTube."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:45:26)",
                "text": "To say a positive thing that I enjoyed, I think towards the end and him speaking about agriculture was pretty interesting. So the techniques of archaeology are pretty interesting, where you can get some insights through the fog of time about what people were doing, how they were living. That’s pretty interesting."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:45:47)",
                "text": "It’s very interesting. It’s a very important discipline. And I’ve said many times before, publicly, I couldn’t do any of my work without the work that archaeologists do. I emphasize very strongly in this video that I don’t study what archaeologists study. But nevertheless, the data that archaeologists have generated over the last century or so has been incredibly valuable to me in the work that I do. But, when I look at the Great Sphinx and the studies of archaeology saying that this is the work of the pharaoh Khafre, despite the absence of any single contemporary inscription that describes it to Khafre, and in fact the presence of other inscriptions that say that it was already there in the time of Khufu, I am not looking at what egyptologists study. They just dismiss all of that and lock into the Khafre connection."
            },
            {
                "speaker": "",
                "time": "(01:46:35)",
                "text": "At Gobekli Tepe, I’m not really looking at what archaeologists look at, I’m looking at the alignments of the megaliths and how they seem to track precession of the star Sirius over a period of time. Archaeologists aren’t interested in any of that. So I value and respect archeology. I think it’s an incredible tool for investigating our past, but I wish archaeologists would bring a slightly gentler frame of mind to it and a slightly opener perspective. And also that archaeologists would be willing to trust the general public to make up their own minds. It’s as though certain archaeologists are afraid of the public being presented with an alternative point of view, which they regard as quote, unquote, “dangerous,” because they somehow underestimate the intelligence of the general public and think the general public are just going to accept that."
            },
            {
                "speaker": "",
                "time": "(01:47:24)",
                "text": "Actually by condemning those alternative point of view, archaeologists make it much more likely that the general public will accept those alternative point of view, because there is a great distrust of experts in our society today. And behaving in a snobbish arrogant way, we archaeologists are the only people who are really qualified to speak about the past and anybody else who speaks about the past is dangerous. That actually is not helpful to archaeology in the long term. There could be a much more positive and a much more cooperative relationship. And I can see that relationship with a gentleman like Ed Barnhart. Was very much the case with archaeologist Martti Parssinen from the University of Helsinki and with geographer Alcio Arranzi, Brazilian geographer. Very, very senior figure who I worked with in the Amazon for season two of Ancient Apocalypse, looking at these astonishing earthworks that have emerged from the Amazon jungle and which more and more are now being found with LiDAR. Indeed, we found some of them ourselves with LiDAR while we were there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:48:26)",
                "text": "Yeah. That was an incredible part of the show that I got a chance to preview. It’s like there’s all this earthworks. Yeah. The traces of things built on the ground that probably you can only really appreciate when you look from up above."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:48:44)",
                "text": "That’s right."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:48:44)",
                "text": "So the idea that they built stuff that you can only appreciate when viewed from up above means they had a very deep relationship with the sky."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:48:55)",
                "text": "With the sky. And a very good knowledge of geometry as well, because these are geometrical structures and some of them even seem to incorporate geometrical games, almost like squaring the circle. It’s not quite that, but you have a lovely square earthwork with a lovely circle earthwork right in the middle of it. Whatever else they were, they were geometers. They were not just builders of fantastically huge earthworks that nobody expected in the Amazon. Not just builders of cities that we now know existed in the Amazon. But, that they were astronomers and mathematicians as well."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:49:32)",
                "text": "Everything we’re talking about is so full of mystery. It’s just fascinating, especially the farther back we go."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:49:36)",
                "text": "That’s what I love about the past, is the mystery that’s there. And that’s another thing that I regret about some archeologists is that their mission seems to drain all mystery out of the past, to suck it dry like some vampire sucking the blood out of the past and to reduce it to a series of numbers that appear to be scientific. I think that’s most unfortunate. The past is deeply mysterious. The whole story of life on earth is deeply mysterious. We were talking about the timeline of human beings, but if you go back to the formation of the earth itself, if I’ve got the figures right, it’s about four-and-a-half billion years ago that the Earth supposedly formed. It was then incredibly hot and inhospitable to life for the next several hundred million years."
            },
            {
                "speaker": "",
                "time": "(01:50:29)",
                "text": "But it was actually Francis Crick who pointed out something odd, that within 100 million years of the earth being cool enough to support life, there’s bacterial life all over the planet. And Crick wrote a book called Life Itself that was published in 1981, and he suggested that life had been brought here by a process of panspermia. Now that’s an idea that’s around in circulation that comets may carry bacteria, which can seed life on planets. But, Crick actually in Life Itself was talking about directed panspermia. He envisaged … This is Crick, not me. He envisaged an alien civilization far away across the galaxy, which faced extinction. Perhaps a supernova was going to go off in the neighborhood."
            },
            {
                "speaker": "",
                "time": "(01:51:22)",
                "text": "They were highly advanced. Their first thought it might’ve been, “Let’s get ourselves off the planet and go and populate some other planet,” but the distances of interstellar space were so great. So their second thought was, “Let’s preserve our DNA. Let’s put genetically engineered bacteria into cryogenic chambers and fire them off into the universe in all directions.” And bottom line of Crick’s theory in Life Itself is one of those cryogenic containers containing bacterial life from another solar system crashed into the early Earth. And that’s why life began so suddenly here on Earth."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:51:58)",
                "text": "If we as a human civilization continue, I think that is a one way to create backups of us elsewhere in the universe, given the space is to do a life gun and shoot it everywhere and it just plants. And you hope that whatever is the magic that makes up human consciousness … And if that magic was already there in the initial DNA of the bacteria-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:52:27)",
                "text": "The potential for that magic is there."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:52:29)",
                "text": "The potential is there."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:52:30)",
                "text": "And evolutionary forces will work upon it in different ways in different environments. But the potential is there. Yes. It’s something that we would do. If we were facing a complete extinction of life on planet Earth, a major global effort would be made to preserve it somehow. And that might well include firing off cryogenic chambers into the universe and hoping that some of them would land somewhere hospitable."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:52:56)",
                "text": "And as you were mentioning, there’s just so many interesting mysteries along the way here. For example, I think like three billion years it was single-cell organisms. So it seems like life was pretty good for single-cell organisms, that there was no need for multicellularity that for animals, for any of this kind of stuff. So why is that? It seems like you could adapt much better if you are a more complicated organism. It took a really long time to take that leap. Is it because it’s really hard to do? And what was the forcing function to do that kind of leap?"
            },
            {
                "speaker": "",
                "time": "(01:53:33)",
                "text": "And the same. For us to be selfish and self-obsessed for us humans, what was the magic leap to Homo sapiens from the other hominids? And why did Homo sapiens win out against the Neanderthals and the other competitors? Why are they not around anymore? So those are all fascinating mysteries and it feels like the more we propose radical ideas about our past and take it seriously and explore the more we’ll be able to figure out that puzzle that leads all the way back to Homo sapiens and maybe all the way back to the origin of life on Earth."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:54:13)",
                "text": "Yeah. Yeah. I think that Homo sapiens is the tail end of a very long, deep series of mysteries that goes back right to the beginning of life on this planet. And probably long before actually, because this planet is part of the universe. And God knows what else is out there in the universe."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:54:31)",
                "text": "Why do you think Homo sapiens evolved? What was the magic thing? There’s a bunch of theories about fire leading to meat, to cooking, which can fuel the brain. That’s one. The other is social interaction. We’re able to use our imagination to construct ideas and share those ideas and tell great stories and that is somehow an evolutionary advantage. Do you have any favorite conceptions of-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:54:57)",
                "text": "Well, it’s interesting. There’s no doubt that anatomically modern humans and Neanderthals coexisted in Europe for at least 10,000 years, probably more than that. And yet one of the popular views is that anatomically modern humans wiped out the Neanderthals, that we killed them off. But, at the same time we were into breeding with the Neanderthals. In a sense, the Neanderthals are not gone. They’re still within us today. We are part Neanderthal. There’s another theory that I’ve read about. There is some evidence that Neanderthals were cannibals, that there was ritual cannibalism took place amongst Neanderthals and particularly the eating of human brains. And this can cause Kuru, which can kill off whole populations. That’s another suggestion of why the Neanderthals died out."
            },
            {
                "speaker": "",
                "time": "(01:55:50)",
                "text": "There’s lots of possibilities that have been put forward. Maybe we just out-competed them. Maybe anatomically modern humans had some brain connections that they didn’t have. Even though the Neanderthal brain was bigger than the brain of anatomically modern human beings, as the old saying goes, size isn’t everything. Maybe we just had a more compact, more efficient brain. The fact of the matter is that Neanderthals and Denisovans did not survive the rise of Homo sapiens."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:56:21)",
                "text": "For our discussion, though, what is interesting is all the hominids seem to be explorers."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:56:26)",
                "text": "Yes."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:56:26)",
                "text": "They spread. I didn’t know this."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:56:28)",
                "text": "The fact that Homo erectus was all over the planet more than a million years ago is testament to that. And I do think that exploration urge is fundamental to humanity. And I would like to say that’s what I think I’m doing. I’m exercising my urge to explore the past in my own way, making my own path and defining my own route."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:56:53)",
                "text": "That’s the leap from non-human to human. One of the things you’ve discussed is your idea of what was the leap to human civilization? What is the driver? What is the inspiration for humans to form civilizations? And for you, that’s shamanism."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:57:12)",
                "text": "Definitely."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:57:12)",
                "text": "Can you explain what that means?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:57:14)",
                "text": "I think that shamanism is the origin of everything of value in humanity. I think it was the earliest form of science. When I spend time with shamans in the Amazon, I observe people who are constantly experimenting with plants in a very scientific way. They’re always trying a pinch of this and a pinch of that in different forms, for example, of the ayahuasca brew, to see if it enhances it or makes it different in any way. The invention of curare is a remarkable scientific feat, which is entirely down to shamans in the Amazon. They are the scientists of the hunter-forager state of society and they were the ancient leaders of human civilization."
            },
            {
                "speaker": "",
                "time": "(01:58:09)",
                "text": "So I think all civilization arises out of shamanism. And shamanism is a naturally scientific endeavor, where experimentation is undertaken an exploration and investigation of the environment around us. And what I’m suggesting is that one group, perhaps more than one group, went a bit further than other groups did, and used that study of the skies and developed navigational techniques and we’re able to sail and explore the Earth. But that ultimately what lies behind it is the same curiosity and investigative skill that shamans are still using in the Amazon to this day. And I do see them as scientists in a very proper use of the word."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(01:58:56)",
                "text": "But do you think something like ayahuasca was a part of that process?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(01:59:02)",
                "text": "Yes. Ayahuasca is the result of shamanistic investigation of what’s available in the Amazon. Of course, ayahuasca is all the fad in Western industrialized societies today. And some people see it as a miracle cure for all kinds of ailments and problems. And perhaps it is, perhaps it can be in certain ways. The ayahuasca itself is not an Amazonian word. It comes from the Quechuan language and it means the vine of souls or the vine of the dead. But the ayahuasca vine is only one of two principle ingredients in the ayahuasca brew. And the other ingredient are leaves that contain dimethyltryptamine. And there are two sources of that. One is a bush called Psychotria viridis, that’s its botanical name. They call it Chacruna in the Amazon. And its leaves are rich in dimethyltryptamine DMT, which is arguably the most powerful psychedelic known to science. And the other source comes from another vine, Diplopterys cabrerana, which the leaves of that vine also contain DMT. So the ayahuasca vine on its own is not going to give you a visionary journey. And the leaves that contain DMT on their own, whether they come from Diplopterys or whether they come from Chacruna, are not going to give you a visionary journey. And the reason they’re not going to give you the visionary journey, is because of the enzyme monoamine oxidase in the gut that shuts down DMT when absorbed orally. Basically, DMT is not accessible orally, unless you combine it with a monoamine oxidase inhibitor. And that’s what I mean when I’m talking about science in the Amazon, because there’s so many tens of thousands, hundreds of thousands different species of plants and trees in the Amazon. And they’ve gone around and they’ve found just two or three of them that put together can produce these extraordinary visionary experiences."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:00:59)",
                "text": "Just imagine the number of plants they had to have eaten, consumed and smoked or all kinds of combinations to arrive at that."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:01:07)",
                "text": "Exactly. Exactly. To realize that this is something very special. And then to use the principles there to find another form of it. So ayahuasca is the form that is made with the ayahuasca vine and the leaves of the Chacruna plant. But Yage is made from the ayahuasca vine and the leaves of another vine the ploparis caapiano, which contain not only, which is the DMT that everybody’s pretty much familiar with these days, but also 5-MeO-DMT. And the Yage experience, which I have also had, in my view is more intense and more powerful almost to the point of being overwhelming than the ayahuasca experience. But what the result of this sophisticated chemistry that we find taking place here is a brew which is hideous to drink. The taste, I find it quite repulsive. I almost retched just smelling it in the cup."
            },
            {
                "speaker": "",
                "time": "(02:02:15)",
                "text": "But then unleashes these extraordinary experiences. And it isn’t just pretty visuals. It’s the sense of encounters with sentient others, that there are sentient beings, that somehow we are surrounded by a realm of sentience that is not normally accessible to us. And that what the ayahuasca brew and certain other psychedelics, like some psilocybin mushrooms in a high enough dose can do it as well. LSD can do it. But Ayahuasca is the master in this of lowering the veil to what appears to be a seamlessly convincing other realm, other world. And of course the hard line, rational scientists will say that’s just all fantasies of your brain. But I don’t think we fully understand,"
            },
            {
                "speaker": "",
                "time": "(02:03:03)",
                "text": "Or even close to understanding exactly what consciousness is. And I remain open to two possibilities that consciousness is generated by the brain, is made by the brain in the way that a factory makes cars. But I also am open to the possibility that the brain is a receiver of consciousness, just as a television set is the receiver of television signals. And that if that is the case, then we locked into the physical realm. We need our everyday alert, problem-solving state of consciousness, and that’s the state of consciousness that western civilization values and highly encourages. But these other states of consciousness that allow us to access alternative realities are possibly more important. It may be apocryphal, but it was reported after Francis Crick’s role-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:04:00)",
                "text": "But it was reported after Francis Crick’s role and his Nobel Prize for the discovery of the double helix that he finally got it under the influence of LSD. There’s the classic example of Kary Mullis and the polymerase chain reaction. He said he got that under the influence of LSD. So the notion that the alert problem-solving state of consciousness is the only valuable state of consciousness is disproved by valuable experiences that people have had in a visionary state. But the question that remains unresolved is those entities that we encounter, and not everybody encounters them, and you’re certainly not going to encounter them on every ayahuasca trip. There are ayahuasca journeys where nothing seems to happen. I suspect something does happen, but it happens at a subconscious level. I know that shamans in the Amazon regard those trips where actually you don’t see visions as amongst the most valuable, and they say you are learning stuff that you’re not remembering, but you’re learning it anyway."
            },
            {
                "speaker": "",
                "time": "(02:05:02)",
                "text": "These sentient others that are encountered, what are they? Are they just figments of our brain on drugs or are we actually gaining access to a parallel reality, which is inhabited by consciousness which is in a non-physical form? And I’m equally open to that idea. I think that may be what is going on here with ayahuasca."
            },
            {
                "speaker": "",
                "time": "(02:05:25)",
                "text": "But the other thing is that there is a presence within the ayahuasca brew, and she is present both in ayahuasca and in yachay. And that’s one of the reasons why the shamans say that actually the master of the process is the ayahuasca vine, not the leaves. It’s as though the vine has harnessed the leaves to gain access to human consciousness. And there, if you have sufficient exposure to ayahuasca or yachay, you drink it enough times, I’ve had maybe 75 or 80 journeys with ayahuasca, you definitely start to feel an intelligent presence with a definite personality, which I interpret as feminine, and which most people in the West interpret it as feminine and they call her Mother Ayahuasca. There are some tribes in the Amazon who interpret the spirit of ayahuasca as male, but in all cases, that spirit is seen as a teacher. That’s fundamentally what ayahuasca is. It’s a teacher. And it teaches moral lessons."
            },
            {
                "speaker": "",
                "time": "(02:06:28)",
                "text": "And that’s fascinating, that a mixture of two plants should cause us to reflect on our own behavior and how it may have hurt and damaged and affected others and fill us with a powerful wish not to repeat that negative behavior again in the future. The more baggage you carry in your life, the harder the beating the ayahuasca is going to give you, until it forces you to confront and take responsibility for your own behavior. And that is an extraordinary thing to come from a plant brew in that way."
            },
            {
                "speaker": "",
                "time": "(02:07:02)",
                "text": "And I think yes, I think ayahuasca is the most powerful of all the plant medicines for accessing these mysterious realms. But there’s no doubt you can access them. They’re all tryptamines. They’re all related to one another in one way. You can access them through LSD and you certainly can access them through psilocyb mushrooms as well in large enough dose."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:07:24)",
                "text": "Both possibilities, as you describe, are interesting. And to me, they’re kind of akin to each other. I wonder what the limit of the brain’s capacity is to create imaginary worlds and treat them seriously and make them real, and in those worlds, explore and have real moral, deep brainstorming sessions with those entities. So it’s almost like the power of the human mind to imagine taken to its limit."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:08:01)",
                "text": "It is. And the curious thing is that the same iconography… People paint their visions after ayahuasca sessions. People were painting in Europe in the cave of Lascaux, for example, and of course they had access to psilocyb mushrooms in prehistoric Europe. There’s a remarkable commonality in the imagery that is painted."
            },
            {
                "speaker": "",
                "time": "(02:08:26)",
                "text": "I like to give credit where credit is due, and there are two names that need to be mentioned here. One is the late, great Terence McKenna and his book Food of the Gods, where he proposed the idea very strongly that it was our ancestral encounters with psychedelics that made us fully human. That’s what switched on the modern human mind."
            },
            {
                "speaker": "",
                "time": "(02:08:47)",
                "text": "And very much the same idea began to be explored a bit earlier by Professor David Lewis-Williams at the University of Witwatersrand in South Africa, fabulous book called The Mind in the Cave, where he is again arguing that these astonishing similarities in cave art and rock art all around the world can only be properly explained by people in deeply altered states of consciousness attempting to remember, when they return to a normal everyday state of consciousness, attempting to remember their visions and document them on permanent media like the wall of a cave."
            },
            {
                "speaker": "",
                "time": "(02:09:22)",
                "text": "So, typically you get a lot of geometric patterns, but you also got entities. And those entities often are therianthropes, part animal, part human in form. Might have the head of a wolf and the body of a human being, might have the head of a bird and the body of a human being, and so on and so forth. And that they communicate with us in the visionary state."
            },
            {
                "speaker": "",
                "time": "(02:09:45)",
                "text": "Interestingly, although this sounds like woo-woo, and it is an area that most scientists would steer clear of at risk of their careers, there is very serious work now being done at Imperial College in London and at the University of California at San Diego, where volunteers are being given extended DMT. There’s a new technology, DMTx, where the DMT is fed directly into the bloodstream by drip, and it’s possible to keep the individual in the peak DMT state. Which normally when you smoke or vape DMT, you’re looking, if you’re lucky, at 10 minutes, or if you’re unlucky, if it’s a bad journey, because those 10 minutes can seem like forever. But with DMTx, with the drip-feeding of DMT into the bloodstream, these volunteers actually could be kept in the peak state for hours."
            },
            {
                "speaker": "",
                "time": "(02:10:40)",
                "text": "And unlike LSD where you rapidly build up tolerance, nobody ever builds up tolerance to DMT. It always hits you with the same power. Even if you took it yesterday and the day before and you’re taking it tomorrow as well, it’s still going to have that same power. There’s no tolerance there. So that’s how they can use that lack of tolerance to keep volunteers in this state."
            },
            {
                "speaker": "",
                "time": "(02:10:59)",
                "text": "And then when they debrief those volunteers… They’re also putting them in MRI scanners and looking at what’s happening in the brain. But when they debrief them, they’re all talking about encounters with sentient others. There’s even a group now called Sentient Others, where volunteers are now exchanging their experiences. They weren’t allowed to do so at the beginning of the experiment, but now that most of them have left it, they’re exchanging their experiences, and it’s all about encounters with sentient others who wish to teach them moral lessons."
            },
            {
                "speaker": "",
                "time": "(02:11:28)",
                "text": "Now, to me, that’s wild. What is going on here? How do we account for this? Yeah, I get the notion of hallucinations and brightly colored visuals, but the moral lessons that come with it, those are very odd."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:11:43)",
                "text": "Yeah. And would you say that the reason that could give birth to a civilization, is it because such visions can help create myths, and especially religious myths, that would be a cohesive thing for a large group of people to get around?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:12:02)",
                "text": "Yes. And can help us to be better members of our own community."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:12:05)",
                "text": "Right, with moral lessons."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:12:06)",
                "text": "Yeah. More contributing members of our community. More caring, more nurturing members of our community. That’s got to be good for any community. I’ve said this a dozen times, but I’ll say it again. If I had the power to do so, I would make it a law, an absolute law, that anybody running for a powerful political position, particularly if that position is president or head of state in any kind of way, that that person has to undergo the ayahuasca ordeal first. They have to have 10 or 12 sessions of ayahuasca as a condition for applying for the job. I suspect that most who had had those experiences wouldn’t want to apply for the job anymore. They would want to live a different kind of life. And those who did want to carry on being a leader of a nation would be very different people from the people who are leading the nations of the earth into chaos and destruction today."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:13:07)",
                "text": "Yeah, they would be doing it for the right reasons. I mentioned to you, I recently interviewed Donald Trump, and I actually brought up this same idea that it would be a much better world if most of Congress and most politicians would take some form of psychedelic, at the very least."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:13:21)",
                "text": "Yeah. I have no doubt that it would be a better world. I mean, this raises an interesting point, which is the role of government in controlling our consciousness. And in my opinion, the so-called War on Drugs is one of the fundamental abuses of human rights that have been undertaken in the past 60 years. It should be a Republican issue. If I understand the Republican Party correctly, the Republican Party believes in individual freedom for adults as much as possible, and particularly the freedom to make choices over their own bodies."
            },
            {
                "speaker": "",
                "time": "(02:13:55)",
                "text": "But in the case of even cannabis, I know, this is one of the great things that’s happening in America. It’s happening state by state where cannabis is being legalized and that draconian hand of government is being taken off the back of people who are consuming a medicine that is far less harmful than alcohol, which is glorified in our society."
            },
            {
                "speaker": "",
                "time": "(02:14:19)",
                "text": "We cannot say that we are free if we allow our government to dictate to us what experiences we may or may not have in our inner consciousness, while doing no harm to others. And the point there is we already have a whole raft of laws that deal with us when we do harm to others. Do we really need laws that tell us what we may or may not experience in the inner sanctum of our own consciousness? I think it’s a fundamental violation of adult sovereignty. And we would have much less drug problems if these drugs were all legalized and made available to people without shaming them, without punishing them in any way, but just part of normal social life. And then you could be sure that you were getting good product rather than really shitty product, which has been cut with all sorts of other things."
            },
            {
                "speaker": "",
                "time": "(02:15:10)",
                "text": "Ultimately, the way forward is for adults to take responsibility for their own behavior, and for society to allow that to happen, and not to have big government taking responsibility for decisions that should be in the hands of individuals."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:15:24)",
                "text": "And for me also, it’s exciting. Some of these substances like psilocybin are being integrated into scientific studies in large scales. It’s really interesting."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:15:33)",
                "text": "We’ve seen a revolution in the way science looks at psychedelics in the last 20, 25 years. They were in that highly demonized category. But again, it’s one of those paradigms which gets overwhelmed by new evidence, and it began to be realized that psilocybin and other psychedelics are very helpful in a range of conditions from which people suffer. Post-traumatic stress disorder. The fear of death when you’re suffering from terminal cancer can be overwhelming, and it’s been found that psilocybin can remove that. Deep depressions can be evaporated with one single massive psilocybin journey. They just go away. There’s really good science on this. And they are being integrated into conventional medicine more and more. We’ll see it happening. I’m not sure if it’ll happen as fast as I would like to see it happen in my lifetime, but it is going to happen."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:16:29)",
                "text": "Yeah, I actually just recently found out that you had a TED Talk, War on Consciousness, that was taken down, and that was just part of just the general resistance. Because it was a pretty… It wasn’t radical. It wasn’t really a radical-"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:16:45)",
                "text": "I was talking about ayahuasca and I was talking about the view that I hold very strongly that as long as we do no harm to others, sovereign adults should be allowed to make decisions about their own bodies and not face a jail sentence or shaming as the result. So it was a TEDx Talk, not a TED Talk, organized by a local TED group. They called them TEDx Talks. And I gave this talk about the war on consciousness, and it was immediately pulled down from TED’s main channel with all kinds of bizarre reasons being given. But unfortunately, it was too late because a number of people had already downloaded the talk and then uploaded it onto other YouTube channels. And actually, their banning of it made it go viral in a way that would not have happened otherwise. But again, it’s a sign that points of view that are not acceptable to those in positions of power are simply dismissed and shut down, or at least attempts are made to do so."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:17:43)",
                "text": "In general, just along that line of thinking, I’m pretty sure that what we understand about consciousness today will seem silly to humans from a hundred years from now."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:17:53)",
                "text": "You bet it will. Especially if we harness psychedelics to investigate consciousness. And that is what is happening at Imperial College right now is the investigation of the experience. They’re not looking… There are other trials that are looking for the therapeutic potential of DMT, but in this case, they’re looking entirely at the experiences that people have and why they’re so similar from people from different age groups and different genders and different parts of the world, they’re all having the same experiences."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:18:23)",
                "text": "And for me, from an engineer perspective, it’s interesting if it’s possible to engineer consciousness in artificial beings. It’s another way to approach the question of how special is human consciousness. From where does it arise? Is it something that permeates all of life? And then in that case, what is the thing that makes life special? What is life? What is these living organisms that we have here that evolve to create humans? And what is truly special about humans? It’s both scary and exciting to consider the possibility that we can create something like this."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:19:02)",
                "text": "But why not? We are a vehicle for consciousness, in my view. I think consciousness is present in all life on earth. I don’t think it’s limited to human beings. We have the equipment to manifest and express that consciousness in the way that a dog, for example, doesn’t have or a snail doesn’t have or a pigeon doesn’t have. But when I look at two pigeons sitting on my garden fence and rubbing up close to each other and enjoying each other’s company and taking off together and hanging out together, I think they’re conscious beings. And I think consciousness is everywhere. I think it’s the basis of everything. And I suspect that fundamentally, consciousness is non-physical, and that it can manifest in physical forms where it can then have experiences that would not be available in the non-physical state. That’s a guess."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:19:52)",
                "text": "That’d be a fascinating… Because then you can construct all kinds of physical forms to manifest the consciousness."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:19:57)",
                "text": "Yeah. And see if consciousness enters, if they become conscious. Isn’t there some suggestion that artificial intelligence is already becoming conscious?"
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:20:04)",
                "text": "That makes humans really uncomfortable, because we are at the top of the food chain, we consider ourselves truly special, and to consider that there’s other things that could be special is scary."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:20:16)",
                "text": "Well, look how other people make us uncomfortable too. I mean, look at the state of the world today. All the conflicts that are raging. That’s because we’re afraid. When I say we, I’m speaking nation by nation, we are afraid of other people. We fear that they’re going to hurt us or damage us in some way. And so we seek to stop that. It’s the root of many, many conflicts, this fear. And so fear of AI may not be such a good idea after all. It might be very interesting to go down that route and see where it comes. Certainly in terms of exploring consciousness, it is very interesting."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:20:50)",
                "text": "Yeah, fear is a useful thing, but it can also be destructive."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:20:54)",
                "text": "Well, it can be destructive and it can shut you down completely."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:20:58)",
                "text": "If you look into the future, maybe the next a hundred years, what do you hope are the interesting discoveries in archeology that we’ll find?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:21:06)",
                "text": "Well, I’d really like to know how the Great Pyramid was built. And we now have, with new tech, with scanning technology, it’s now become apparent that there are many major voids within the Great Pyramid. Right above the Grand Gallery, there’s what looks like a second Grand Gallery that has been identified with remote scanning. And new chambers, one of them has even been opened up already, are being found as a result of this. So it may be that the Great Pyramid will ultimately give up its secrets."
            },
            {
                "speaker": "",
                "time": "(02:21:39)",
                "text": "I often think that the Great Pyramid is partly designed to do that. It’s designed to invite its own initiates. Some people aren’t interested in the Great Pyramid at all, but some people are fascinated by it and they’re drawn towards it. And when they’re drawn towards it, it immediately starts raising questions in their minds, and they seek answers to their questions."
            },
            {
                "speaker": "",
                "time": "(02:21:59)",
                "text": "So it’s like saying, ” Here I stand. Investigate me. Find out about me. Figure out what I am. Why have I got these two shafts cut into the side of the so-called Queen’s Chamber?” Why do they slope up through the body of the Great Pyramid? Why do they not exit on the outside of the Great Pyramid? Why, when we send a robot up those shafts, do we find them after about 160 feet blocked by a door with metal handles. Why when we drill through that door to see what’s beyond it, three or four feet away, we see another door. It’s very frustrating. But it’s saying to us, “Keep on exploring. If you’re persistent enough, we’ll eventually give you the answer.”"
            },
            {
                "speaker": "",
                "time": "(02:22:40)",
                "text": "So I’m hoping that that answer will come as to how this most mysterious of monuments was actually built and the inspiration that lay behind it. Certainly, I’m sure it was never a tomb, or a tomb only. The later pyramids might’ve been. Actually no pharaonic burial has been discovered in any pyramid. But nevertheless, it’s pretty clear that the later pyramids with the pyramid texts written on the walls, like the pyramid of Unas, Fifth Dynasty pyramid at Saqqara, were tombs."
            },
            {
                "speaker": "",
                "time": "(02:23:13)",
                "text": "But the Great Pyramid, to go to that length to create a tomb, to make it a scale model of the earth, to orient it perfectly to true north, to make it 6 million tons. This is not a tomb. This is something else. This is a curiosity device. This is something that is asking us to understand it. And I hope we will understand it. And I hope Egyptologists will be willing to set aside that prejudice that they’re only looking at a tomb and consider other possibilities. And as new tech is revealing these previously unknown inner spaces within the Great Pyramid, I think that’s going to become more and more likely."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:23:48)",
                "text": "So not just the how it was built, but the why."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:23:50)",
                "text": "But the why."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:23:52)",
                "text": "And to you, it seems obvious that there would be a cosmic motivation."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:23:57)",
                "text": "Yeah, very, very much so. As above, so below. Which is an idea in the Hermetica. The God Hermes for the Greeks was the Greek version of Thoth, the wisdom God of Ancient Egypt. And that’s where that saying comes from. It comes from the Hermetica. But it’s expressing an ancient Egyptian idea, to mirror the perfection of the heavens on earth."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:24:19)",
                "text": "So you think there’s something interesting to be discovered about the how it was built? You mean beyond the ideas of using ramps and wet sand."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:24:27)",
                "text": "Yeah. Ramps won’t do it. Ramps won’t do it. Nor will wet sand. It’s true that the ancient Egyptians did haul big objects on sleds on wet sand. There are even reliefs that show the process where an individual is standing on the front of the sledge pouring water down to lubricate the sand underneath. And that’s a perfectly respectable way to move a 200 ton block of stone across sand, flat sand, if you have enough people to pull it. But that is not going to help you get dozens of 70 ton granite blocks 300 feet in the air to form the roof of the King’s Chamber and the floor of the chamber above it, and the roof of that chamber, and the floor of the chamber above that, and so on and so forth. Wet sand never got those objects up there. Somehow they were lifted up there."
            },
            {
                "speaker": "",
                "time": "(02:25:18)",
                "text": "Now, yeah, ramps are proposed as the solution, but where are the remains of those ramps? If you’re going to carry blocks weighing up to two or three tons right to the top of the Great Pyramid to complete your work, you’re going to need a ramp that’s going to extend out into the desert for more than a mile at a 10 degree slope. And it’s calculated that a 10 degree slope is about the maximum slope that human labor can haul objects up a ramp. And that ramp can’t just be compacted sand, since heavy objects are being hauled up. It’s going to have to be made of very solid material, almost as solid as the pyramid itself. Where is it? We don’t see any trace of those so-called ramps that are supposed to have been involved in the construction of the pyramid. I think we don’t know. I think we have no idea it’s built. That’s why there’s so many different theories. We haven’t got the answer yet. But the how of it is one of the big mysteries from our past."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:26:12)",
                "text": "I love the Great Pyramids as a kind of puzzle that was created by the ancient peoples to be solved by later peoples. I don’t know if you’re aware of the 10,000-year clock that was built by Jeff Bezos and Danny Hillis in Sierra Diablo mountains in Texas. They’re building a clock that ticks once a year for 10,000 years."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:26:36)",
                "text": "Oh, wow."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:26:37)",
                "text": "So it’s talking about… And it’s supposed to sort of run, if there’s a nuclear apocalypse, it just runs."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:26:44)",
                "text": "It’ll keep running."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:26:45)",
                "text": "It’s an example of modern humans thinking like, okay, if 10,000 years from now and beyond, if something goes wrong or the future humans that are way different come back and they analyze what happened here, how can we create monuments that they could then analyze, and in that way be curious about. In their curiosity, discover some deep truths about this current time. It’s an interesting kind of notion of what can we build now."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:27:17)",
                "text": "That would last. And the answer is that the majority of what we build now wouldn’t last."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:27:17)",
                "text": "It wouldn’t."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:27:23)",
                "text": "It would be gone within a few thousand years. But what would last is massive megalithic structures like the Great Pyramid. That would last. And it could be used to send a message to the future. I think Göbekli Tepe serves a similar function. I mean, there it was, it was buried 10,400 years ago. And then for the next 10,000 years, nobody touched it. Nobody knew it was there. It took the genius of Klaus Schmidt, the original excavator, to realize what he’d found and what it was. But the great thing about the ceiling of Göbekli Tepe, the deliberate burial of Göbekli Tepe, is it means that no later culture trod over it and imposed their organic materials on it and messed up the dating sequences and so on and so forth, or vandalized it or used it as a quarry. It’s all there intact."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:28:17)",
                "text": "So you mentioned that the pyramids, and some of the other amazing things that humans have built, was the result of us humans struggling with our mortality."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:28:28)",
                "text": "That’s the ultimate goal. That seems to me what’s at the heart of many pyramids around the world is that they’re connected in one way or another to the notion of death and to the notion of the exploration of the afterlife. And this is of course, the fundamental mystery that all human beings face. We may wish to ignore it, we may wish to pretend that it’s not going to happen, but we are of course, all mortal. Every one of us, all 8 billion or however many of us that are on the planet right now, we’re all going to face death sooner or later. And the question is what happens?"
            },
            {
                "speaker": "",
                "time": "(02:29:06)",
                "text": "And there are a few cultures that really intensely, deeply studied that mystery. We are not one of them. The general view of science, I think, is that we’re accidents of evolution. When we die, the light blinks out. There’s no more of us. There’s no such thing as the soul. But that’s not a proven point. There’s no experiment that proves that’s the case. We know we die, but we don’t know whether there’s such a thing as a soul or not."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:29:32)",
                "text": "Yeah, it’s the great mystery."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:29:34)",
                "text": "It’s a great mystery that we all share, and those cultures that have investigated it, and Ancient Egypt is the best example, have investigated it thoroughly and map out the journey that we make after death. But that notion of a journey after death and of hazards and challenges along the way and ultimately of a judgment, that notion is found right around the world, and it even manifests into the three monotheistic faiths that are still present in the world today."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:30:01)",
                "text": "Well, you’re one such human, and you said you contemplate your own death."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:30:07)",
                "text": "Yeah."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:30:08)",
                "text": "Are you afraid of it?"
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:30:09)",
                "text": "No. I’m not afraid of death at all. I’m curious about death. I think it could be very interesting. I think it’s the beginning of the next great adventure. So I don’t fear it. And I would like to live as long as my body is healthy enough to make living worthwhile. But I don’t fear death. What I do fear is pain. I do fear the humiliation that old age and the collapse of the faculties can bring. I do fear the cancers that can strike us down and riddle us with pain and agony. That I fear very, very much indeed."
            },
            {
                "speaker": "",
                "time": "(02:30:46)",
                "text": "But death is going to come to all of us. I accept it. It’s going to come to me. I’m not going to say I’m looking forward to it, but when it happens, I’m going to approach it, I hope, with a sense of curiosity and a sense of adventure, that there’s something beyond this life. It isn’t heaven, it isn’t hell, but there’s something. The soul goes on. I think reincarnation is a very plausible idea. Again, modern science would reject that. But there’s the excellent work of Ian Stevenson, Children Who Remember Past Lives, who found that children up to the age of seven often have memories of past lives."
            },
            {
                "speaker": "",
                "time": "(02:31:25)",
                "text": "And in cultures where memories of past lives are discouraged, they tend not to express that much. But in cultures where memories of past lives are encouraged, like India, they do express it. And he found several subjects, children under the age of seven in India, who were able to remember specific details of a past life, and he was able to go to the place where that past life unfolded and validate those details. So if consciousness is the basis of everything, if it’s the essence of everything, and consciousness benefits in some way from being incarnated in physical form, then reincarnation makes a lot of sense. All the investment that the universe has put into creating this home for life may have a much bigger purpose than just accident."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:32:10)",
                "text": "What a beautiful mystery this whole thing is."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:32:12)",
                "text": "Yeah. We are immersed in mystery. We live in the midst of mystery. We’re surrounded by mystery. And if we pretend otherwise, we’re deluding ourselves."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:32:19)",
                "text": "And Graham, thank you so much for inspiring the world to explore that mystery. Thank you for talking today."
            },
            {
                "speaker": "Graham Hancock",
                "time": "(02:32:24)",
                "text": "Thank you, Lex. It’s been a pleasure."
            },
            {
                "speaker": "Lex Fridman",
                "time": "(02:32:27)",
                "text": "Thanks for listening to this conversation with Graham Hancock. To support this podcast, please check out our sponsors in the description."
            },
            {
                "speaker": "",
                "time": "(02:32:34)",
                "text": "And now let me leave you with some words from Charles Darwin. “It is not the strongest of the species that survives, nor the most intelligent. It is the one that is the most adaptable to change.” Thank you for listening and hope to see you next time."
            }
        ]
    }
]